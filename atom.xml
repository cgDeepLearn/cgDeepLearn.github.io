<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>cgDeepLearn</title>
  
  <subtitle>More than code</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://blog.writeathink.cn/"/>
  <updated>2018-10-31T01:54:18.978Z</updated>
  <id>https://blog.writeathink.cn/</id>
  
  <author>
    <name>cgDeepLearn</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Python下Select模块以及IO多路复用</title>
    <link href="https://blog.writeathink.cn/2018/10/31/Python-Select/"/>
    <id>https://blog.writeathink.cn/2018/10/31/Python-Select/</id>
    <published>2018-10-31T01:09:27.000Z</published>
    <updated>2018-10-31T01:54:18.978Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p class="description">select模块以及IO多路复用<br></p><p><img src="" alt="" style="width:100%"></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Python中的<code>select</code>模块专注于I/O多路复用，提供了<code>select</code>, <code>poll</code>, <code>epoll</code>三个方法(其中后两个在Linux中可用，windows仅支持select)，另外也提供了<code>kqueue</code>方法(freeBSD系统).</p><p>select()的机制中提供一<code>fd_set</code>的数据结构，实际上是一<code>long</code>类型的数组， 每一个数组元素都能与一打开的文件句柄（不管是Socket句柄，还是其他文件或命名管道或设备句柄）建立联系，建立联系的工作由程序员完成， 当调用select()时，由内核根据IO状态修改fd_set的内容，由此来通知执行了select()的进程哪一Socket或文件可读或可写。</p><p><strong>select主要用于socket通信当中，能监视我们需要的文件描述变化。</strong></p><a id="more"></a><h2 id="非阻塞式I-O编程特点"><a href="#非阻塞式I-O编程特点" class="headerlink" title="非阻塞式I/O编程特点"></a>非阻塞式I/O编程特点</h2><ul><li>如果发现一个I/O有输入，读取的过程中，另外一个也有了输入，这时候不会产生任何反应.这就需要你的程序语句去用到select函数的时候才知道有数据输入。</li><li>程序去select的时候，如果没有数据输入，程序会一直等待，直到有数据为止，也就是程序中无需循环和sleep。</li></ul><p>Select在Socket编程中还是比较重要的，可是对于初学Socket的人来说都不太爱用Select写程序，他们只是习惯写诸如<code>connect</code>、<code>accept</code>、<code>recv</code>或<code>recvfrom</code>这样的阻塞程序（所谓阻塞方式block，顾名思义，就是进程或是线程执行到这些函数时必须等待某个事件的发生，如果事件没有发生，进程或线程就被阻塞，函数不能立即返回）。</p><p>可是使用Select就可以完成非阻塞（所谓非阻塞方式non-block，就是进程或线程执行此函数时不必非要等待事件的发生，一旦执行肯定返回，以返回值的不同来反映函数的执行情况，如果事件发生则与阻塞方式相同，若事件没有发生，则返回一个代码来告知事件未发生，而进程或线程继续执行，所以效率较高）方式工作的程序，它能够监视我们需要监视的文件描述符的变化情况——读写或是异常。</p><h2 id="Select方法"><a href="#Select方法" class="headerlink" title="Select方法"></a>Select方法</h2><h3 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h3><p>进程指定内核监听哪些文件描述符(最多监听1024个fd)的哪些事件，当没有文件描述符事件发生时，进程被阻塞；当一个或者多个文件描述符事件发生时，进程被唤醒。</p><p>当我们调用select()时：</p><ol><li>上下文切换转换为内核态</li><li>将fd从用户空间复制到内核空间</li><li>内核遍历所有fd，查看其对应事件是否发生</li><li>如果没发生，将进程阻塞，当设备驱动产生中断或者timeout时间后，将进程唤醒，再次进行遍历</li><li>返回遍历后的fd</li><li>将fd从内核空间复制到用户空间</li></ol><h3 id="select函数方法参数"><a href="#select函数方法参数" class="headerlink" title="select函数方法参数"></a>select函数方法参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fd_r_list, fd_w_list, fd_e_list = select.select(rlist, wlist, xlist, [timeout])</span><br></pre></td></tr></table></figure><h4 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h4><p>可接受四个参数（前三个必须）:</p><ul><li>rlist: wait until ready for reading</li><li>wlist: wait until ready for writing</li><li>xlist: wait for an “exceptional condition”</li><li>timeout: 超时时间</li></ul><h4 id="返回值：三个列表"><a href="#返回值：三个列表" class="headerlink" title="返回值：三个列表"></a>返回值：三个列表</h4><p>select方法用来监视文件描述符(当文件描述符条件不满足时，select会阻塞)，当某个文件描述符状态改变后，会返回三个列表</p><ol><li>当参数1 序列中的fd满足“可读”条件时，则获取发生变化的fd并添加到fd_r_list中</li><li>当参数2 序列中含有fd时，则将该序列中所有的fd添加到 fd_w_list中</li><li>当参数3 序列中的fd发生错误时，则将该发生错误的fd添加到 fd_e_list中</li><li>当超时时间为空，则select会一直阻塞，直到监听的句柄发生变化.当超时时间 ＝ n(正整数)时，那么如果监听的句柄均无任何变化，则select会阻塞n秒，之后返回三个空列表，如果监听的句柄有变化，则直接执行。</li></ol><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><h4 id="示例1-模拟select-同时监听多个端口"><a href="#示例1-模拟select-同时监听多个端口" class="headerlink" title="示例1:模拟select,同时监听多个端口"></a>示例1:模拟select,同时监听多个端口</h4><ul><li>服务端</li></ul><figure class="highlight python"><figcaption><span>服务端select_server.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="string">"""模拟select,同时监听多个端口"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> select</span><br><span class="line"></span><br><span class="line">HOST = <span class="string">''</span></span><br><span class="line">PORT1, PORT2, PORT3 = <span class="number">8001</span>, <span class="number">8002</span>, <span class="number">8003</span></span><br><span class="line">BUFSIZ = <span class="number">1024</span></span><br><span class="line">ADDR1, ADDR2, ADDR3 = (HOST, PORT1), (HOST, PORT2), (HOST, PORT3)</span><br><span class="line"></span><br><span class="line">ss1 = socket.socket()</span><br><span class="line">ss1.bind(ADDR1)</span><br><span class="line">ss1.listen()</span><br><span class="line"></span><br><span class="line">ss2 = socket.socket()</span><br><span class="line">ss2.bind(ADDR2)</span><br><span class="line">ss2.listen()</span><br><span class="line"></span><br><span class="line">ss3 = socket.socket()</span><br><span class="line">ss3.bind(ADDR3)</span><br><span class="line">ss3.listen()</span><br><span class="line"></span><br><span class="line">inputs = [ss1, ss2, ss3]</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">    r_list, w_list, e_list = select.select(inputs,[],inputs,<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> ss <span class="keyword">in</span> r_list:</span><br><span class="line">        <span class="comment"># conn表示每一个连接对象</span></span><br><span class="line">        conn, address = ss.accept()</span><br><span class="line">        conn.sendall(bytes(<span class="string">'hello'</span>, encoding=<span class="string">'utf-8'</span>))</span><br><span class="line">        conn.close()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> ss <span class="keyword">in</span> e_list:</span><br><span class="line">        inputs.remove(ss)</span><br></pre></td></tr></table></figure><ul><li>客户端</li></ul><figure class="highlight python"><figcaption><span>客户端1select_client1.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="string">"""客户端1"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"></span><br><span class="line">HOST = <span class="string">'localhost'</span></span><br><span class="line">PORT = <span class="number">8001</span></span><br><span class="line">BUFSIZ = <span class="number">1024</span></span><br><span class="line">ADDR = (HOST, PORT)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cs = socket.socket()</span><br><span class="line">cs.connect(ADDR)</span><br><span class="line"></span><br><span class="line">msg = cs.recv(BUFSIZ)</span><br><span class="line"></span><br><span class="line">print(msg.decode(<span class="string">'utf-8'</span>))</span><br><span class="line"></span><br><span class="line">cs.close()</span><br></pre></td></tr></table></figure><hr><figure class="highlight python"><figcaption><span>客户端2select_client2.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="string">"""客户端2"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"></span><br><span class="line">HOST = <span class="string">'localhost'</span></span><br><span class="line">PORT = <span class="number">8002</span></span><br><span class="line">BUFSIZ = <span class="number">1024</span></span><br><span class="line">ADDR = (HOST, PORT)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cs = socket.socket()</span><br><span class="line">cs.connect(ADDR)</span><br><span class="line"></span><br><span class="line">msg = cs.recv(BUFSIZ)</span><br><span class="line"></span><br><span class="line">print(msg.decode(<span class="string">'utf-8'</span>))</span><br><span class="line"></span><br><span class="line">cs.close()</span><br></pre></td></tr></table></figure><p>运行server端和client端，客户端1,2均能连接。<br>但是以上程序并不能同时对客户端的输入同时响应处理(两个客户端连接都没关闭的情况下)，下面就来介绍I/O多路复用的例子</p><h4 id="示例2：IO多路复用–使用socket模拟多线程，并实现读写分离"><a href="#示例2：IO多路复用–使用socket模拟多线程，并实现读写分离" class="headerlink" title="示例2：IO多路复用–使用socket模拟多线程，并实现读写分离"></a>示例2：IO多路复用–使用socket模拟多线程，并实现读写分离</h4><ul><li>服务端</li></ul><figure class="highlight python"><figcaption><span>服务端select_multi_server.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="string">"""使用socket模拟多线程，使多用户可以同时连接"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> select</span><br><span class="line"><span class="keyword">import</span> queue</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> ctime</span><br><span class="line"></span><br><span class="line">HOST = <span class="string">''</span></span><br><span class="line">PORT = <span class="number">8001</span></span><br><span class="line">BUFSIZ = <span class="number">1024</span></span><br><span class="line">ADDR = (HOST, PORT)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建连接</span></span><br><span class="line">ss = socket.socket(socket.AF_INET, socket.SOCK_STREAM)</span><br><span class="line"><span class="comment">#ss.setblocking(False)</span></span><br><span class="line"></span><br><span class="line">ss.bind(ADDR)</span><br><span class="line">ss.listen(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">inputs = [ss, ]</span><br><span class="line">outputs = []</span><br><span class="line">message_dict = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> inputs:</span><br><span class="line">    print(<span class="string">'waiting for the next event...'</span>)</span><br><span class="line">    r_list, w_list, e_list = select.select(inputs, outputs, inputs, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> r_list:</span><br><span class="line">        <span class="comment"># 判断当前触发的是不是服务端对象，当触发的是服务端对象时，说明有新客户端连接进来了</span></span><br><span class="line">        <span class="keyword">if</span> s <span class="keyword">is</span> ss:</span><br><span class="line">            <span class="comment"># 表示有新用户来连接</span></span><br><span class="line">            conn, addr = s.accept()</span><br><span class="line">            print(<span class="string">"connection from"</span>, addr)</span><br><span class="line">            <span class="comment"># 将客户端对象也加入到监听的列表中，当客户端发消息时select将触发</span></span><br><span class="line">            <span class="comment">#conn.setblocking(0)</span></span><br><span class="line">            inputs.append(conn)</span><br><span class="line">            <span class="comment"># 为连接的客户端单独创建一个消息队列，用来保存客户端发送的消息</span></span><br><span class="line">            message_dict[conn] = queue.Queue()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 有老用户发消息</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                data_bytes = s.recv(BUFSIZ)</span><br><span class="line">            <span class="comment"># 客户端未断开</span></span><br><span class="line">            <span class="comment">#if data_bytes != '':</span></span><br><span class="line">                data = data_bytes.decode(<span class="string">'utf-8'</span>)</span><br><span class="line">                print(<span class="string">'received "%s" from %s'</span> % (data, s.getpeername()))</span><br><span class="line">                <span class="comment"># 将收到的消息放到相对应的socket客户端的消息列表中</span></span><br><span class="line">                message_dict[s].put(data)</span><br><span class="line">                <span class="comment"># 将需要进行回复操作socket放到outputs列表中，让select监听</span></span><br><span class="line">                <span class="keyword">if</span> s <span class="keyword">not</span> <span class="keyword">in</span> outputs:</span><br><span class="line">                    outputs.append(s)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="comment"># else:</span></span><br><span class="line">                <span class="comment"># 客户端断开了连接(或出现其他异常)，将客户端的监听从inputs列表中移除</span></span><br><span class="line">                print(<span class="string">'closing'</span>, addr)</span><br><span class="line">                <span class="keyword">if</span> s <span class="keyword">in</span> outputs:</span><br><span class="line">                    outputs.remove(s)</span><br><span class="line">                inputs.remove(s)</span><br><span class="line">                s.close()</span><br><span class="line">                <span class="comment"># 移除相应socket客户端对象的消息队列</span></span><br><span class="line">                <span class="keyword">del</span> message_dict[s]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 处理发送消息列表</span></span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> w_list:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># 如果消息队列中有消息，从消息队列中获取要发送的消息</span></span><br><span class="line">            message_queue = message_dict.get(s)</span><br><span class="line">            send_data = <span class="string">''</span></span><br><span class="line">            <span class="keyword">if</span> message_queue <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                send_data = message_queue.get_nowait()</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 客户端连接断开了</span></span><br><span class="line">                print(<span class="string">'has closed'</span>)</span><br><span class="line">        <span class="keyword">except</span> queue.Empty:</span><br><span class="line">            <span class="comment"># 客户端连接断开了</span></span><br><span class="line">            print(s.getpeername())</span><br><span class="line">            outputs.remove(s)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 处理消息</span></span><br><span class="line">            <span class="keyword">if</span> message_queue <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                <span class="comment"># 把接收到的数据加上时间戳再返回</span></span><br><span class="line">                s.send((<span class="string">"[%s] %s"</span> % (ctime(), send_data)).encode(<span class="string">'utf-8'</span>))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                print(<span class="string">"has closed"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 处理异常情况</span></span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> e_list:</span><br><span class="line">        print(<span class="string">"exception condition on"</span>, s.getpeername())</span><br><span class="line">        inputs.remove(s)</span><br><span class="line">        <span class="keyword">if</span> s <span class="keyword">in</span> outputs:</span><br><span class="line">            outputs.remove(s)</span><br><span class="line"></span><br><span class="line">        s.close()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">del</span> message_dict[s]</span><br></pre></td></tr></table></figure><ul><li>客户端</li></ul><figure class="highlight python"><figcaption><span>客户端select_multi_client.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coidng=utf-8</span></span><br><span class="line"><span class="string">"""客户端"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"></span><br><span class="line">HOST = <span class="string">'localhost'</span></span><br><span class="line">PORT = <span class="number">8001</span></span><br><span class="line">BUFSIZ = <span class="number">1024</span></span><br><span class="line">ADDR = (HOST, PORT)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sock_num = <span class="number">2</span></span><br><span class="line">socks = [socket.socket(socket.AF_INET, socket.SOCK_STREAM) <span class="keyword">for</span> _ <span class="keyword">in</span> range(sock_num)]</span><br><span class="line"></span><br><span class="line">msgs = [<span class="string">"Hello"</span>, <span class="string">"I'm Robot"</span>, <span class="string">"Bye"</span>]</span><br><span class="line"></span><br><span class="line">print(<span class="string">"connecting to %s port %s..."</span> % ADDR)</span><br><span class="line"><span class="comment"># 连接到服务器</span></span><br><span class="line"><span class="keyword">for</span> s <span class="keyword">in</span> socks:</span><br><span class="line">    s.connect(ADDR)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> index, msg <span class="keyword">in</span> enumerate(msgs):</span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> socks:</span><br><span class="line">        print(<span class="string">'%s: sending "%s" %d'</span> % (s.getpeername(), msg, index))</span><br><span class="line">        s.send(msg.encode(<span class="string">'utf-8'</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> s <span class="keyword">in</span> socks:</span><br><span class="line">    data = s.recv(BUFSIZ).decode(<span class="string">"utf-8"</span>)</span><br><span class="line">    print(<span class="string">'%s: received "%s"'</span> % (s.getpeername(),data))</span><br><span class="line">    <span class="comment"># 接收到一个回复后就断开连接，我们就可以看看服务器端是如何处理之后的请求的</span></span><br><span class="line">    <span class="keyword">if</span> data != <span class="string">""</span>:</span><br><span class="line">        print(<span class="string">'closing socket'</span>, s.getsockname())</span><br><span class="line">        s.close()</span><br></pre></td></tr></table></figure><ul><li>运行结果</li></ul><p>分别运行服务端和客户端程序：</p><figure class="highlight shell"><figcaption><span>服务端结果</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> python select_multi_server.py</span><br><span class="line">waiting for the next event...</span><br><span class="line">connection from ('127.0.0.1', 9078)</span><br><span class="line">waiting for the next event...</span><br><span class="line">connection from ('127.0.0.1', 9079)</span><br><span class="line">received "HelloI'm Robot" from ('127.0.0.1', 9078)</span><br><span class="line">waiting for the next event...</span><br><span class="line">received "Bye" from ('127.0.0.1', 9078)</span><br><span class="line">received "HelloI'm RobotBye" from ('127.0.0.1', 9079)</span><br><span class="line">waiting for the next event...</span><br><span class="line">waiting for the next event...</span><br><span class="line">('127.0.0.1', 9078)</span><br><span class="line">('127.0.0.1', 9079)</span><br><span class="line">waiting for the next event...</span><br><span class="line">closing ('127.0.0.1', 9079)</span><br><span class="line">waiting for the next event...</span><br><span class="line">received "" from ('127.0.0.1', 9079)</span><br><span class="line">waiting for the next event...</span><br><span class="line">received "" from ('127.0.0.1', 9079)</span><br><span class="line">waiting for the next event...</span><br><span class="line">closing ('127.0.0.1', 9079)</span><br><span class="line">has closed</span><br><span class="line">has closed</span><br><span class="line">waiting for the next event...</span><br></pre></td></tr></table></figure><hr><figure class="highlight shell"><figcaption><span>客户端结果</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> python select_multi_client.py</span><br><span class="line">connecting to localhost port 8001...</span><br><span class="line">('127.0.0.1', 8001): sending "Hello" 0</span><br><span class="line">('127.0.0.1', 8001): sending "Hello" 0</span><br><span class="line">('127.0.0.1', 8001): sending "I'm Robot" 1</span><br><span class="line">('127.0.0.1', 8001): sending "I'm Robot" 1</span><br><span class="line">('127.0.0.1', 8001): sending "Bye" 2</span><br><span class="line">('127.0.0.1', 8001): sending "Bye" 2</span><br><span class="line">('127.0.0.1', 8001): received "[Wed Oct 31 09:41:05 2018] HelloI'm RobotBye"</span><br><span class="line">closing socket ('127.0.0.1', 9078)</span><br><span class="line">('127.0.0.1', 8001): received "[Wed Oct 31 09:41:05 2018] HelloI'm RobotBye"</span><br><span class="line">closing socket ('127.0.0.1', 9079)</span><br></pre></td></tr></table></figure><h2 id="select、poll、epoll区别"><a href="#select、poll、epoll区别" class="headerlink" title="select、poll、epoll区别"></a>select、poll、epoll区别</h2><p>多次运行程序，你会发现客户端程序返回结果里的received后面的略有不同，你发现其中的原因了吗！</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;select模块以及IO多路复用&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;Python中的&lt;code&gt;select&lt;/code&gt;模块专注于I/O多路复用，提供了&lt;code&gt;select&lt;/code&gt;, &lt;code&gt;poll&lt;/code&gt;, &lt;code&gt;epoll&lt;/code&gt;三个方法(其中后两个在Linux中可用，windows仅支持select)，另外也提供了&lt;code&gt;kqueue&lt;/code&gt;方法(freeBSD系统).&lt;/p&gt;
&lt;p&gt;select()的机制中提供一&lt;code&gt;fd_set&lt;/code&gt;的数据结构，实际上是一&lt;code&gt;long&lt;/code&gt;类型的数组， 每一个数组元素都能与一打开的文件句柄（不管是Socket句柄，还是其他文件或命名管道或设备句柄）建立联系，建立联系的工作由程序员完成， 当调用select()时，由内核根据IO状态修改fd_set的内容，由此来通知执行了select()的进程哪一Socket或文件可读或可写。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;select主要用于socket通信当中，能监视我们需要的文件描述变化。&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://blog.writeathink.cn/categories/Python/"/>
    
    
      <category term="python" scheme="https://blog.writeathink.cn/tags/python/"/>
    
      <category term="select" scheme="https://blog.writeathink.cn/tags/select/"/>
    
      <category term="socket" scheme="https://blog.writeathink.cn/tags/socket/"/>
    
      <category term="IO多路复用" scheme="https://blog.writeathink.cn/tags/IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"/>
    
      <category term="epoll" scheme="https://blog.writeathink.cn/tags/epoll/"/>
    
  </entry>
  
  <entry>
    <title>Python Socket编程</title>
    <link href="https://blog.writeathink.cn/2018/10/24/Socket/"/>
    <id>https://blog.writeathink.cn/2018/10/24/Socket/</id>
    <published>2018-10-24T06:59:09.000Z</published>
    <updated>2018-10-24T07:48:02.565Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p class="description">Socket套接字<br></p><p><img src="" alt="" style="width:100%"></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><div class="note info"><p><br><br><code>socket</code>起源于Unix，而Unix/Linux基本哲学之一就是“一切皆文件”，对于文件用【打开】【读写】【关闭】模式来操作。<br>socket就是该模式的一个实现，<code>socket</code>即是一种特殊的文件，一些socket函数就是对其进行的操作（读/写IO、打开、关闭）<br><br>- socket和file的区别<br><br>1. file模块是针对某个指定文件进行【打开】【读写】【关闭】<br><br>2. socket模块是针对 服务器端 和 客户端 Socket 进行【打开】【读写】【关闭】<br><br>下面我们通过几种不同方式来实现时间戳服务器端和客户端：<code>TCP</code>、<code>UDP</code>、<code>SocketServer TCP</code>、<code>Twisted Reactor TCP</code><br><br></p></div><a id="more"></a><h2 id="TCP时间戳服务"><a href="#TCP时间戳服务" class="headerlink" title="TCP时间戳服务"></a>TCP时间戳服务</h2><h3 id="TCP服务器端"><a href="#TCP服务器端" class="headerlink" title="TCP服务器端"></a>TCP服务器端</h3><h4 id="TCP服务器端设计方式伪代码"><a href="#TCP服务器端设计方式伪代码" class="headerlink" title="TCP服务器端设计方式伪代码"></a>TCP服务器端设计方式伪代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ss = socket()               <span class="comment"># 创建服务器套接字</span></span><br><span class="line">ss.bind()                   <span class="comment"># 套接字与地址绑定</span></span><br><span class="line">ss.listen()                 <span class="comment"># 监听连接</span></span><br><span class="line">inf_loop:                   <span class="comment"># 服务器无限循环</span></span><br><span class="line">    cs = ss.accept()        <span class="comment"># 接受客户端连接</span></span><br><span class="line">    comm_loop:              <span class="comment"># 通信循环</span></span><br><span class="line">        cs.recv()/cs.send() <span class="comment"># 对话(接受/发送)</span></span><br><span class="line">    cs.close()              <span class="comment"># 关闭客户端套接字</span></span><br><span class="line">ss.close()                  <span class="comment"># 关闭服务器套接字(可选)</span></span><br></pre></td></tr></table></figure><h4 id="创建TCP时间戳服务器"><a href="#创建TCP时间戳服务器" class="headerlink" title="创建TCP时间戳服务器"></a>创建TCP时间戳服务器</h4><figure class="highlight python"><figcaption><span>TCP时间戳服务器(tsTserv.py)</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">创建一个TCP服务器，它接受来自客户端的消息，然后将消息加上时间前缀并发送回客户端</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> socket <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> ctime</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">HOST = <span class="string">''</span></span><br><span class="line">PORT =<span class="number">21567</span></span><br><span class="line">BUFSIZ = <span class="number">1024</span></span><br><span class="line">ADDR = (HOST, PORT)</span><br><span class="line"></span><br><span class="line">tcpSerSock = socket(AF_INET, SOCK_STREAM)</span><br><span class="line">tcpSerSock.bind(ADDR)</span><br><span class="line">tcpSerSock.listen(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">    print(<span class="string">"waiting for connection..."</span>)</span><br><span class="line">    tcpCliSock, addr = tcpSerSock.accept()</span><br><span class="line">    print(<span class="string">"...connected from "</span>, addr)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        data = tcpCliSock.recv(BUFSIZ)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> data:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        tcpCliSock.send(bytes(<span class="string">'[%s] %s'</span> % (ctime(), data.decode(<span class="string">'utf-8'</span>)),<span class="string">'utf-8'</span>))</span><br><span class="line">    tcpCliSock.close()</span><br><span class="line"></span><br><span class="line">tcpSerSock.close()</span><br></pre></td></tr></table></figure><h3 id="TCP客户端"><a href="#TCP客户端" class="headerlink" title="TCP客户端"></a>TCP客户端</h3><h4 id="客户端伪代码"><a href="#客户端伪代码" class="headerlink" title="客户端伪代码"></a>客户端伪代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cs = socket()           <span class="comment"># 创建客户端套接字</span></span><br><span class="line">cs.connect()            <span class="comment"># 尝试连接服务器</span></span><br><span class="line">comm_loop:              <span class="comment"># 通信循环</span></span><br><span class="line">    cs.send()/cs.recv() <span class="comment"># 对话(发送/接收)</span></span><br><span class="line">cs.close()              <span class="comment"># 关闭客户端套接字</span></span><br></pre></td></tr></table></figure><h4 id="创建TCP时间戳客户端"><a href="#创建TCP时间戳客户端" class="headerlink" title="创建TCP时间戳客户端"></a>创建TCP时间戳客户端</h4><figure class="highlight python"><figcaption><span>TCP时间戳客户端(tsTclnt.py)</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> socket <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">HOST = <span class="string">'localhost'</span></span><br><span class="line">PORT = <span class="number">21567</span></span><br><span class="line">BUFSIZ = <span class="number">1024</span></span><br><span class="line">ADDR = (HOST, PORT)</span><br><span class="line"></span><br><span class="line">tcpCliSock = socket(AF_INET, SOCK_STREAM)</span><br><span class="line">tcpCliSock.connect(ADDR)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">    data = input(<span class="string">'&gt; '</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> data:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    tcpCliSock.send(bytes(data,<span class="string">'utf-8'</span>))</span><br><span class="line">    data = tcpCliSock.recv(BUFSIZ)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> data:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    print(data.decode(<span class="string">'utf-8'</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tcpCliSock.close()</span><br></pre></td></tr></table></figure><h3 id="执行TCP服务器和客户端"><a href="#执行TCP服务器和客户端" class="headerlink" title="执行TCP服务器和客户端"></a>执行TCP服务器和客户端</h3><ul><li>服务器端:</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ python tsTserv.py</span><br><span class="line">waiting <span class="keyword">for</span> connection...</span><br><span class="line">...connected from (<span class="string">'127.0.0.1'</span>, 28182)</span><br><span class="line">waiting <span class="keyword">for</span> connection</span><br></pre></td></tr></table></figure><ul><li>客户端</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ python tsTclnt.py</span><br><span class="line">&gt; Hi</span><br><span class="line">[Wed Oct 24 10:39:43 2018] Hi</span><br><span class="line">&gt; I<span class="string">'m Jack</span></span><br><span class="line"><span class="string">[Wed Oct 24 10:39:47 2018] I'</span>m Jack</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure><h2 id="UDP时间戳服务器"><a href="#UDP时间戳服务器" class="headerlink" title="UDP时间戳服务器"></a>UDP时间戳服务器</h2><h3 id="UDP服务器端"><a href="#UDP服务器端" class="headerlink" title="UDP服务器端"></a>UDP服务器端</h3><h4 id="TCP服务器端设计方式伪代码-1"><a href="#TCP服务器端设计方式伪代码-1" class="headerlink" title="TCP服务器端设计方式伪代码"></a>TCP服务器端设计方式伪代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ss = socket()                   <span class="comment"># 创建服务器套接字</span></span><br><span class="line">ss.bind()                       <span class="comment"># 绑定服务器套接字</span></span><br><span class="line">inf_loop:                       <span class="comment"># 服务器无限循环</span></span><br><span class="line">    ss.recvfrom()/ss.sendto()   <span class="comment"># 接收/发送</span></span><br><span class="line">ss.close()                      <span class="comment"># 关闭服务器套接字</span></span><br></pre></td></tr></table></figure><h4 id="创建UDP服务器"><a href="#创建UDP服务器" class="headerlink" title="创建UDP服务器"></a>创建UDP服务器</h4><figure class="highlight python"><figcaption><span>UDP时间戳服务器(tsUserv.py)</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">UDP TimeStamp server</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> socket <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> ctime</span><br><span class="line"></span><br><span class="line">HOST = <span class="string">''</span></span><br><span class="line">PORT = <span class="number">21567</span></span><br><span class="line">BUFSIZ = <span class="number">1024</span></span><br><span class="line">ADDR = (HOST, PORT)</span><br><span class="line"></span><br><span class="line">udpSerSock = socket(AF_INET, SOCK_DGRAM)</span><br><span class="line">udpSerSock.bind(ADDR)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">    print(<span class="string">"wating for message..."</span>)</span><br><span class="line">    data, addr = udpSerSock.recvfrom(BUFSIZ)</span><br><span class="line">    udpSerSock.sendto(bytes(<span class="string">'[%s] %s'</span> %</span><br><span class="line">                            (ctime(), data.decode(<span class="string">'utf-8'</span>)), <span class="string">'utf-8'</span>), addr)</span><br><span class="line">    print(<span class="string">"...received from and returned to:"</span>, addr)</span><br><span class="line"></span><br><span class="line">udpSerSock.close()</span><br></pre></td></tr></table></figure><h3 id="UDP客户端"><a href="#UDP客户端" class="headerlink" title="UDP客户端"></a>UDP客户端</h3><h4 id="UDP客户端端设计方式伪代码"><a href="#UDP客户端端设计方式伪代码" class="headerlink" title="UDP客户端端设计方式伪代码"></a>UDP客户端端设计方式伪代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cs = socket()                   <span class="comment"># 创建客户端套接字</span></span><br><span class="line">comm_loop:                      <span class="comment"># 通信循环</span></span><br><span class="line">    cs.sendto()/cs.recvfrom()   <span class="comment"># 对话(发送接收)</span></span><br><span class="line">cs.close()                      <span class="comment"># 关闭客户端套接字</span></span><br></pre></td></tr></table></figure><h4 id="创建UDP客户端"><a href="#创建UDP客户端" class="headerlink" title="创建UDP客户端"></a>创建UDP客户端</h4><figure class="highlight python"><figcaption><span>UDP时间戳客户端(tsUclnt.py)</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># codin=utf-8</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">UDP TimeStamp Client</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> socket <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">HOST = <span class="string">'localhost'</span></span><br><span class="line">PORT = <span class="number">21567</span></span><br><span class="line">BUFSIZ = <span class="number">1024</span></span><br><span class="line">ADDR = (HOST, PORT)</span><br><span class="line"></span><br><span class="line">udpSerSock = socket(AF_INET, SOCK_DGRAM)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">    data = input(<span class="string">'&gt; '</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> data:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    udpSerSock.sendto(bytes(data,<span class="string">'utf-8'</span>), ADDR)</span><br><span class="line">    data, ADDR = udpSerSock.recvfrom(BUFSIZ)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> data:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    print(data.decode(<span class="string">'utf-8'</span>))</span><br><span class="line"></span><br><span class="line">udpSerSock.close()</span><br></pre></td></tr></table></figure><h2 id="SocketServer时间戳"><a href="#SocketServer时间戳" class="headerlink" title="SocketServer时间戳"></a>SocketServer时间戳</h2><h3 id="服务器端"><a href="#服务器端" class="headerlink" title="服务器端"></a>服务器端</h3><figure class="highlight python"><figcaption><span>SocketServer时间戳TCP服务器(tsTservSS.py)</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">SocketServer时间戳TCP服务器</span></span><br><span class="line"><span class="string">使用SocketServer类、TCPServer和StreamRequestHandler</span></span><br><span class="line"><span class="string">分叉，多线程</span></span><br><span class="line"><span class="string">windows不支持分叉</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> socketserver <span class="keyword">import</span> (TCPServer <span class="keyword">as</span> TCP, StreamRequestHandler <span class="keyword">as</span> SRH,</span><br><span class="line">                          ForkingMixIn <span class="keyword">as</span> FMI, ThreadingMixIn <span class="keyword">as</span> TMI)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> ctime</span><br><span class="line"></span><br><span class="line">HOST = <span class="string">''</span></span><br><span class="line">PORT = <span class="number">21567</span></span><br><span class="line">ADDR = (HOST, PORT)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FServer</span><span class="params">(FMI, TCP)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TServer</span><span class="params">(TMI, TCP)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyRequestHandler</span><span class="params">(SRH)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">handle</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"...connected from:"</span>, self.client_address)</span><br><span class="line">        self.wfile.write(</span><br><span class="line">            (<span class="string">"[%s] %s"</span> % (ctime(), self.rfile.readline().decode(<span class="string">'utf-8'</span>))).encode(<span class="string">'utf-8'</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tcpServ = TServer(ADDR, MyRequestHandler) <span class="comment"># TCP, FSever, TServer</span></span><br><span class="line">print(<span class="string">"waiting for connection..."</span>)</span><br><span class="line"></span><br><span class="line">tcpServ.serve_forever()</span><br></pre></td></tr></table></figure><h3 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h3><figure class="highlight python"><figcaption><span>SocketServer时间戳TCP客户端(tsTclntSS.py)</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">SocketServer时间戳TCP客户端</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> socket <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">HOST = <span class="string">'localhost'</span></span><br><span class="line">PORT = <span class="number">21567</span></span><br><span class="line">BUFSIZ = <span class="number">1024</span></span><br><span class="line">ADDR = (HOST, PORT)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">    tcpCliSock = socket(AF_INET, SOCK_STREAM)</span><br><span class="line">    tcpCliSock.connect(ADDR)</span><br><span class="line">    data = input(<span class="string">'&gt; '</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> data:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    tcpCliSock.send((<span class="string">"%s\r\n"</span> % data).encode(<span class="string">'utf-8'</span>))</span><br><span class="line">    data = tcpCliSock.recv(BUFSIZ).decode(<span class="string">'utf-8'</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> data:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    print(data.strip())</span><br><span class="line">    tcpCliSock.close()</span><br></pre></td></tr></table></figure><h2 id="Twisted-Reactor-TCP时间戳"><a href="#Twisted-Reactor-TCP时间戳" class="headerlink" title="Twisted Reactor TCP时间戳"></a>Twisted Reactor TCP时间戳</h2><h3 id="服务器端-1"><a href="#服务器端-1" class="headerlink" title="服务器端"></a>服务器端</h3><figure class="highlight python"><figcaption><span>Twisted Reactor时间戳TCP服务器(tsTservTW.py)</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Twisted Reactor时间戳TCP服务器，使用了Twisted Internet类</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> twisted.internet <span class="keyword">import</span> protocol, reactor</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> ctime</span><br><span class="line"></span><br><span class="line">PORT = <span class="number">21567</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TSServProtocol</span><span class="params">(protocol.Protocol)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">connectionMade</span><span class="params">(self)</span>:</span></span><br><span class="line">        clnt = self.clnt = self.transport.getPeer().host</span><br><span class="line">        print(<span class="string">"...connected from:"</span>, clnt)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dataReceived</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        self.transport.write((<span class="string">"[%s] %s"</span> % (ctime(), data.decode(<span class="string">'utf-8'</span>))).encode(<span class="string">"utf-8"</span>))</span><br><span class="line"></span><br><span class="line">factory = protocol.Factory()</span><br><span class="line">factory.protocol = TSServProtocol</span><br><span class="line">print(<span class="string">"waiting fro connection..."</span>)</span><br><span class="line">reactor.listenTCP(PORT, factory)</span><br><span class="line">reactor.run()</span><br></pre></td></tr></table></figure><h3 id="客户端-1"><a href="#客户端-1" class="headerlink" title="客户端"></a>客户端</h3><figure class="highlight python"><figcaption><span>Twisted Reactor时间戳TCP客户端(tsTclntTW.py)</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Twisted Reactor时间戳TCP客户端</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> twisted.internet <span class="keyword">import</span> protocol, reactor</span><br><span class="line"></span><br><span class="line">PORT = <span class="number">21567</span></span><br><span class="line">HOST = <span class="string">'localhost'</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TSClntProtocol</span><span class="params">(protocol.Protocol)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sendData</span><span class="params">(self)</span>:</span></span><br><span class="line">        data = input(<span class="string">'&gt; '</span>)</span><br><span class="line">        <span class="keyword">if</span> data:</span><br><span class="line">            print(<span class="string">"...sending %s..."</span> % data)</span><br><span class="line">            self.transport.write(data.encode(<span class="string">'utf-8'</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.transport.loseConnection()</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">connectionMade</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.sendData()</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dataReceived</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        print(data.decode())</span><br><span class="line">        self.sendData()</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TSClntFactory</span><span class="params">(protocol.ClientFactory)</span>:</span></span><br><span class="line">    protocol = TSClntProtocol</span><br><span class="line">    clientConnectionLost = clientConnectionFailed = <span class="keyword">lambda</span> self, connector, reason: reactor.stop()</span><br><span class="line"></span><br><span class="line">reactor.connectTCP(HOST, PORT, TSClntFactory())</span><br><span class="line">reactor.run()</span><br></pre></td></tr></table></figure><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>我们用几种方式实现了一个时间戳服务器和客户端,下次我们将学习IO多路复用及python下的<code>select</code>模块</p>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;Socket套接字&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;div class=&quot;note info&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;code&gt;socket&lt;/code&gt;起源于Unix，而Unix/Linux基本哲学之一就是“一切皆文件”，对于文件用【打开】【读写】【关闭】模式来操作。&lt;br&gt;socket就是该模式的一个实现，&lt;code&gt;socket&lt;/code&gt;即是一种特殊的文件，一些socket函数就是对其进行的操作（读/写IO、打开、关闭）&lt;br&gt;&lt;br&gt;- socket和file的区别&lt;br&gt;&lt;br&gt;1. file模块是针对某个指定文件进行【打开】【读写】【关闭】&lt;br&gt;&lt;br&gt;2. socket模块是针对 服务器端 和 客户端 Socket 进行【打开】【读写】【关闭】&lt;br&gt;&lt;br&gt;下面我们通过几种不同方式来实现时间戳服务器端和客户端：&lt;code&gt;TCP&lt;/code&gt;、&lt;code&gt;UDP&lt;/code&gt;、&lt;code&gt;SocketServer TCP&lt;/code&gt;、&lt;code&gt;Twisted Reactor TCP&lt;/code&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="Python" scheme="https://blog.writeathink.cn/categories/Python/"/>
    
    
      <category term="python" scheme="https://blog.writeathink.cn/tags/python/"/>
    
      <category term="socket" scheme="https://blog.writeathink.cn/tags/socket/"/>
    
      <category term="TCP" scheme="https://blog.writeathink.cn/tags/TCP/"/>
    
      <category term="UDP" scheme="https://blog.writeathink.cn/tags/UDP/"/>
    
      <category term="SocketServer" scheme="https://blog.writeathink.cn/tags/SocketServer/"/>
    
      <category term="Twisted" scheme="https://blog.writeathink.cn/tags/Twisted/"/>
    
  </entry>
  
  <entry>
    <title>gRPC简介及其在Python中使用</title>
    <link href="https://blog.writeathink.cn/2018/10/22/gRPC/"/>
    <id>https://blog.writeathink.cn/2018/10/22/gRPC/</id>
    <published>2018-10-22T01:10:35.000Z</published>
    <updated>2018-10-29T08:33:54.741Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p class="description"><br><br></p><p><img src="" alt="" style="width:100%"></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>gRPC  是一个高性能、开源和通用的 RPC 框架，面向移动和 HTTP/2 设计。目前提供 C、Java 和 Go 语言版本，分别是：grpc, grpc-java, grpc-go. 其中 C 版本支持 C, C++, Node.js, Python, Ruby, Objective-C, PHP 和 C# 支持.</p><p>gRPC 基于 HTTP/2 标准设计，带来诸如双向流、流控、头部压缩、单 TCP 连接上的多复用请求等特。这些特性使得其在移动设备上表现更好，更省电和节省空间占用。<br><a id="more"></a></p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><h3 id="gRPC是什么"><a href="#gRPC是什么" class="headerlink" title="gRPC是什么"></a>gRPC是什么</h3><p>在 gRPC 里客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法，使得您能够更容易地创建分布式应用和服务。与许多 RPC 系统类似，gRPC 也是基于以下理念：定义一个服务，指定其能够被远程调用的方法（包含参数和返回类型）。在服务端实现这个接口，并运行一个 gRPC 服务器来处理客户端调用。在客户端拥有一个存根能够像服务端一样的方法。</p><p><img src="http://www.grpc.io/img/grpc_concept_diagram_00.png" alt="grpc_concept_diagram_00"></p><p>gRPC 客户端和服务端可以在多种环境中运行和交互 - 从 google 内部的服务器到你自己的笔记本，并且可以用任何 gRPC 支持的语言来编写。所以，你可以很容易地用 Java 创建一个 gRPC 服务端，用 Go、Python、Ruby 来创建客户端。此外，Google 最新 API 将有 gRPC 版本的接口，使你很容易地将 Google 的功能集成到你的应用里。</p><h3 id="使用protocol-buffers"><a href="#使用protocol-buffers" class="headerlink" title="使用protocol buffers"></a>使用protocol buffers</h3><p>gRPC 默认使用 <code>protocol buffers</code>，这是 Google 开源的一套成熟的<code>结构数据序列化机制</code>（当然也可以使用其他数据格式如 JSON）。正如你将在下方例子里所看到的，你用 proto files 创建 gRPC 服务，用 protocol buffers 消息类型来定义方法参数和返回类型。你可以在 Protocol Buffers 文档找到更多关于 Protocol Buffers 的资料。</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="准备Python环境"><a href="#准备Python环境" class="headerlink" title="准备Python环境"></a>准备Python环境</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ python -m pip install --upgrade pip</span><br><span class="line"></span><br><span class="line">$ python -m pip install virtualenv</span><br><span class="line">$ virtualenv venv</span><br><span class="line">$ <span class="built_in">source</span> venv/bin/activate</span><br><span class="line">$ python -m pip install --upgrade pip</span><br></pre></td></tr></table></figure><h3 id="安装gRPC"><a href="#安装gRPC" class="headerlink" title="安装gRPC"></a>安装gRPC</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在之前激活的虚拟环境下运行</span></span><br><span class="line">pip install grpcio</span><br></pre></td></tr></table></figure><p>同时还要安装gRPC tools:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install grpcio-tools googleapis-common-protos</span><br></pre></td></tr></table></figure><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><h3 id="下载官方例子"><a href="#下载官方例子" class="headerlink" title="下载官方例子"></a>下载官方例子</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone -b v1.15.0 https://github.com/grpc/grpc</span><br><span class="line"># Navigate to the &quot;hello, world&quot; Python example:</span><br><span class="line">$ cd grpc/examples/python/helloworld</span><br></pre></td></tr></table></figure><h3 id="运行一个gRPC应用"><a href="#运行一个gRPC应用" class="headerlink" title="运行一个gRPC应用"></a>运行一个gRPC应用</h3><p>在 <code>examples/python/helloworld</code> 目录中:</p><ol><li>运行服务端：</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python greeter_server.py</span><br></pre></td></tr></table></figure><ol><li>在另一个terminal，运行客户端：</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python greeter_client.py</span><br></pre></td></tr></table></figure><p>Congratulations! You’ve just run a client-server application with gRPC.</p><h2 id="python编写一个RPC服务完整过程"><a href="#python编写一个RPC服务完整过程" class="headerlink" title="python编写一个RPC服务完整过程"></a>python编写一个RPC服务完整过程</h2><h3 id="定义服务"><a href="#定义服务" class="headerlink" title="定义服务"></a>定义服务</h3><p>创建我们例子的第一步是定义一个服务：一个 RPC 服务通过参数和返回类型来指定可以远程调用的方法。 gRPC 通过 <code>protocol buffers</code> 来实现。<br>我们使用 protocol buffers 接口定义语言来定义服务方法，用 protocol buffer 来定义参数和返回类型。客户端和服务端均使用服务定义生成的接口代码。</p><p>这里有我们服务定义的例子，在 <code>helloworld.proto</code> 里用 protocol buffers IDL 定义的。<code>Greeter</code> 服务有一个方法 <code>SayHello</code> ，可以让服务端从远程客户端接收一个包含用户名的 <code>HelloRequest</code> 消息后，在一个 <code>HelloReply</code> 里发送回一个 <code>Greeter</code>。这是你可以在 gRPC 里指定的最简单的 RPC - 你可以在教程里找到针对你选择的语言更多类型的例子。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">syntax = <span class="string">"proto3"</span>;</span><br><span class="line"></span><br><span class="line">option java_multiple_files = <span class="keyword">true</span>;</span><br><span class="line">option java_package = <span class="string">"io.grpc.examples.helloworld"</span>;</span><br><span class="line">option java_outer_classname = <span class="string">"HelloWorldProto"</span>;</span><br><span class="line">option objc_class_prefix = <span class="string">"HLW"</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> helloworld;</span><br><span class="line"></span><br><span class="line"><span class="comment">// The greeting service definition.</span></span><br><span class="line">service Greeter &#123;</span><br><span class="line">  <span class="comment">// Sends a greeting</span></span><br><span class="line">  <span class="function">rpc <span class="title">SayHello</span> <span class="params">(HelloRequest)</span> <span class="title">returns</span> <span class="params">(HelloReply)</span> </span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// The request message containing the user's name.</span></span><br><span class="line">message HelloRequest &#123;</span><br><span class="line">  string name = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// The response message containing the greetings</span></span><br><span class="line">message HelloReply &#123;</span><br><span class="line">  string message = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="生成gRPC"><a href="#生成gRPC" class="headerlink" title="生成gRPC"></a>生成gRPC</h3><p>一旦定义好服务，我们可以使用 protocol buffer 编译器 protoc 来生成创建应用所需的特定客户端和服务端的代码 - 你可以生成任意 gRPC 支持的语言的代码，当然 PHP 和 Objective-C 仅支持创建客户端代码。生成的代码同时包括客户端的存根和服务端要实现的抽象接口，均包含 Greeter 所定义的方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python -m grpc_tools.protoc -I . --python_out=. --grpc_python_out=. helloworld.proto</span><br><span class="line"><span class="comment"># helloworld.proto为上面我们编写的proto文件</span></span><br></pre></td></tr></table></figure><p>这生成了 <code>helloworld_pb2.py</code>和<code>helloworld_pb2_grpc.py</code>两个文件 ，包含我们生成的客户端和服务端类，此外还有用于填充、序列化、提取 HelloRequest 和 HelloResponse 消息类型的类。</p><h3 id="编写服务器端代码"><a href="#编写服务器端代码" class="headerlink" title="编写服务器端代码"></a>编写服务器端代码</h3><h4 id="服务实现"><a href="#服务实现" class="headerlink" title="服务实现"></a>服务实现</h4><p><code>greeter_server.py</code> 实现了 <code>Greeter</code> 服务所需要的行为。<br>正如你所见，Greeter 类通过实现 <code>sayHello</code> 方法，实现了从 proto 服务定义生成的<code>helloworld_pb2.BetaGreeterServicer</code> 接口：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Greeter</span><span class="params">(helloworld_pb2.BetaGreeterServicer)</span>：</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">def</span> <span class="title">SayHello</span><span class="params">(self, request, context)</span>：</span></span><br><span class="line"><span class="class">    <span class="title">return</span> <span class="title">helloworld_pb2</span>.<span class="title">HelloReply</span><span class="params">(message=<span class="string">'Hello, %s!'</span> % request.name)</span></span></span><br></pre></td></tr></table></figure><p>为了返回给客户端应答并且完成调用：</p><p>用我们的激动人心的消息构建并填充一个在我们接口定义的 <code>HelloReply</code> 应答对象。将 HelloReply 返回给客户端。</p><h4 id="服务端实现"><a href="#服务端实现" class="headerlink" title="服务端实现"></a>服务端实现</h4><p>需要提供一个 gRPC 服务的另一个主要功能是让这个服务实在在网络上可用。</p><p>greeter_server.py 提供了以下代码作为 Python 的例子。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">server = helloworld_pb2.beta_create_Greeter_server(Greeter())</span><br><span class="line">server.add_insecure_port(<span class="string">'[：：]：50051'</span>)</span><br><span class="line">server.start()</span><br><span class="line"><span class="keyword">try</span>：</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>：</span><br><span class="line">        time.sleep(_ONE_DAY_IN_SECONDS)</span><br><span class="line"><span class="keyword">except</span> KeyboardInterrupt：</span><br><span class="line">    server.stop()</span><br></pre></td></tr></table></figure><p>在这里我们创建了合理的 gRPC 服务器，将我们实现的 Greeter 服务绑定到一个端口。然后我们启动服务器：服务器现在已准备好从 Greeter 服务客户端接收请求。我们将在具体语言对应的文档里更深入地了解这所有的工作是怎样进行的。</p><h3 id="编写客户端代码"><a href="#编写客户端代码" class="headerlink" title="编写客户端代码"></a>编写客户端代码</h3><h4 id="连接服务"><a href="#连接服务" class="headerlink" title="连接服务"></a>连接服务</h4><p>首先我们看一下我们如何连接 Greeter 服务器。我们需要创建一个 gRPC 频道，指定我们要连接的主机名和服务器端口。然后我们用这个频道创建存根实例。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">channel = implementations.insecure_channel(<span class="string">'localhost'</span>, <span class="number">50051</span>)</span><br><span class="line">stub = helloworld_pb2.beta_create_Greeter_stub(channel)</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h4 id="调用-RPC"><a href="#调用-RPC" class="headerlink" title="调用 RPC"></a>调用 RPC</h4><p>现在我们可以联系服务并获得一个 greeting ：</p><ol><li>我们创建并填充一个 HelloRequest 发送给服务。</li><li>我们用请求调用存根的 SayHello()，如果 RPC 成功，会得到一个填充的 HelloReply ，从其中我们可以获得 greeting。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">response = stub.SayHello(helloworld_pb2.HelloRequest(name=<span class="string">'you'</span>), _TIMEOUT_SECONDS)</span><br><span class="line"><span class="keyword">print</span> <span class="string">"Greeter client received： "</span> + response.message</span><br></pre></td></tr></table></figure><p><code>greeter_client.py</code>完整代码如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> grpc</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> helloworld_pb2</span><br><span class="line"><span class="keyword">import</span> helloworld_pb2_grpc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># NOTE(gRPC Python Team): .close() is possible on a channel and should be</span></span><br><span class="line">    <span class="comment"># used in circumstances in which the with statement does not fit the needs</span></span><br><span class="line">    <span class="comment"># of the code.</span></span><br><span class="line">    <span class="keyword">with</span> grpc.insecure_channel(<span class="string">'localhost:50051'</span>) <span class="keyword">as</span> channel:</span><br><span class="line">        stub = helloworld_pb2_grpc.GreeterStub(channel)</span><br><span class="line">        response = stub.SayHello(helloworld_pb2.HelloRequest(name=<span class="string">'you'</span>))</span><br><span class="line">    print(<span class="string">"Greeter client received: "</span> + response.message)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    run()</span><br></pre></td></tr></table></figure><h3 id="运行并测试服务"><a href="#运行并测试服务" class="headerlink" title="运行并测试服务"></a>运行并测试服务</h3><p>你可以尝试用同一个语言在客户端和服务端构建并运行例子。或者你可以尝试 gRPC 最有用的一个功能 - 不同的语言间的互操作性，即在不同的语言运行客户端和服务端。每个服务端和客户端使用从同一过 proto 文件生成的接口代码，则意味着任何 Greeter 客户端可以与任何 Greeter 服务端对话。</p><ol><li>运行服务端程序,程序会监听 50051端口:</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python route_guide_server.py</span><br></pre></td></tr></table></figure><ol><li>运行客户端程序</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python route_guide_client.py</span><br></pre></td></tr></table></figure><h2 id="grpc-4种通信方式"><a href="#grpc-4种通信方式" class="headerlink" title="grpc: 4种通信方式"></a>grpc: 4种通信方式</h2><p>helloworld 使用了最简单的 grpc 通信方式: 类似 http 协议的一次 request+response.</p><h3 id="4种通信方式"><a href="#4种通信方式" class="headerlink" title="4种通信方式"></a>4种通信方式</h3><p>根据不同的业务场景, grpc 支持 4 种通信方式:</p><ul><li>客服端一次请求, 服务器一次应答</li><li>客服端一次请求, 服务器多次应答(流式)</li><li>客服端多次请求(流式), 服务器一次应答</li><li>客服端多次请求(流式), 服务器多次应答(流式)</li></ul><p>官方提供了一个 route guide service 的 demo, 应用到了这 4 种通信方式, 具体的业务如下:</p><ul><li>数据源: json 格式的数据源, 存储了很多地点, 每个地点由经纬度(point)和地名(location)组成</li><li>通信方式 1: 客户端请求一个地点是否在数据源中</li><li>通信方式 2: 客户端指定一个矩形范围(矩形的对角点坐标), 服务器返回这个范围内的地点信息</li><li>通信方式 3: 客户端给服务器发送多个地点信息, 服务器返回汇总信息(summary)</li><li>通信方式 4: 客户端和服务器使用地点信息 聊天(chat)</li></ul><h3 id="对应的proto文件"><a href="#对应的proto文件" class="headerlink" title="对应的proto文件"></a>对应的proto文件</h3><figure class="highlight java"><figcaption><span>route_guide.proto</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">syntax = <span class="string">"proto3"</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">option java_multiple_files = <span class="keyword">true</span>;</span><br><span class="line">option java_package = <span class="string">"io.grpc.examples.routeguide"</span>;</span><br><span class="line">option java_outer_classname = <span class="string">"RouteGuideProto"</span>;</span><br><span class="line">option objc_class_prefix = <span class="string">"RTG"</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> routeguide;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Interface exported by the server.</span></span><br><span class="line">service RouteGuide &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="function">rpc <span class="title">GetFeature</span><span class="params">(Point)</span> <span class="title">returns</span> <span class="params">(Feature)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">rpc <span class="title">ListFeatures</span><span class="params">(Rectangle)</span> <span class="title">returns</span> <span class="params">(stream Feature)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">rpc <span class="title">RecordRoute</span><span class="params">( stream Point)</span> <span class="title">returns</span> <span class="params">(RouteSummary)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">rpc <span class="title">RouteChat</span><span class="params">(stream RouteNote)</span> <span class="title">returns</span> <span class="params">(stream RouteNote)</span> </span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">message Point &#123;</span><br><span class="line">    int32 latitude = <span class="number">1</span>;</span><br><span class="line">    int32 longitude = <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">message Rectangle &#123;</span><br><span class="line">    Point lo = <span class="number">1</span>;</span><br><span class="line">    Point hi = <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">message Feature &#123;</span><br><span class="line">    string name = <span class="number">1</span>;</span><br><span class="line">    Point location = <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">message RouteNote &#123;</span><br><span class="line">    Point location = <span class="number">1</span>;</span><br><span class="line">    string message = <span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">message RouteSummary &#123;</span><br><span class="line">    int32 point_count = <span class="number">1</span>;</span><br><span class="line">    int32 feature_count = <span class="number">2</span>;</span><br><span class="line">    int32 distance = <span class="number">3</span>;</span><br><span class="line">    int32 elapsed_time = <span class="number">4</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>proto 中想要表示流式传输, 只需要添加 <code>stream</code> 关键字即可</p><p>同样的, 使用 <code>protoc</code> 生成代码:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m grpc_tools.protoc --python_out=. --grpc_python_out=. -I. route_guide.proto</span><br></pre></td></tr></table></figure><p>生成了 <code>route_guide_pb2.py</code> 和<code>route_guide_pb2_grpc.py</code> 文件</p><h3 id="处理数据源文件-route-guide-db-json"><a href="#处理数据源文件-route-guide-db-json" class="headerlink" title="处理数据源文件(route_guide_db.json)"></a>处理数据源文件(route_guide_db.json)</h3><figure class="highlight py"><figcaption><span>route_guide_db.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> route_guide_pb2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_route_guide_db</span><span class="params">()</span>:</span></span><br><span class="line">    feature_list = []</span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'route_guide_db.json'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> json.load(f):</span><br><span class="line">            feature = route_guide_pb2.Feature(name=item[<span class="string">'name'</span>],</span><br><span class="line">                                              location=route_guide_pb2.Point(latitude=item[<span class="string">'location'</span>][<span class="string">'latitude'</span>],</span><br><span class="line">                                                                             longitude=item[<span class="string">'location'</span>][<span class="string">'longitude'</span>]))</span><br><span class="line">            feature_list.append(feature)</span><br><span class="line">    <span class="keyword">return</span> feature_list</span><br></pre></td></tr></table></figure><p>处理 json 的过程很简单, 解析 json 数据得到由坐标点组成的数组</p><p>怎么处理流式数据呢?. 答案是 <code>for ... in</code> + <code>yield</code></p><h3 id="完整服务器端代码"><a href="#完整服务器端代码" class="headerlink" title="完整服务器端代码"></a>完整服务器端代码</h3><figure class="highlight python"><figcaption><span>route_guide_server.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""The Python implementation of the gRPC route guide server."""</span></span><br><span class="line"><span class="keyword">from</span> concurrent <span class="keyword">import</span> futures</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> grpc</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> route_guide_pb2</span><br><span class="line"><span class="keyword">import</span> route_guide_pb2_grpc</span><br><span class="line"><span class="keyword">import</span> route_guide_db</span><br><span class="line"></span><br><span class="line">_ONE_DAY_IN_SECONDS = <span class="number">60</span> * <span class="number">60</span> * <span class="number">24</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_feature</span><span class="params">(feature_db, point)</span>:</span></span><br><span class="line">    <span class="string">"""returns feature at given location or None"""</span></span><br><span class="line">    <span class="keyword">for</span> feature <span class="keyword">in</span> feature_db:</span><br><span class="line">        <span class="keyword">if</span> feature.location == point:</span><br><span class="line">            <span class="keyword">return</span> feature</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_distance</span><span class="params">(start, end)</span>:</span></span><br><span class="line">    <span class="string">"""Distance between two points."""</span></span><br><span class="line">    coord_factor = <span class="number">10000000.0</span></span><br><span class="line">    lat_1 = start.latitude / coord_factor</span><br><span class="line">    lat_2 = end.latitude / coord_factor</span><br><span class="line">    lon_1 = start.longitude / coord_factor</span><br><span class="line">    lon_2 = end.longitude / coord_factor</span><br><span class="line"></span><br><span class="line">    lat_rad_1 = math.radians(lat_1)</span><br><span class="line">    lat_rad_2 = math.radians(lat_2)</span><br><span class="line">    delta_lat_rad = math.radians(lat_2 - lat_1)</span><br><span class="line">    delta_lon_rad = math.radians(lon_2 - lon_2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Formula is based on http://mathforum.org/library/drmath/view/51879.html</span></span><br><span class="line">    a = (pow(math.sin(delta_lat_rad / <span class="number">2</span>), <span class="number">2</span>) +</span><br><span class="line">         (math.cos(lat_rad_1) * math.cos(lat_rad_2) * pow(math.sin(delta_lon_rad / <span class="number">2</span>), <span class="number">2</span>)))</span><br><span class="line">    c = <span class="number">2</span> * math.atan2(math.sqrt(a), math.sqrt(<span class="number">1</span> - a))</span><br><span class="line">    R = <span class="number">6371000</span></span><br><span class="line">    <span class="keyword">return</span> R * c</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RouteGuideServicer</span><span class="params">(route_guide_pb2_grpc.RouteGuideServicer)</span>:</span></span><br><span class="line">    <span class="string">"""Provides methods that implement functionality of route guide server."""</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.db = route_guide_db.read_route_guide_db()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">GetFeature</span><span class="params">(self, request, context)</span>:</span></span><br><span class="line">        feature = get_feature(self.db, request)</span><br><span class="line">        <span class="keyword">if</span> feature <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span> route_guide_pb2.Feature(name=<span class="string">""</span>, location=request)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> feature</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">ListFeatures</span><span class="params">(self, request, context)</span>:</span></span><br><span class="line">        left = min(request.lo.longitude, request.hi.longitude)</span><br><span class="line">        right = max(request.lo.longitude, request.hi.longitude)</span><br><span class="line">        top = max(request.lo.latitude, request.hi.latitude)</span><br><span class="line">        bottom = min(request.lo.latitude, request.hi.latitude)</span><br><span class="line">        <span class="keyword">for</span> feature <span class="keyword">in</span> self.db:</span><br><span class="line">            <span class="keyword">if</span>(feature.location.longitude &gt;= left <span class="keyword">and</span></span><br><span class="line">                feature.location.longitude &lt;=right <span class="keyword">and</span></span><br><span class="line">                feature.location.latitude &gt;= bottom <span class="keyword">and</span></span><br><span class="line">                feature.location.latitude &lt;= top):</span><br><span class="line">                <span class="keyword">yield</span> feature</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">RecordRoute</span><span class="params">(self, request_iterator, context)</span>:</span></span><br><span class="line">        point_count = <span class="number">0</span></span><br><span class="line">        feature_count = <span class="number">0</span></span><br><span class="line">        distance = <span class="number">0.0</span></span><br><span class="line">        prev_point = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">        start_time = time.time()</span><br><span class="line">        <span class="keyword">for</span> point <span class="keyword">in</span> request_iterator:</span><br><span class="line">            point_count += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> get_feature(self.db, point):</span><br><span class="line">                feature_count += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> prev_point:</span><br><span class="line">                distance += get_distance(prev_point, point)</span><br><span class="line">            prev_point = point</span><br><span class="line"></span><br><span class="line">        elapsed_time = time.time() - start_time</span><br><span class="line">        <span class="keyword">return</span> route_guide_pb2.RouteSummary(</span><br><span class="line">            point_count=point_count,</span><br><span class="line">            feature_count=feature_count,</span><br><span class="line">            distance=int(distance),</span><br><span class="line">            elapsed_time=int(elapsed_time))</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">RouteChat</span><span class="params">(self, request_iterator, context)</span>:</span></span><br><span class="line">        prev_notes = []</span><br><span class="line">        <span class="keyword">for</span> new_note <span class="keyword">in</span> request_iterator:</span><br><span class="line">            <span class="keyword">for</span> prev_note <span class="keyword">in</span> prev_notes:</span><br><span class="line">                <span class="keyword">if</span> prev_note.location == new_note.location:</span><br><span class="line">                    <span class="keyword">yield</span> prev_note</span><br><span class="line">            prev_notes.append(new_note)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">serve</span><span class="params">()</span>:</span></span><br><span class="line">    server = grpc.server(futures.ThreadPoolExecutor(max_workers=<span class="number">10</span>))</span><br><span class="line">    route_guide_pb2_grpc.add_RouteGuideServicer_to_server(RouteGuideServicer(), server)</span><br><span class="line">    server.add_insecure_port(<span class="string">'[::]:50051'</span>)</span><br><span class="line">    server.start()</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">            time.sleep(_ONE_DAY_IN_SECONDS)</span><br><span class="line">    <span class="keyword">except</span> KeyboardInterrupt:</span><br><span class="line">        server.stop(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">"route guide server is running..."</span>)</span><br><span class="line">    serve()</span><br></pre></td></tr></table></figure><h3 id="完整客户端代码"><a href="#完整客户端代码" class="headerlink" title="完整客户端代码"></a>完整客户端代码</h3><figure class="highlight python"><figcaption><span>route_guide_client.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""The Python implementation of the gRPC route guide client."""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> grpc</span><br><span class="line"><span class="keyword">import</span> route_guide_pb2</span><br><span class="line"><span class="keyword">import</span> route_guide_pb2_grpc</span><br><span class="line"><span class="keyword">import</span> route_guide_db</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_route_note</span><span class="params">(message, latitude, longitude)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> route_guide_pb2.RouteNote(</span><br><span class="line">        message=message,</span><br><span class="line">        location=route_guide_pb2.Point(latitude=latitude, longitude=longitude)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">guide_get_one_feature</span><span class="params">(stub, point)</span>:</span></span><br><span class="line">    feature = stub.GetFeature(point)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> feature.location:</span><br><span class="line">        print(<span class="string">"server returned incomplete feature"</span>)</span><br><span class="line">        <span class="keyword">return</span> </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> feature.name:</span><br><span class="line">        print(<span class="string">"Feature called %s at %s"</span> % (feature.name, feature.location))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">"Found no feature at %s"</span> % feature.location)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">guide_get_feature</span><span class="params">(stub)</span>:</span></span><br><span class="line">    guide_get_one_feature(stub,</span><br><span class="line">        route_guide_pb2.Point(latitude=<span class="number">409146138</span>, longitude=<span class="number">-746188906</span>))</span><br><span class="line">    guide_get_one_feature(stub, route_guide_pb2.Point(latitude=<span class="number">0</span>, longitude=<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">guide_list_features</span><span class="params">(stub)</span>:</span></span><br><span class="line">    rectangle = route_guide_pb2.Rectangle(</span><br><span class="line">        lo=route_guide_pb2.Point(latitude=<span class="number">400000000</span>, longitude=<span class="number">-750000000</span>),</span><br><span class="line">        hi=route_guide_pb2.Point(latitude=<span class="number">420000000</span>, longitude=<span class="number">-730000000</span>))</span><br><span class="line">    print(<span class="string">"looking for features between 40, -75 and 42, -73"</span>)</span><br><span class="line"></span><br><span class="line">    features = stub.ListFeatures(rectangle)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> feature <span class="keyword">in</span> features:</span><br><span class="line">        print(<span class="string">"Feature called %s at %s"</span> % (feature.name, feature.location))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_route</span><span class="params">(feature_list)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">10</span>):</span><br><span class="line">        random_feature = feature_list[random.randint(<span class="number">0</span>, len(feature_list))]</span><br><span class="line">        print(<span class="string">"Visiting point %s"</span> % random_feature.location)</span><br><span class="line">        <span class="keyword">yield</span> random_feature.location</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">guide_record_route</span><span class="params">(stub)</span>:</span></span><br><span class="line">    feature_list = route_guide_db.read_route_guide_db()</span><br><span class="line"></span><br><span class="line">    route_iterator = generate_route(feature_list)</span><br><span class="line">    route_summary = stub.RecordRoute(route_iterator)</span><br><span class="line">    print(<span class="string">"Finished trip with %s points "</span> % route_summary.point_count)</span><br><span class="line">    print(<span class="string">"Passed %s features "</span> % route_summary.feature_count)</span><br><span class="line">    print(<span class="string">"Travelled %s meters "</span> % route_summary.distance)</span><br><span class="line">    print(<span class="string">"It took %s seconds "</span> % route_summary.elapsed_time)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_messages</span><span class="params">()</span>:</span></span><br><span class="line">    messages = [</span><br><span class="line">        make_route_note(<span class="string">"First message"</span>, <span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">        make_route_note(<span class="string">"Second message"</span>, <span class="number">0</span>, <span class="number">1</span>),</span><br><span class="line">        make_route_note(<span class="string">"Third message"</span>, <span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">        make_route_note(<span class="string">"Fourth message"</span>, <span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">        make_route_note(<span class="string">"Fifth message"</span>, <span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> msg <span class="keyword">in</span> messages:</span><br><span class="line">        print(<span class="string">"Sending %s at %s"</span> % (msg.message, msg.location))</span><br><span class="line">        <span class="keyword">yield</span> msg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">guide_route_chat</span><span class="params">(stub)</span>:</span></span><br><span class="line">    responses = stub.RouteChat(generate_messages())</span><br><span class="line">    <span class="keyword">for</span> response <span class="keyword">in</span> responses:</span><br><span class="line">        print(<span class="string">"Received message %s at %s"</span> % (response.message, response.location))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">with</span> grpc.insecure_channel(<span class="string">'localhost:50051'</span>) <span class="keyword">as</span> channel:</span><br><span class="line">        stub = route_guide_pb2_grpc.RouteGuideStub(channel)</span><br><span class="line">        print(<span class="string">"-------------- GetFeature --------------"</span>)</span><br><span class="line">        guide_get_feature(stub)</span><br><span class="line">        print(<span class="string">"-------------- ListFeatures --------------"</span>)</span><br><span class="line">        guide_list_features(stub)</span><br><span class="line">        print(<span class="string">"-------------- RecordRoute --------------"</span>)</span><br><span class="line">        guide_record_route(stub)</span><br><span class="line">        print(<span class="string">"-------------- RouteChat --------------"</span>)</span><br><span class="line">        guide_route_chat(stub)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    run()</span><br></pre></td></tr></table></figure><h3 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br></pre></td><td class="code"><pre><span class="line">-------------- GetFeature --------------</span><br><span class="line">Feature called Berkshire Valley Management Area Trail, Jefferson, NJ, USA at latitude: 409146138</span><br><span class="line">longitude: -746188906</span><br><span class="line"></span><br><span class="line">Found no feature at</span><br><span class="line">-------------- ListFeatures --------------</span><br><span class="line">looking for features between 40, -75 and 42, -73</span><br><span class="line">Feature called Patriots Path, Mendham, NJ 07945, USA at latitude: 407838351</span><br><span class="line">longitude: -746143763</span><br><span class="line"></span><br><span class="line">Feature called 101 New Jersey 10, Whippany, NJ 07981, USA at latitude: 408122808</span><br><span class="line">longitude: -743999179</span><br><span class="line"></span><br><span class="line">Feature called U.S. 6, Shohola, PA 18458, USA at latitude: 413628156</span><br><span class="line">longitude: -749015468</span><br><span class="line"></span><br><span class="line">Feature called 5 Conners Road, Kingston, NY 12401, USA at latitude: 419999544</span><br><span class="line">longitude: -740371136</span><br><span class="line"></span><br><span class="line">Feature called Mid Hudson Psychiatric Center, New Hampton, NY 10958, USA at latitude: 414008389</span><br><span class="line">longitude: -743951297</span><br><span class="line"></span><br><span class="line">Feature called 287 Flugertown Road, Livingston Manor, NY 12758, USA at latitude: 419611318</span><br><span class="line">longitude: -746524769</span><br><span class="line"></span><br><span class="line">Feature called 4001 Tremley Point Road, Linden, NJ 07036, USA at latitude: 406109563</span><br><span class="line">longitude: -742186778</span><br><span class="line"></span><br><span class="line">Feature called 352 South Mountain Road, Wallkill, NY 12589, USA at latitude: 416802456</span><br><span class="line">longitude: -742370183</span><br><span class="line"></span><br><span class="line">Feature called Bailey Turn Road, Harriman, NY 10926, USA at latitude: 412950425</span><br><span class="line">longitude: -741077389</span><br><span class="line"></span><br><span class="line">Feature called 193-199 Wawayanda Road, Hewitt, NJ 07421, USA at latitude: 412144655</span><br><span class="line">longitude: -743949739</span><br><span class="line"></span><br><span class="line">Feature called 406-496 Ward Avenue, Pine Bush, NY 12566, USA at latitude: 415736605</span><br><span class="line">longitude: -742847522</span><br><span class="line"></span><br><span class="line">Feature called 162 Merrill Road, Highland Mills, NY 10930, USA at latitude: 413843930</span><br><span class="line">longitude: -740501726</span><br><span class="line"></span><br><span class="line">Feature called Clinton Road, West Milford, NJ 07480, USA at latitude: 410873075</span><br><span class="line">longitude: -744459023</span><br><span class="line"></span><br><span class="line">Feature called 16 Old Brook Lane, Warwick, NY 10990, USA at latitude: 412346009</span><br><span class="line">longitude: -744026814</span><br><span class="line"></span><br><span class="line">Feature called 3 Drake Lane, Pennington, NJ 08534, USA at latitude: 402948455</span><br><span class="line">longitude: -747903913</span><br><span class="line"></span><br><span class="line">Feature called 6324 8th Avenue, Brooklyn, NY 11220, USA at latitude: 406337092</span><br><span class="line">longitude: -740122226</span><br><span class="line"></span><br><span class="line">Feature called 1 Merck Access Road, Whitehouse Station, NJ 08889, USA at latitude: 406421967</span><br><span class="line">longitude: -747727624</span><br><span class="line"></span><br><span class="line">Feature called 78-98 Schalck Road, Narrowsburg, NY 12764, USA at latitude: 416318082</span><br><span class="line">longitude: -749677716</span><br><span class="line"></span><br><span class="line">Feature called 282 Lakeview Drive Road, Highland Lake, NY 12743, USA at latitude: 415301720</span><br><span class="line">longitude: -748416257</span><br><span class="line"></span><br><span class="line">Feature called 330 Evelyn Avenue, Hamilton Township, NJ 08619, USA at latitude: 402647019</span><br><span class="line">longitude: -747071791</span><br><span class="line"></span><br><span class="line">Feature called New York State Reference Route 987E, Southfields, NY 10975, USA at latitude: 412567807</span><br><span class="line">longitude: -741058078</span><br><span class="line"></span><br><span class="line">Feature called 103-271 Tempaloni Road, Ellenville, NY 12428, USA at latitude: 416855156</span><br><span class="line">longitude: -744420597</span><br><span class="line"></span><br><span class="line">Feature called 1300 Airport Road, North Brunswick Township, NJ 08902, USA at latitude: 404663628</span><br><span class="line">longitude: -744820157</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 407113723</span><br><span class="line">longitude: -749746483</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 402133926</span><br><span class="line">longitude: -743613249</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 400273442</span><br><span class="line">longitude: -741220915</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 411236786</span><br><span class="line">longitude: -744070769</span><br><span class="line"></span><br><span class="line">Feature called 211-225 Plains Road, Augusta, NJ 07822, USA at latitude: 411633782</span><br><span class="line">longitude: -746784970</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 415830701</span><br><span class="line">longitude: -742952812</span><br><span class="line"></span><br><span class="line">Feature called 165 Pedersen Ridge Road, Milford, PA 18337, USA at latitude: 413447164</span><br><span class="line">longitude: -748712898</span><br><span class="line"></span><br><span class="line">Feature called 100-122 Locktown Road, Frenchtown, NJ 08825, USA at latitude: 405047245</span><br><span class="line">longitude: -749800722</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 418858923</span><br><span class="line">longitude: -746156790</span><br><span class="line"></span><br><span class="line">Feature called 650-652 Willi Hill Road, Swan Lake, NY 12783, USA at latitude: 417951888</span><br><span class="line">longitude: -748484944</span><br><span class="line"></span><br><span class="line">Feature called 26 East 3rd Street, New Providence, NJ 07974, USA at latitude: 407033786</span><br><span class="line">longitude: -743977337</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 417548014</span><br><span class="line">longitude: -740075041</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 410395868</span><br><span class="line">longitude: -744972325</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 404615353</span><br><span class="line">longitude: -745129803</span><br><span class="line"></span><br><span class="line">Feature called 611 Lawrence Avenue, Westfield, NJ 07090, USA at latitude: 406589790</span><br><span class="line">longitude: -743560121</span><br><span class="line"></span><br><span class="line">Feature called 18 Lannis Avenue, New Windsor, NY 12553, USA at latitude: 414653148</span><br><span class="line">longitude: -740477477</span><br><span class="line"></span><br><span class="line">Feature called 82-104 Amherst Avenue, Colonia, NJ 07067, USA at latitude: 405957808</span><br><span class="line">longitude: -743255336</span><br><span class="line"></span><br><span class="line">Feature called 170 Seven Lakes Drive, Sloatsburg, NY 10974, USA at latitude: 411733589</span><br><span class="line">longitude: -741648093</span><br><span class="line"></span><br><span class="line">Feature called 1270 Lakes Road, Monroe, NY 10950, USA at latitude: 412676291</span><br><span class="line">longitude: -742606606</span><br><span class="line"></span><br><span class="line">Feature called 509-535 Alphano Road, Great Meadows, NJ 07838, USA at latitude: 409224445</span><br><span class="line">longitude: -748286738</span><br><span class="line"></span><br><span class="line">Feature called 652 Garden Street, Elizabeth, NJ 07202, USA at latitude: 406523420</span><br><span class="line">longitude: -742135517</span><br><span class="line"></span><br><span class="line">Feature called 349 Sea Spray Court, Neptune City, NJ 07753, USA at latitude: 401827388</span><br><span class="line">longitude: -740294537</span><br><span class="line"></span><br><span class="line">Feature called 13-17 Stanley Street, West Milford, NJ 07480, USA at latitude: 410564152</span><br><span class="line">longitude: -743685054</span><br><span class="line"></span><br><span class="line">Feature called 47 Industrial Avenue, Teterboro, NJ 07608, USA at latitude: 408472324</span><br><span class="line">longitude: -740726046</span><br><span class="line"></span><br><span class="line">Feature called 5 White Oak Lane, Stony Point, NY 10980, USA at latitude: 412452168</span><br><span class="line">longitude: -740214052</span><br><span class="line"></span><br><span class="line">Feature called Berkshire Valley Management Area Trail, Jefferson, NJ, USA at latitude: 409146138</span><br><span class="line">longitude: -746188906</span><br><span class="line"></span><br><span class="line">Feature called 1007 Jersey Avenue, New Brunswick, NJ 08901, USA at latitude: 404701380</span><br><span class="line">longitude: -744781745</span><br><span class="line"></span><br><span class="line">Feature called 6 East Emerald Isle Drive, Lake Hopatcong, NJ 07849, USA at latitude: 409642566</span><br><span class="line">longitude: -746017679</span><br><span class="line"></span><br><span class="line">Feature called 1358-1474 New Jersey 57, Port Murray, NJ 07865, USA at latitude: 408031728</span><br><span class="line">longitude: -748645385</span><br><span class="line"></span><br><span class="line">Feature called 367 Prospect Road, Chester, NY 10918, USA at latitude: 413700272</span><br><span class="line">longitude: -742135189</span><br><span class="line"></span><br><span class="line">Feature called 10 Simon Lake Drive, Atlantic Highlands, NJ 07716, USA at latitude: 404310607</span><br><span class="line">longitude: -740282632</span><br><span class="line"></span><br><span class="line">Feature called 11 Ward Street, Mount Arlington, NJ 07856, USA at latitude: 409319800</span><br><span class="line">longitude: -746201391</span><br><span class="line"></span><br><span class="line">Feature called 300-398 Jefferson Avenue, Elizabeth, NJ 07201, USA at latitude: 406685311</span><br><span class="line">longitude: -742108603</span><br><span class="line"></span><br><span class="line">Feature called 43 Dreher Road, Roscoe, NY 12776, USA at latitude: 419018117</span><br><span class="line">longitude: -749142781</span><br><span class="line"></span><br><span class="line">Feature called Swan Street, Pine Island, NY 10969, USA at latitude: 412856162</span><br><span class="line">longitude: -745148837</span><br><span class="line"></span><br><span class="line">Feature called 66 Pleasantview Avenue, Monticello, NY 12701, USA at latitude: 416560744</span><br><span class="line">longitude: -746721964</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 405314270</span><br><span class="line">longitude: -749836354</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 414219548</span><br><span class="line">longitude: -743327440</span><br><span class="line"></span><br><span class="line">Feature called 565 Winding Hills Road, Montgomery, NY 12549, USA at latitude: 415534177</span><br><span class="line">longitude: -742900616</span><br><span class="line"></span><br><span class="line">Feature called 231 Rocky Run Road, Glen Gardner, NJ 08826, USA at latitude: 406898530</span><br><span class="line">longitude: -749127080</span><br><span class="line"></span><br><span class="line">Feature called 100 Mount Pleasant Avenue, Newark, NJ 07104, USA at latitude: 407586880</span><br><span class="line">longitude: -741670168</span><br><span class="line"></span><br><span class="line">Feature called 517-521 Huntington Drive, Manchester Township, NJ 08759, USA at latitude: 400106455</span><br><span class="line">longitude: -742870190</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 400066188</span><br><span class="line">longitude: -746793294</span><br><span class="line"></span><br><span class="line">Feature called 40 Mountain Road, Napanoch, NY 12458, USA at latitude: 418803880</span><br><span class="line">longitude: -744102673</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 414204288</span><br><span class="line">longitude: -747895140</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 414777405</span><br><span class="line">longitude: -740615601</span><br><span class="line"></span><br><span class="line">Feature called 48 North Road, Forestburgh, NY 12777, USA at latitude: 415464475</span><br><span class="line">longitude: -747175374</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 404062378</span><br><span class="line">longitude: -746376177</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 405688272</span><br><span class="line">longitude: -749285130</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 400342070</span><br><span class="line">longitude: -748788996</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 401809022</span><br><span class="line">longitude: -744157964</span><br><span class="line"></span><br><span class="line">Feature called 9 Thompson Avenue, Leonardo, NJ 07737, USA at latitude: 404226644</span><br><span class="line">longitude: -740517141</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 410322033</span><br><span class="line">longitude: -747871659</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 407100674</span><br><span class="line">longitude: -747742727</span><br><span class="line"></span><br><span class="line">Feature called 213 Bush Road, Stone Ridge, NY 12484, USA at latitude: 418811433</span><br><span class="line">longitude: -741718005</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 415034302</span><br><span class="line">longitude: -743850945</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 411349992</span><br><span class="line">longitude: -743694161</span><br><span class="line"></span><br><span class="line">Feature called 1-17 Bergen Court, New Brunswick, NJ 08901, USA at latitude: 404839914</span><br><span class="line">longitude: -744759616</span><br><span class="line"></span><br><span class="line">Feature called 35 Oakland Valley Road, Cuddebackville, NY 12729, USA at latitude: 414638017</span><br><span class="line">longitude: -745957854</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 412127800</span><br><span class="line">longitude: -740173578</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 401263460</span><br><span class="line">longitude: -747964303</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 412843391</span><br><span class="line">longitude: -749086026</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 418512773</span><br><span class="line">longitude: -743067823</span><br><span class="line"></span><br><span class="line">Feature called 42-102 Main Street, Belford, NJ 07718, USA at latitude: 404318328</span><br><span class="line">longitude: -740835638</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 419020746</span><br><span class="line">longitude: -741172328</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 404080723</span><br><span class="line">longitude: -746119569</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 401012643</span><br><span class="line">longitude: -744035134</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 404306372</span><br><span class="line">longitude: -741079661</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 403966326</span><br><span class="line">longitude: -748519297</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 405002031</span><br><span class="line">longitude: -748407866</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 409532885</span><br><span class="line">longitude: -742200683</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 416851321</span><br><span class="line">longitude: -742674555</span><br><span class="line"></span><br><span class="line">Feature called 3387 Richmond Terrace, Staten Island, NY 10303, USA at latitude: 406411633</span><br><span class="line">longitude: -741722051</span><br><span class="line"></span><br><span class="line">Feature called 261 Van Sickle Road, Goshen, NY 10924, USA at latitude: 413069058</span><br><span class="line">longitude: -744597778</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 418465462</span><br><span class="line">longitude: -746859398</span><br><span class="line"></span><br><span class="line">Feature called  at latitude: 411733222</span><br><span class="line">longitude: -744228360</span><br><span class="line"></span><br><span class="line">Feature called 3 Hasta Way, Newton, NJ 07860, USA at latitude: 410248224</span><br><span class="line">longitude: -747127767</span><br><span class="line"></span><br><span class="line">-------------- RecordRoute --------------</span><br><span class="line">Visiting point latitude: 405002031</span><br><span class="line">longitude: -748407866</span><br><span class="line"></span><br><span class="line">Visiting point latitude: 400106455</span><br><span class="line">longitude: -742870190</span><br><span class="line"></span><br><span class="line">Visiting point latitude: 409532885</span><br><span class="line">longitude: -742200683</span><br><span class="line"></span><br><span class="line">Visiting point latitude: 413628156</span><br><span class="line">longitude: -749015468</span><br><span class="line"></span><br><span class="line">Visiting point latitude: 413700272</span><br><span class="line">longitude: -742135189</span><br><span class="line"></span><br><span class="line">Visiting point latitude: 406523420</span><br><span class="line">longitude: -742135517</span><br><span class="line"></span><br><span class="line">Visiting point latitude: 400273442</span><br><span class="line">longitude: -741220915</span><br><span class="line"></span><br><span class="line">Visiting point latitude: 400066188</span><br><span class="line">longitude: -746793294</span><br><span class="line"></span><br><span class="line">Visiting point latitude: 415034302</span><br><span class="line">longitude: -743850945</span><br><span class="line"></span><br><span class="line">Visiting point latitude: 412567807</span><br><span class="line">longitude: -741058078</span><br><span class="line"></span><br><span class="line">Finished trip with 10 points</span><br><span class="line">Passed 10 features</span><br><span class="line">Travelled 551060 meters</span><br><span class="line">It took 0 seconds</span><br><span class="line">-------------- RouteChat --------------</span><br><span class="line">Sending First message at</span><br><span class="line">Sending Second message at longitude: 1</span><br><span class="line"></span><br><span class="line">Sending Third message at latitude: 1</span><br><span class="line"></span><br><span class="line">Sending Fourth message at</span><br><span class="line">Sending Fifth message at latitude: 1</span><br><span class="line"></span><br><span class="line">Received message First message at</span><br><span class="line">Received message Third message at latitude: 1</span><br></pre></td></tr></table></figure><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文主要介绍了grpc下python的基本运行方式，以及grpc的四种通信方式。</p>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;gRPC  是一个高性能、开源和通用的 RPC 框架，面向移动和 HTTP/2 设计。目前提供 C、Java 和 Go 语言版本，分别是：grpc, grpc-java, grpc-go. 其中 C 版本支持 C, C++, Node.js, Python, Ruby, Objective-C, PHP 和 C# 支持.&lt;/p&gt;
&lt;p&gt;gRPC 基于 HTTP/2 标准设计，带来诸如双向流、流控、头部压缩、单 TCP 连接上的多复用请求等特。这些特性使得其在移动设备上表现更好，更省电和节省空间占用。&lt;br&gt;
    
    </summary>
    
      <category term="Python" scheme="https://blog.writeathink.cn/categories/Python/"/>
    
    
      <category term="python" scheme="https://blog.writeathink.cn/tags/python/"/>
    
      <category term="RPC" scheme="https://blog.writeathink.cn/tags/RPC/"/>
    
      <category term="分布式" scheme="https://blog.writeathink.cn/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="微服务" scheme="https://blog.writeathink.cn/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>MySQL-Datamask-ProxySQL</title>
    <link href="https://blog.writeathink.cn/2018/07/31/MySQL-Datamask-ProxySQL/"/>
    <id>https://blog.writeathink.cn/2018/07/31/MySQL-Datamask-ProxySQL/</id>
    <published>2018-07-31T01:59:54.000Z</published>
    <updated>2018-10-23T02:17:11.228Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p class="description">MySQL datamasking using ProxySQL<br></p><p><img src="" alt="" style="width:100%"></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><div class="note info"><p><br><br>操作环境一览:<br><br>- 操作系统： CentOS7<br><br>- MySQL: 5.5<br><br>- ProxySQL: 1.4.9<br><br>- ProxySQL主机IP: 192.168.48.100<br><br>- MySQL主库IP: 192.168.48.120<br><br></p></div><a id="more"></a><h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><h3 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h3><ul><li>一张带有信用卡信息(faked)等敏感信息的顾客表，</li><li>开发、测试用户并不真正需要信用卡号的等敏感信息。</li></ul><h3 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h3><ul><li>开发测试用户能够通过ProxySQL访问数据</li><li>开发测试用户能够访问所有列，但是带有敏感信息的需要隐藏</li><li>开发测试用户不能在特定表上执行SELECT *操作</li></ul><p>顾客表示例：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+<span class="comment">----+-----------+-------------+------------+------------------+----------+</span></span><br><span class="line">| id | firstname | lastname    | cc_type    | cc_num           | cc_verif |</span><br><span class="line">+<span class="comment">----+-----------+-------------+------------+------------------+----------+</span></span><br><span class="line">|  1 | Frederic  | Descamps    | mastercard | 5275653223285289 |      456 |</span><br><span class="line">|  8 | Dim0      | Vanoverbeke | mastercard | 5345654523285289 |      123 |</span><br><span class="line">| 15 | Kenny     |  Gryp       |  visa      | 4916066793184589 |      456 |</span><br><span class="line">+<span class="comment">----+-----------+-------------+------------+------------------+----------+</span></span><br></pre></td></tr></table></figure><p>我们可以在后端mysql主库上(192.168.48.120)创建该测试顾客表:</p><ul><li>创建账号</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">'proxysql'</span>@<span class="string">'192.168.48.120'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'123456'</span>;</span><br></pre></td></tr></table></figure><ul><li>创建表</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> <span class="keyword">test</span>;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> customers</span><br><span class="line">(</span><br><span class="line">  <span class="keyword">id</span> <span class="built_in">int</span>(<span class="number">3</span>) <span class="keyword">not</span> <span class="literal">null</span> primary <span class="keyword">key</span>,</span><br><span class="line">  firstname <span class="built_in">varchar</span>(<span class="number">20</span>) <span class="keyword">not</span> <span class="literal">null</span>,</span><br><span class="line">  lastname <span class="built_in">varchar</span>(<span class="number">20</span>) <span class="keyword">not</span> <span class="literal">null</span>,</span><br><span class="line">  cc_type <span class="built_in">varchar</span>(<span class="number">20</span>) <span class="keyword">not</span> <span class="literal">null</span>,</span><br><span class="line">  cc_num <span class="built_in">varchar</span>(<span class="number">50</span>) <span class="keyword">not</span> <span class="literal">null</span>,</span><br><span class="line">  cc_verif <span class="built_in">int</span>(<span class="number">3</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><ul><li>授权</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> ALL <span class="keyword">ON</span> test.customers <span class="keyword">TO</span> <span class="string">'proxysql'</span>@<span class="string">'192.168.48.120'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">FLUSH</span> <span class="keyword">PRIVILEGES</span>;</span><br></pre></td></tr></table></figure><h2 id="ProxySQL"><a href="#ProxySQL" class="headerlink" title="ProxySQL"></a>ProxySQL</h2><h3 id="安装ProxySQL"><a href="#安装ProxySQL" class="headerlink" title="安装ProxySQL"></a>安装ProxySQL</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">proxysql需要依赖一些perl库，所以使用yum安装</span></span><br><span class="line">wget https://github.com/sysown/proxysql/releases/download/v1.4.9/proxysql-1.4.9-3-centos7.x86_64.rpm</span><br><span class="line">yum install -y proxysql-1.4.9-3-centos7.x86_64.rpm</span><br></pre></td></tr></table></figure><h3 id="启动ProxySQL"><a href="#启动ProxySQL" class="headerlink" title="启动ProxySQL"></a>启动ProxySQL</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/proxysql start</span><br><span class="line"><span class="meta">#</span><span class="bash">proxysql客户端监听在6033端口上，管理端监听6032端口</span></span><br><span class="line">连接proxysql管理端进行配置：</span><br><span class="line">mysql -uadmin -padmin -h127.0.0.1 -P6032</span><br><span class="line"><span class="meta">#</span><span class="bash">默认的管理端账号密码都是admin，登录进去之后可以修改变量进行修改账号密码</span></span><br></pre></td></tr></table></figure><h3 id="添加后端的mysql主机"><a href="#添加后端的mysql主机" class="headerlink" title="添加后端的mysql主机"></a>添加后端的mysql主机</h3><p>将mysql服务器ip换成你的mysql服务器ip</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ProxySQL&gt; INSERT INTO mysql_servers(hostgroup_id,hostname,port) </span><br><span class="line">          VALUES (1,'192.168.48.100',3306);</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> mysql_servers;</span><br><span class="line"></span><br><span class="line">MySQL [(none)]&gt; select * from mysql_servers;</span><br><span class="line">+<span class="comment">--------------+-----------+------+--------+--------+-------------+-----------------+---------------------+---------+----------------+---------+</span></span><br><span class="line">| hostgroup_id | hostname  | port | status | weight | compression | max_connections | max_replication_lag | use_ssl | max_latency_ms | <span class="keyword">comment</span> |</span><br><span class="line">+<span class="comment">--------------+-----------+------+--------+--------+-------------+-----------------+---------------------+---------+----------------+---------+</span></span><br><span class="line">| <span class="number">1</span>            | <span class="number">192.168</span><span class="number">.48</span><span class="number">.120</span> | <span class="number">3306</span> | <span class="keyword">ONLINE</span> | <span class="number">1</span>      | <span class="number">0</span>           | <span class="number">1000</span>            | <span class="number">0</span>                   | <span class="number">0</span>       | <span class="number">0</span>              |         |</span><br></pre></td></tr></table></figure><h3 id="添加可以访问后端主机的账号"><a href="#添加可以访问后端主机的账号" class="headerlink" title="添加可以访问后端主机的账号"></a>添加可以访问后端主机的账号</h3><p>在mysql主库(192.168.48.120)中添加账号proxysql及密码，以及授权</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> ALL <span class="keyword">ON</span> *.* <span class="keyword">TO</span> <span class="string">'proxysql'</span>@<span class="string">'192.168.48.120'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'123456'</span>;</span><br><span class="line">在proxysql服务器(192.168.48.100)中添加可以增删改查后端mysql服务器的账号</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> mysql_users(username,<span class="keyword">password</span>,default_hostgroup,transaction_persistent)<span class="keyword">values</span>(<span class="string">'proxysql'</span>,<span class="string">'123456'</span>,<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">MySQL [(none)]&gt; insert into mysql_users(username,password,default_hostgroup,transaction_persistent)values('proxysql','123456',1,1);</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br></pre></td></tr></table></figure><p>在proxysql主机的mysql_users表中添加刚才创建的账号，proxysql客户端需要使用这个账号来访问数据库。</p><ul><li>default_hostgroup默认组设置为写组，也就是1</li><li>当读写分离的路由规则不符合时，会访问默认组的数据库</li><li>将刚才我们修改的数据加载至RUNTIME中(参考ProxySQL的多层配置结构)：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">load</span> mysql <span class="keyword">users</span> <span class="keyword">to</span> runtime;</span><br><span class="line"><span class="keyword">load</span> mysql servers <span class="keyword">to</span> runtime;</span><br><span class="line">save mysql users to disk;</span><br><span class="line">save mysql servers to disk;</span><br></pre></td></tr></table></figure><h2 id="DataMasking"><a href="#DataMasking" class="headerlink" title="DataMasking"></a>DataMasking</h2><p>ProxySQL有查询重写(Query Rewrite)功能，如果你想要重写查询，你必匹配查询的原始语句(使用match_pattern)，因为原始查询语句需要被重写。</p><h3 id="添加查询规则"><a href="#添加查询规则" class="headerlink" title="添加查询规则"></a>添加查询规则</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ProxySQL&gt; INSERT INTO mysql_query_rules (rule_id,active,username,match_pattern,error_msg)</span><br><span class="line">          VALUES (90,1,'proxysql','^<span class="keyword">SELECT</span> \*.*FROM.*customers<span class="string">',</span></span><br><span class="line"><span class="string">          '</span><span class="keyword">Query</span> <span class="keyword">not</span> allowed due <span class="keyword">to</span> sensitive information, please contact dba@myapp.com<span class="string">');</span></span><br><span class="line"><span class="string">Let’s load it in runtime and test</span></span><br><span class="line"><span class="string">ProxySQL&gt; LOAD MYSQL QUERY RULES TO RUNTIME;</span></span><br></pre></td></tr></table></figure><ul><li>另开一个终端，以6033端口(数据端口)登录:</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -uproxysql -p123456 -h 192.168.48.100 -P 6033</span><br></pre></td></tr></table></figure><ul><li>执行SELECT *操作：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from test.customers;</span><br><span class="line">ERROR 1148 (42000): Query not allowed due to sensitive information, please contact dba@myapp.com</span><br></pre></td></tr></table></figure><p>Yeah!我们根据配置的mysql_query_rules成功阻断了对customers表上的<code>SELECT*</code>操作.</p><ul><li>我们再在管理连接中插入如下一条查询规则:</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">ProxySQL&gt; INSERT INTO mysql_query_rules (rule_id,active,username,match_pattern,replace_pattern,apply)</span><br><span class="line">          VALUES (1,1,'proxysql','^[sS][eE][lL][eE][cC][tT] (.*)cc_num([ ,])(.*)', </span><br><span class="line">                "<span class="keyword">SELECT</span> \<span class="number">1</span><span class="keyword">CONCAT</span>(<span class="keyword">REPEAT</span>(<span class="string">'X'</span>,<span class="number">12</span>),<span class="keyword">RIGHT</span>(cc_num,<span class="number">4</span>)) cc_num\<span class="number">2</span>\<span class="number">3</span><span class="string">",1);</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ProxySQL&gt; LOAD MYSQL QUERY RULES TO RUNTIME;</span></span><br><span class="line"><span class="string">我们在数据连接中再测试一下:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">mysql&gt; select firstname, cc_num from test.customers;</span></span><br><span class="line"><span class="string">+-----------+------------------+</span></span><br><span class="line"><span class="string">| firstname | cc_num           |</span></span><br><span class="line"><span class="string">+-----------+------------------+</span></span><br><span class="line"><span class="string">| Frederic  | XXXXXXXXXXXX5289 |</span></span><br><span class="line"><span class="string">| Dim0      | XXXXXXXXXXXX5289 |</span></span><br><span class="line"><span class="string">| Kenny     | XXXXXXXXXXXX4589 |</span></span><br><span class="line"><span class="string">+-----------+------------------+</span></span><br></pre></td></tr></table></figure><p>WOOhoo!我们成功实现了只显示卡号后4位！</p><ul><li>保存规则到磁盘</li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ProxySQL&gt; SAVE MYSQL QUERY RULES TO DISK;</span><br></pre></td></tr></table></figure><h2 id="更多"><a href="#更多" class="headerlink" title="更多"></a>更多</h2><p>我们需要对更多的表和字段做更多的datamasking(例如姓名字段做隐藏等)，我们就需要编写更多的查询规则(mysql_query_rules),并在管理连接中添加到mysql_query_rules表中.</p>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;MySQL datamasking using ProxySQL&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;div class=&quot;note info&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;操作环境一览:&lt;br&gt;&lt;br&gt;- 操作系统： CentOS7&lt;br&gt;&lt;br&gt;- MySQL: 5.5&lt;br&gt;&lt;br&gt;- ProxySQL: 1.4.9&lt;br&gt;&lt;br&gt;- ProxySQL主机IP: 192.168.48.100&lt;br&gt;&lt;br&gt;- MySQL主库IP: 192.168.48.120&lt;br&gt;&lt;br&gt;&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="Linux" scheme="https://blog.writeathink.cn/categories/Linux/"/>
    
    
      <category term="MySQL" scheme="https://blog.writeathink.cn/tags/MySQL/"/>
    
      <category term="ProxySQL" scheme="https://blog.writeathink.cn/tags/ProxySQL/"/>
    
      <category term="DataMask" scheme="https://blog.writeathink.cn/tags/DataMask/"/>
    
  </entry>
  
  <entry>
    <title>只在使用 Mix-in 组件制作工具类时进行多重继承</title>
    <link href="https://blog.writeathink.cn/2018/06/11/Mix-in-inherit/"/>
    <id>https://blog.writeathink.cn/2018/06/11/Mix-in-inherit/</id>
    <published>2018-06-11T08:37:57.000Z</published>
    <updated>2018-06-12T03:04:36.515Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p class="description">Python是面向对象的编程语言，它提供了一些内置的编程机制，使得开发者可以适当地实现多重继承。但是我们仍然应该尽量避开多重继承。<br></p><p><img src="" alt="" style="width:100%"></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><div class="note info"><p><br><br>若一定要利用多重继承所带来的便利及封装性，那就编写<code>mix-in</code>类。<code>mix-in</code>是一种小型的类，它只定义了其他类可能需要提供的一套附加方法，而不定义自己的实例属性，此外，它也不要求使用者调用自己的<code>__init__</code>构造器。<br><br></p></div><a id="more"></a><h2 id="例子1-ToDictMixin"><a href="#例子1-ToDictMixin" class="headerlink" title="例子1:ToDictMixin"></a>例子1:ToDictMixin</h2><p>现在，要把内存中的Python对象转换成字典形式，以便将其序列化，那我们就不妨把这个功能写成通用的代码，以便其他类使用。</p><h3 id="ToDictMixin"><a href="#ToDictMixin" class="headerlink" title="ToDictMixin"></a>ToDictMixin</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ToDictMixin类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ToDictMixin</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">to_dict</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 用__dict__来访问实例内部的字典</span></span><br><span class="line">        <span class="keyword">return</span> self._traverse_dict(self.__dict__)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_traverse_dict</span><span class="params">(self, instance_dict)</span>:</span></span><br><span class="line">        output = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> key, value <span class="keyword">in</span> instance_dict.items():</span><br><span class="line">            output[key] = self._traverse(key, value)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_traverse</span><span class="params">(self, key, value)</span>:</span></span><br><span class="line">        <span class="comment"># 根据value不同类型分别作处理</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(value, ToDictMixin):</span><br><span class="line">            <span class="keyword">return</span> value.to_dict()</span><br><span class="line">        <span class="keyword">elif</span> isinstance(value, dict):</span><br><span class="line">            <span class="keyword">return</span> self._traverse_dict(value)</span><br><span class="line">        <span class="keyword">elif</span> isinstance(value, list):</span><br><span class="line">            <span class="keyword">return</span> [self._traverse(key, i) <span class="keyword">for</span> i <span class="keyword">in</span> value]</span><br><span class="line">        <span class="keyword">elif</span> hasattr(value, <span class="string">'__dict__'</span>):</span><br><span class="line">            <span class="keyword">return</span> self._traverse_dict(value.__dict__)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> value</span><br></pre></td></tr></table></figure><h3 id="BinaryTree"><a href="#BinaryTree" class="headerlink" title="BinaryTree"></a>BinaryTree</h3><p>使用<code>ToDictMixin</code>把二叉树表示为字典:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 二叉树类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BinaryTree</span><span class="params">(ToDictMixin)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, value, left=None, right=None)</span>:</span></span><br><span class="line">        self.value= value</span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br></pre></td></tr></table></figure><p>现在，我们可以把一大批互相关联的Python对象都轻松地转换成字典：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tree = BinaryTree(<span class="number">1</span>,</span><br><span class="line">    left=BinaryTree(<span class="number">2</span>, right=BinaryTree(<span class="number">3</span>)),</span><br><span class="line">    right=BinaryTree(<span class="number">4</span>, left=BinaryTree(<span class="number">5</span>)))</span><br><span class="line">print(tree.to_dict())</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">&#123;<span class="string">'value'</span>: <span class="number">1</span>, <span class="string">'right'</span>: &#123;<span class="string">'value'</span>: <span class="number">4</span>, <span class="string">'right'</span>: <span class="keyword">None</span>, <span class="string">'left'</span>: &#123;<span class="string">'value'</span>: <span class="number">5</span>, <span class="string">'right'</span>: <span class="keyword">None</span>, <span class="string">'left'</span>: <span class="keyword">None</span>&#125;&#125;, <span class="string">'left'</span>: &#123;<span class="string">'value'</span>: <span class="number">2</span>, <span class="string">'right'</span>: &#123;<span class="string">'value'</span>: <span class="number">3</span>, <span class="string">'right'</span>: <span class="keyword">None</span>, <span class="string">'left'</span>: <span class="keyword">None</span>&#125;, <span class="string">'left'</span>: <span class="keyword">None</span>&#125;&#125;</span><br></pre></td></tr></table></figure><h3 id="BinaryTreeWithParent"><a href="#BinaryTreeWithParent" class="headerlink" title="BinaryTreeWithParent"></a>BinaryTreeWithParent</h3><p><code>mix-in</code>的最大优势在于，使用者可以随时安插这些通用的功能，并能在必要的时候覆写它们。</p><p>下面定义的这个<code>BinaryTree</code>子类，会持有指向父节点的引用。如果采用默认的<code>ToDictMixin.to_dict</code>来处理它，那么程序就会因为循环引用而陷入死循环(parent)。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BinaryTreeWithParent</span><span class="params">(BinaryTree)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, value, left=None, right=None, parent=None)</span>:</span></span><br><span class="line">        super().__init__(value, left=left, right=right)</span><br><span class="line">        self.parent = parent</span><br></pre></td></tr></table></figure><p>解决办法是在<code>BinaryTreeWithParent</code>里覆写<code>ToDictMixin._traverse方法</code>，令该方法只处理与序列化有关的值，从而使mix-in的实现代码不会陷入死循环：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 覆写_traverse方法，不再遍历父节点，而是只把父节点所对应的数值插入到最终生成的字典里面</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BinaryTreeWithParent</span><span class="params">(BinaryTree)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, value, left=None, right=None, parent=None)</span>:</span></span><br><span class="line">        super().__init__(value, left=left, right=right)</span><br><span class="line">        self.parent = parent</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_traverse</span><span class="params">(self, key, value)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> (isinstance(value, BinaryTreeWithParent) <span class="keyword">and</span> key == <span class="string">'parent'</span>):</span><br><span class="line">            <span class="keyword">return</span> value.value  <span class="comment"># 返回父节点(parent)的值</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> super()._traverse(key, value)</span><br></pre></td></tr></table></figure><p>调用<code>BinaryTreeWithParent.to_dict</code>看看:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root = BinaryTreeWithParent(<span class="number">1</span>)</span><br><span class="line">root.left = BinaryTreeWithParent(<span class="number">2</span>, parent=root)</span><br><span class="line">root.left.right = BinaryTreeWithParent(<span class="number">4</span>, parent=root.left)</span><br><span class="line">print(root.to_dict())</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">&#123;<span class="string">'value'</span>: <span class="number">1</span>, <span class="string">'right'</span>: <span class="keyword">None</span>, <span class="string">'left'</span>: &#123;<span class="string">'value'</span>: <span class="number">2</span>, <span class="string">'right'</span>: &#123;<span class="string">'value'</span>: <span class="number">4</span>, <span class="string">'right'</span>: <span class="keyword">None</span>, <span class="string">'left'</span>: <span class="keyword">None</span>, <span class="string">'parent'</span>: <span class="number">2</span>&#125;, <span class="string">'left'</span>: <span class="keyword">None</span>, <span class="string">'parent'</span>: <span class="number">1</span>&#125;, <span class="string">'parent'</span>: <span class="keyword">None</span>&#125;</span><br></pre></td></tr></table></figure><p>定义了<code>BinaryTreeWithParent._traverse</code>方法之后，如果其他类的某个属性也是<code>BinaryTreeWithParent</code>类型，那么<code>ToDictMixin</code>会自动处理好这些属性:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NamedSubTree</span><span class="params">(ToDictMixin)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name, tree_with_parent)</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line">        self.tree_with_parent = tree_with_parent</span><br><span class="line"></span><br><span class="line">my_tree = NamedSubTree(<span class="string">'foobar'</span>, root.left.right)  <span class="comment"># 上面定义的root</span></span><br><span class="line">print(my_tree.to_dict())</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">&#123;<span class="string">'name'</span>: <span class="string">'foobar'</span>, <span class="string">'tree_with_parent'</span>: &#123;<span class="string">'value'</span>: <span class="number">4</span>, <span class="string">'right'</span>: <span class="keyword">None</span>, <span class="string">'left'</span>: <span class="keyword">None</span>, <span class="string">'parent'</span>: <span class="number">2</span>&#125;&#125;</span><br></pre></td></tr></table></figure><h2 id="多个mix-in组合"><a href="#多个mix-in组合" class="headerlink" title="多个mix-in组合"></a>多个mix-in组合</h2><h3 id="JsonMixin"><a href="#JsonMixin" class="headerlink" title="JsonMixin"></a>JsonMixin</h3><p>多个mix-in之间也可以相互组合。例如，可以编写这样一个mix-in，它能够为任意类提供通用的JSON序列化功能。我们可以假定：继承了mix-in的哪个类，会提供名为to_dict的方法(此方法有可能是那个类通过多重继承ToDictMixin而具备的，也有可能不是)。</p><figure class="highlight python"><figcaption><span>JsonMixin</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import json first</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JsonMixin</span><span class="params">(object)</span>:</span></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_json</span><span class="params">(cls, data)</span>:</span></span><br><span class="line">        kwargs = json.loads(data)</span><br><span class="line">        <span class="keyword">return</span> cls(**kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">to_json</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> json.dumps(self.to_dict())</span><br></pre></td></tr></table></figure><p>请注意，JsonMixin类既定义了实例方法，有定义了类方法。这两种行为都可以通过mix-in来提供。在本例中，凡是想继承JsonMixin的类，只需符合两个条件即可:</p><ul><li>(1) 包含名为to_dict的方法</li><li>(2) <strong>init</strong>方法接受关键字参数</li></ul><h3 id="组合ToDictMixin和JsonMixin"><a href="#组合ToDictMixin和JsonMixin" class="headerlink" title="组合ToDictMixin和JsonMixin"></a>组合ToDictMixin和JsonMixin</h3><p>我们用下面这个继承了mix-in组件的数据类来表示数据中心的拓扑结构:</p><figure class="highlight python"><figcaption><span>DatacenterRack</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DatacenterRack</span><span class="params">(ToDictMixin, JsonMixin)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, switch=None, machines=None)</span>:</span></span><br><span class="line">        self.switch = Switch(**switch)</span><br><span class="line">        self.machines = [Machine(**kwargs) <span class="keyword">for</span> kwargs <span class="keyword">in</span> machines]</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Switch</span><span class="params">(ToDictMixin, JsonMixin)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, **kwargs)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        <span class="comment"># 接受处理关键字参数</span></span><br><span class="line">        <span class="keyword">for</span> k, w <span class="keyword">in</span> kwargs.items():</span><br><span class="line">            setattr(self, k, w)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Machine</span><span class="params">(ToDictMixin, JsonMixin)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, **kwargs)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        <span class="comment"># 接受处理关键字参数</span></span><br><span class="line">        <span class="keyword">for</span> k, w <span class="keyword">in</span> kwargs.items():</span><br><span class="line">            setattr(self, k, w)</span><br></pre></td></tr></table></figure><p>对这样的类进行序列化，以及从JSON中加载它，都是比较简单的。下面的这段代码，会重复执行序列化及反序列化操作，以验证这两个功能有没有正确地实现出来。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">serialized = <span class="string">"""&#123;</span></span><br><span class="line"><span class="string">    "switch": &#123;"ports": 5,"speed":1e9&#125;,</span></span><br><span class="line"><span class="string">    "machines": [</span></span><br><span class="line"><span class="string">        &#123;"cores": 8, "ram": 32e9, "disk": 5e12&#125;,</span></span><br><span class="line"><span class="string">        &#123;"cores": 4, "ram": 16e9, "disk": 5e12&#125;,</span></span><br><span class="line"><span class="string">        &#123;"cores": 2, "ram": 4e9, "disk": 500e9&#125;</span></span><br><span class="line"><span class="string">    ]</span></span><br><span class="line"><span class="string">&#125;"""</span></span><br><span class="line"></span><br><span class="line">deserialized = DatacenterRack.from_json(serialized)</span><br><span class="line">roundtrip = deserialized.to_json()</span><br><span class="line"><span class="keyword">assert</span> json.loads(serialized)  == json.loads(roundtrip)</span><br></pre></td></tr></table></figure><p>使用这种mix-in的时候，既可以像本例这样，直接继承多个mix-in组件，也可以先令继承体系中的其他类继承相关的mix-in组件，然后再令本类继承那些类，以达到同样的效果</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li>能用mix-in组件实现的效果，就不要用多重继承来做</li><li>将各功能实现为可插拔的mix-in组件，然后令相关的类继承自己需要的那些组件，即可定制该类实例所应具备的行为。</li><li>把简单的行为封装到mix-in组件里，然后就可以用多个mix-in组合出复杂的行为了。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;Python是面向对象的编程语言，它提供了一些内置的编程机制，使得开发者可以适当地实现多重继承。但是我们仍然应该尽量避开多重继承。&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;div class=&quot;note info&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;br&gt;若一定要利用多重继承所带来的便利及封装性，那就编写&lt;code&gt;mix-in&lt;/code&gt;类。&lt;code&gt;mix-in&lt;/code&gt;是一种小型的类，它只定义了其他类可能需要提供的一套附加方法，而不定义自己的实例属性，此外，它也不要求使用者调用自己的&lt;code&gt;__init__&lt;/code&gt;构造器。&lt;br&gt;&lt;br&gt;&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="Python" scheme="https://blog.writeathink.cn/categories/Python/"/>
    
    
      <category term="Mix-in" scheme="https://blog.writeathink.cn/tags/Mix-in/"/>
    
      <category term="inherit" scheme="https://blog.writeathink.cn/tags/inherit/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu下搭建个人gitlab服务器</title>
    <link href="https://blog.writeathink.cn/2018/05/10/start-gitlab/"/>
    <id>https://blog.writeathink.cn/2018/05/10/start-gitlab/</id>
    <published>2018-05-10T06:21:22.000Z</published>
    <updated>2018-05-10T06:34:46.176Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p class="description">本文主要记录在Ubuntu 16.04操作系统中搭建GitLab服务器的操作记录<br></p><p><img src="" alt="" style="width:100%"></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><blockquote><p>GitLab 是一个用于仓库管理系统的开源项目。使用Git作为代码管理工具，并在此基础上搭建起来的web服务.可通过Web界面进行访问公开的或者私人项目,它拥有与Github类似的功能,能够浏览源代码,管理缺陷和注释.可以管理团队对仓库的访问,它非常易于浏览提交过的版本并提供一个文件历史库,团队成员可以利用内置的简单聊天程序(Wall)进行交流。它还提供一个代码片段收集功能可以轻松实现代码复用.<br><a id="more"></a></p></blockquote><h2 id="安装依赖包"><a href="#安装依赖包" class="headerlink" title="安装依赖包"></a>安装依赖包</h2><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install curl openssh-server ca-certificates postfix</span><br></pre></td></tr></table></figure><h2 id="执行完成后-出现邮件配置，选择Internet-Site这一项，确定"><a href="#执行完成后-出现邮件配置，选择Internet-Site这一项，确定" class="headerlink" title="执行完成后,出现邮件配置，选择Internet Site这一项，确定"></a>执行完成后,出现邮件配置，选择<code>Internet Site</code>这一项，确定</h2><h2 id="添加清华镜像源"><a href="#添加清华镜像源" class="headerlink" title="添加清华镜像源"></a>添加清华镜像源</h2><ul><li>添加Gitlab的GPG公钥</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl https://packages.gitlab.com/gpg.key 2&gt; /dev/null | sudo apt-key add - &amp;&gt;/dev/null</span><br></pre></td></tr></table></figure><ul><li>添加源</li></ul><p><code>sudo vim /etc/apt/sources.list.d/gitlab-ce.list</code>,加入如下语句：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">deb https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/ubuntu xenial main</span><br></pre></td></tr></table></figure><h2 id="安装gitlab-ce"><a href="#安装gitlab-ce" class="headerlink" title="安装gitlab-ce"></a>安装gitlab-ce</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install gitlab-ce</span><br></pre></td></tr></table></figure><p>会下载400多MB的，安装完成会占用1GB多的空间，请确保服务器空间充足</p><h2 id="启动各项服务"><a href="#启动各项服务" class="headerlink" title="启动各项服务"></a>启动各项服务</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gitlab-ctl reconfigure</span><br></pre></td></tr></table></figure><h2 id="检查GitLab是否安装好并且已经正确运行"><a href="#检查GitLab是否安装好并且已经正确运行" class="headerlink" title="检查GitLab是否安装好并且已经正确运行"></a>检查GitLab是否安装好并且已经正确运行</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gitlab-ctl status</span><br></pre></td></tr></table></figure><p>得到如下结果，说明Gitlab运行正常</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">run: gitaly: (pid 25122) 1215s; run: log: (pid 17658) 2960s</span><br><span class="line">run: gitlab-monitor: (pid 25134) 1214s; run: log: (pid 17872) 2948s</span><br><span class="line">run: gitlab-workhorse: (pid 25139) 1213s; run: log: (pid 17594) 2974s</span><br><span class="line">run: logrotate: (pid 25153) 1211s; run: log: (pid 17626) 2966s</span><br><span class="line">run: nginx: (pid 26851) 857s; run: log: (pid 17610) 2972s</span><br><span class="line">run: node-exporter: (pid 25180) 1210s; run: log: (pid 17842) 2954s</span><br><span class="line">run: postgres-exporter: (pid 25190) 1209s; run: log: (pid 17956) 2934s</span><br><span class="line">run: postgresql: (pid 25201) 1207s; run: log: (pid 17322) 3028s</span><br><span class="line">run: prometheus: (pid 25210) 1204s; run: log: (pid 17914) 2940s</span><br><span class="line">run: redis: (pid 25226) 1201s; run: log: (pid 17256) 3034s</span><br><span class="line">run: redis-exporter: (pid 25309) 1199s; run: log: (pid 17888) 2946s</span><br><span class="line">run: sidekiq: (pid 26311) 1071s; run: log: (pid 17576) 2976s</span><br><span class="line">run: unicorn: (pid 26662) 933s; run: log: (pid 17532) 2982s</span><br></pre></td></tr></table></figure><h2 id="配置gitlab-external-url访问规则"><a href="#配置gitlab-external-url访问规则" class="headerlink" title="配置gitlab external_url访问规则"></a>配置gitlab external_url访问规则</h2><ul><li>修改gitlab.rb配置文件</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/gitlab/gitlab.rb</span><br></pre></td></tr></table></figure><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="deletion">- external_url 'http://gitlab.example.com'</span></span><br><span class="line"><span class="addition">+ external_url 'http://192.168.2.200:9876/' </span></span><br><span class="line"><span class="addition">+ ## 192.168.48.200为服务器地址，请替换为你的</span></span><br><span class="line"><span class="addition">+ ## 9876为自定义的端口，默认为80端口。</span></span><br></pre></td></tr></table></figure><ul><li>添加防火墙规则</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">## 开放自定义端口访问(上面定义的9876端口)</span><br><span class="line">sudo iptables -A INPUT -p tcp -m tcp --dport 9876 -j ACCEPT</span><br><span class="line">## 如果上面使用的默认端口,就开放80端口</span><br><span class="line">## sudo iptables -A INPUT -p tcp -m tcp --dport 80 -j ACCEPT</span><br></pre></td></tr></table></figure><h2 id="启动sshd和postfix服务"><a href="#启动sshd和postfix服务" class="headerlink" title="启动sshd和postfix服务"></a>启动<code>sshd</code>和<code>postfix</code>服务</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo service sshd start</span><br><span class="line"></span><br><span class="line">sudo service postfix start</span><br></pre></td></tr></table></figure><h2 id="浏览页面并设置密码"><a href="#浏览页面并设置密码" class="headerlink" title="浏览页面并设置密码"></a>浏览页面并设置密码</h2><p>浏览器输入<code>http://192.168.2.200:9876</code>(如果使用的默认端口则为<code>http://192.168.2.200</code>),将<code>192.168.2.200</code>替换为你的服务器地址.</p><p><img src="https://github.com/cgDeepLearn/LinuxSetups/blob/master/pics/gitlab-changepass.png?raw=true" alt="change-pass"></p><p>第一次进入后会出现修改密码的页面</p><p>输入密码确认。其默认用户为<code>root</code></p><p>然后可以修改用户名密码或者注册新用户等</p><h2 id="创建组、项目"><a href="#创建组、项目" class="headerlink" title="创建组、项目"></a>创建组、项目</h2><p><img src="https://github.com/cgDeepLearn/LinuxSetups/blob/master/pics/gitlab-create.png?raw=true" alt="git-create"></p><p>当然也可以从github等仓库导入</p><h2 id="添加ssh-key等"><a href="#添加ssh-key等" class="headerlink" title="添加ssh-key等"></a>添加ssh-key等</h2><p>这和github等相同</p>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;本文主要记录在Ubuntu 16.04操作系统中搭建GitLab服务器的操作记录&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;GitLab 是一个用于仓库管理系统的开源项目。使用Git作为代码管理工具，并在此基础上搭建起来的web服务.可通过Web界面进行访问公开的或者私人项目,它拥有与Github类似的功能,能够浏览源代码,管理缺陷和注释.可以管理团队对仓库的访问,它非常易于浏览提交过的版本并提供一个文件历史库,团队成员可以利用内置的简单聊天程序(Wall)进行交流。它还提供一个代码片段收集功能可以轻松实现代码复用.&lt;br&gt;
    
    </summary>
    
      <category term="Linux" scheme="https://blog.writeathink.cn/categories/Linux/"/>
    
    
      <category term="gitlab" scheme="https://blog.writeathink.cn/tags/gitlab/"/>
    
      <category term="git" scheme="https://blog.writeathink.cn/tags/git/"/>
    
      <category term="Ubuntu" scheme="https://blog.writeathink.cn/tags/Ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>使用Cookiecutter来初始化你的Django项目,Awesome!!!</title>
    <link href="https://blog.writeathink.cn/2018/03/19/Cookiecutter-Django/"/>
    <id>https://blog.writeathink.cn/2018/03/19/Cookiecutter-Django/</id>
    <published>2018-03-19T06:53:10.000Z</published>
    <updated>2018-03-19T07:16:19.598Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p class="description">快来动手试试吧，简直太棒了<br></p><p><img src="" alt="" style="width:100%"></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><div class="note info"><p><br>Cookiecutter可以让你快速从模板中建立工程，cookiecutter-django则是Django的模板，可以快速生成<code>Django</code>大型项目模板。其特性如下:</p><p><ul><br>  <li>跨平台: Windows,Mac 和Linux都支持</li><br>  <li>在Python2.7, 3.3, 3.4, 3.5, 3.6 和PyPy下运行</li><br>  <li>工程模板可以是任何语言</li><br>  <li>简单易用</li><br></ul><br></p></div><br><a id="more"></a></p><h2 id="安装配置Cookiecutter-django"><a href="#安装配置Cookiecutter-django" class="headerlink" title="安装配置Cookiecutter-django"></a>安装配置Cookiecutter-django</h2><h3 id="安装cookiecutter"><a href="#安装cookiecutter" class="headerlink" title="安装cookiecutter"></a>安装cookiecutter</h3><p>首先, get Cookiecutter.相信我,它棒极了:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> pip install <span class="string">"cookiecutter&gt;=1.4.0"</span></span></span><br></pre></td></tr></table></figure><h3 id="生成项目"><a href="#生成项目" class="headerlink" title="生成项目"></a>生成项目</h3><p>然后用<code>Cookiecutter-django</code>来生成一个Django项目:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cookiecutter https://github.com/audreyr/cookiecutter-pypackage.git</span><br></pre></td></tr></table></figure><p>你需要在引导下填一些values,例如:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">Cloning into &apos;cookiecutter-django&apos;...</span><br><span class="line">remote: Counting objects: 550, done.</span><br><span class="line">remote: Compressing objects: 100% (310/310), done.</span><br><span class="line">remote: Total 550 (delta 283), reused 479 (delta 222)</span><br><span class="line">Receiving objects: 100% (550/550), 127.66 KiB | 58 KiB/s, done.</span><br><span class="line">Resolving deltas: 100% (283/283), done.</span><br><span class="line">project_name [Project Name]: My First Django Project</span><br><span class="line">project_slug [reddit_clone]: my_first_django_project</span><br><span class="line">author_name [Daniel Roy Greenfeld]: cgDeepLearn</span><br><span class="line">email [you@example.com]: cgDeepLearn@gmail.com</span><br><span class="line">description [A short description of the project.]: My first Django Project with Cookiecutter</span><br><span class="line">domain_name [example.com]: myxxxx.com</span><br><span class="line">version [0.1.0]: 0.0.1</span><br><span class="line">timezone [UTC]: Asia/Shanghai</span><br><span class="line">use_whitenoise [y]: n</span><br><span class="line">use_celery [n]: y</span><br><span class="line">use_mailhog [n]: n</span><br><span class="line">use_sentry_for_error_reporting [y]: y</span><br><span class="line">use_opbeat [n]: y</span><br><span class="line">use_pycharm [n]: y</span><br><span class="line">windows [n]: n</span><br><span class="line">use_docker [y]: n</span><br><span class="line">use_heroku [n]: n</span><br><span class="line">use_compressor [n]: y</span><br><span class="line">Select postgresql_version:</span><br><span class="line">1 - 10.3</span><br><span class="line">2 - 10.2</span><br><span class="line">3 - 10.1</span><br><span class="line">4 - 9.6</span><br><span class="line">5 - 9.5</span><br><span class="line">6 - 9.4</span><br><span class="line">7 - 9.3</span><br><span class="line">Choose from 1, 2, 3, 4 [1]: 4</span><br><span class="line">Select js_task_runner:</span><br><span class="line">1 - Gulp</span><br><span class="line">2 - Grunt</span><br><span class="line">3 - None</span><br><span class="line">Choose from 1, 2, 3, 4 [1]: 1</span><br><span class="line">custom_bootstrap_compilation [n]: n</span><br><span class="line">Select open_source_license:</span><br><span class="line">1 - MIT</span><br><span class="line">2 - BSD</span><br><span class="line">3 - GPLv3</span><br><span class="line">4 - Apache Software License 2.0</span><br><span class="line">5 - Not open source</span><br><span class="line">Choose from 1, 2, 3, 4, 5 [1]: 1</span><br><span class="line">keep_local_envs_in_vcs [y]: y</span><br></pre></td></tr></table></figure><p>根据你的需要来选择一些选项。注: <code>project_slug</code>是你的项目名(在路径中体现)</p><h3 id="配置使用Django"><a href="#配置使用Django" class="headerlink" title="配置使用Django"></a>配置使用Django</h3><p>进入项目根目录:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span>  my_first_django_project</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ls</span></span><br></pre></td></tr></table></figure><h4 id="关联仓库"><a href="#关联仓库" class="headerlink" title="关联仓库"></a>关联仓库</h4><p>在github创建一个repo,关联你的项目，并首次push:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git init</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git add .</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git commit -m <span class="string">"first awesome commit"</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git remote add origin git@github.com:yourname/yourproject.git</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git push -u origin master</span></span><br></pre></td></tr></table></figure><h4 id="配置Django"><a href="#配置Django" class="headerlink" title="配置Django"></a>配置Django</h4><p>选择<code>Django</code>安装版本(修改requirements/base.txt):</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">django==1.11.2</span><br><span class="line"># django==2.0.3 ## django 2.0+</span><br></pre></td></tr></table></figure><p>数据库如果选择了<code>Postgresql</code>(Postgresql的安装使用情参考<a href="https://github.com/cgDeepLearn/LinuxSetups/blob/master/docs/databases/postgresql.md" target="_blank" rel="noopener">Postgresql安装配置</a>),需安装<code>psycopg2</code>依赖:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## requirements/local.txt</span><br><span class="line">psycopg==2.7.4</span><br></pre></td></tr></table></figure><p>在激活的虚拟环境下安装依赖:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip install -r requirements\local.txt</span><br></pre></td></tr></table></figure><h4 id="Pycharm的配置"><a href="#Pycharm的配置" class="headerlink" title="Pycharm的配置"></a>Pycharm的配置</h4><p>如果生成项目时选项pycharm填入了y,下面我们来配置一下。</p><ul><li>打开 <code>File - Settings</code> -&gt; <code>Languages and Frameworks</code> -&gt; <code>Django</code>.</li></ul><p><img src="https://github.com/cgDeepLearn/LinuxSetups/blob/master/pics/pycharm_django_settings.png?raw=true" alt="pycharm-django-settings"></p><ul><li>勾选上 <code>Enable Django Support</code></li></ul><p>我们需要为Django数据库配置Postgresql数据库地址，我们点击<code>Environment variavles</code> 的 <code>...</code> ,添加<code>DATABASE_URL</code>变量(注DATABASE_URL在conf.setting中使用):</p><p><img src="https://github.com/cgDeepLearn/LinuxSetups/blob/master/pics/pycharm_django_env.png?raw=true" alt="pycharm-dajngo-env"></p><ul><li>Run the Server</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> python manage.py migrate</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> python manage.py createsuperuser</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> python manage.py runserver</span></span><br></pre></td></tr></table></figure><h2 id="Cookiecutter-Django英文文档"><a href="#Cookiecutter-Django英文文档" class="headerlink" title="Cookiecutter-Django英文文档"></a>Cookiecutter-Django英文文档</h2><p>阅读<a href="https://cookiecutter-django.readthedocs.io/en/latest/" target="_blank" rel="noopener">英文指南</a>:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://cookiecutter-django.readthedocs.io/en/latest/</span><br></pre></td></tr></table></figure><h2 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h2>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;快来动手试试吧，简直太棒了&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;&lt;div class=&quot;note info&quot;&gt;&lt;p&gt;&lt;br&gt;Cookiecutter可以让你快速从模板中建立工程，cookiecutter-django则是Django的模板，可以快速生成&lt;code&gt;Django&lt;/code&gt;大型项目模板。其特性如下:&lt;/p&gt;
&lt;p&gt;&lt;ul&gt;&lt;br&gt;  &lt;li&gt;跨平台: Windows,Mac 和Linux都支持&lt;/li&gt;&lt;br&gt;  &lt;li&gt;在Python2.7, 3.3, 3.4, 3.5, 3.6 和PyPy下运行&lt;/li&gt;&lt;br&gt;  &lt;li&gt;工程模板可以是任何语言&lt;/li&gt;&lt;br&gt;  &lt;li&gt;简单易用&lt;/li&gt;&lt;br&gt;&lt;/ul&gt;&lt;br&gt;&lt;/p&gt;&lt;/div&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Python" scheme="https://blog.writeathink.cn/categories/Python/"/>
    
      <category term="Django" scheme="https://blog.writeathink.cn/categories/Python/Django/"/>
    
    
      <category term="python" scheme="https://blog.writeathink.cn/tags/python/"/>
    
      <category term="django" scheme="https://blog.writeathink.cn/tags/django/"/>
    
      <category term="cookiecutter" scheme="https://blog.writeathink.cn/tags/cookiecutter/"/>
    
  </entry>
  
  <entry>
    <title>Python协程的演化-从yield/send到async/await</title>
    <link href="https://blog.writeathink.cn/2018/03/12/asyncio/"/>
    <id>https://blog.writeathink.cn/2018/03/12/asyncio/</id>
    <published>2018-03-12T01:51:27.000Z</published>
    <updated>2018-03-19T08:29:15.938Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p class="description">python协程的演化<br></p><p><img src="" alt="" style="width:100%"></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><div class="note info"><p></p><p>Python由于众所周知的<code>GIL</code>的原因,同一时刻只能有一个线程在运行，那么对于CPU密集的程序来说，线程之间的切换开销就成了拖累，而以I/O为瓶颈的程序正是协程所擅长的：</p><p>多任务并发（非并行），每个任务在合适的时候挂起（发起I/O）和恢复(I/O结束)*</p><p>Python中的协程经历了很长的一段发展历程。其大概经历了如下三个阶段：</p><ol><li>最初的生成器进化的yield/send</li><li>python3.4引入@asyncio.coroutine和yield from</li><li>在Python3.5版本中引入async/await关键字</li></ol><p></p></div><br><a id="more"></a></p><h2 id="yield-send"><a href="#yield-send" class="headerlink" title="yield/send"></a>yield/send</h2><p>我们用斐波那契数列做个例子</p><h3 id="传统的方式"><a href="#传统的方式" class="headerlink" title="传统的方式"></a>传统的方式</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normal_fib</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="string">"""返回斐波那契数列前n项"""</span></span><br><span class="line">    res = [<span class="number">0</span>] * n</span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    a, b = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> index &lt; n:</span><br><span class="line">        res[index] = b</span><br><span class="line">        a, b = b, a + b</span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line">print(<span class="string">'-'</span>*<span class="number">10</span> + <span class="string">'test old fib'</span> + <span class="string">'-'</span>*<span class="number">10</span>)</span><br><span class="line"><span class="keyword">for</span> fib_res <span class="keyword">in</span> normal_fib(<span class="number">20</span>):</span><br><span class="line">    print(fib_res)</span><br></pre></td></tr></table></figure><p>如果我们仅仅是需要拿到斐波那契序列的第n位，或者仅仅是希望依此产生斐波那契序列，那么上面这种传统方式就会比较耗费内存。这时生成器的特性就派上用场了—&gt; <code>yield</code>!!!</p><h3 id="yield"><a href="#yield" class="headerlink" title="yield"></a>yield</h3><p>我们用<code>yield</code>实现菲波那切数列。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_fib</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="string">"""斐波那契数列生成器"""</span></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    a, b = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> index &lt; n:</span><br><span class="line">        <span class="keyword">yield</span> b</span><br><span class="line">        a, b = b, a + b</span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'-'</span>*<span class="number">10</span> + <span class="string">'test yield fib'</span> + <span class="string">'-'</span>*<span class="number">10</span>)</span><br><span class="line"><span class="keyword">for</span> fib_res <span class="keyword">in</span> fib(<span class="number">20</span>):</span><br><span class="line">    print(fib_res)</span><br></pre></td></tr></table></figure><p>当一个函数中包含<code>yield</code>语句时，python会自动将其识别为一个生成器。这时fib(20)并不会真正调用函数体，而是以函数体生成了一个生成器对象实例。</p><p><code>yield</code>在这里可以保留<code>gen_fib</code>函数的计算现场，暂停<code>gen_fib</code>的计算并将b返回。而将fib放入<code>for…in</code>循环中时，每次循环都会调用<code>next(fib(20))</code>，唤醒生成器，执行到下一个<code>yield</code>语句处，直到抛出<code>StopIteration</code>异常。此异常会被for循环捕获，导致跳出循环。</p><h3 id="send"><a href="#send" class="headerlink" title="send"></a>send</h3><p><code>send</code> 事件驱动，生成器进化成协程</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">coro_fib</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="string">"""斐波那契协程,send一个间隔时间，产出一个值"""</span></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    a, b = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> index &lt; n:</span><br><span class="line">        sleep_sec = <span class="keyword">yield</span> b  <span class="comment"># 产出b，将send值绑定到sleep_sec,</span></span><br><span class="line">        print(<span class="string">'wait &#123;&#125; secs.'</span>.format(sleep_sec))</span><br><span class="line">        time.sleep(sleep_sec)</span><br><span class="line">        a, b = b, a + b</span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'-'</span>*<span class="number">10</span> + <span class="string">'test yield send'</span> + <span class="string">'-'</span>*<span class="number">10</span>)</span><br><span class="line">N = <span class="number">20</span></span><br><span class="line">cfib = coro_fib(N)</span><br><span class="line">fib_res = next(cfib)  <span class="comment"># 预激协程,运行至yield处暂停</span></span><br><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">    print(fib_res)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        fib_res = cfib.send(random.uniform(<span class="number">0</span>, <span class="number">0.5</span>))  <span class="comment"># send驱动协程, 修改合适的时间清楚执行过程</span></span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure><p>协程更多详细信息请移步<a href="coroutine.md">python coroutine</a>这里~</p><h3 id="yield-from"><a href="#yield-from" class="headerlink" title="yield from"></a>yield from</h3><p><code>yield from</code>用于重构生成器，简单的，可以这么使用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">copy_fib</span><span class="params">(n)</span>:</span></span><br><span class="line">    print(<span class="string">'I am copy from gen_fib'</span>)</span><br><span class="line">    <span class="keyword">yield</span> <span class="keyword">from</span> gen_fib(n)  <span class="comment"># 委派给gen_fib生成器</span></span><br><span class="line">    print(<span class="string">'Copy end'</span>)</span><br><span class="line">print(<span class="string">'-'</span>*<span class="number">10</span> + <span class="string">'test yield from'</span> + <span class="string">'-'</span>*<span class="number">10</span>)</span><br><span class="line"><span class="keyword">for</span> fib_res <span class="keyword">in</span> copy_fib(<span class="number">20</span>):</span><br><span class="line">    print(fib_res)</span><br></pre></td></tr></table></figure><p>这种使用方式很简单，但远远不是<code>yield from</code>的全部。<code>yield from</code>的作用还体现可以像一个管道一样将<code>send</code>信息传递给内层协程，并且<strong>处理好了各种异常情况</strong>，因此，对于<code>coro_fib</code>也可以这样包装和使用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">copy_coro_fib</span><span class="params">(n)</span>:</span></span><br><span class="line">    print(<span class="string">'I am copy from coro_fib'</span>)</span><br><span class="line">    <span class="keyword">yield</span> <span class="keyword">from</span> coro_fib(n)  <span class="comment"># 委托给coro_fib,异常也交由它处理</span></span><br><span class="line">    print(<span class="string">'Copy end'</span>)</span><br><span class="line">print(<span class="string">'-'</span>*<span class="number">10</span> + <span class="string">'test yield from and send'</span> + <span class="string">'-'</span>*<span class="number">10</span>)</span><br><span class="line">N = <span class="number">20</span></span><br><span class="line">ccfib = copy_coro_fib(N)</span><br><span class="line">fib_res = next(ccfib)</span><br><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">    print(fib_res)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        fib_res = ccfib.send(random.uniform(<span class="number">0</span>, <span class="number">0.5</span>))</span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure><h2 id="asyncio-yield-from"><a href="#asyncio-yield-from" class="headerlink" title="asyncio/yield from"></a>asyncio/yield from</h2><p><code>asyncio</code>是一个基于事件循环的实现<code>异步I/O</code>的模块。通过<code>yield from</code>，我们可以将协程的控制权交给事件循环，然后挂起当前协程；之后，由事件循环决定何时唤醒协程,接着向后执行代码。</p><p>使用<code>asyncio.coroutine</code>装饰器</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 并发处理两个快慢不一的斐波那契生成函数</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@asyncio.coroutine</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fast_fib</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="string">"""smart one"""</span></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    a, b = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> index &lt; n:</span><br><span class="line">        sleep_secs = random.uniform(<span class="number">0</span>, <span class="number">0.2</span>)</span><br><span class="line">        <span class="keyword">yield</span> <span class="keyword">from</span> asyncio.sleep(sleep_secs)</span><br><span class="line">        print(<span class="string">'Fast one think &#123;&#125; secs to get &#123;&#125;'</span>.format(sleep_secs, b))</span><br><span class="line">        a, b = b, a + b</span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">slow_fib</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="string">"""slow one"""</span></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    a, b = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> index &lt; n:</span><br><span class="line">        sleep_secs = random.uniform(<span class="number">0</span>, random_sec)</span><br><span class="line">        <span class="keyword">yield</span> <span class="keyword">from</span> asyncio.sleep(sleep_secs)</span><br><span class="line">        print(<span class="string">'Slow one think &#123;&#125; secs to get &#123;&#125;'</span>.format(sleep_secs, b))</span><br><span class="line">        a, b = b, a + b</span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    loop = asyncio.get_event_loop()  <span class="comment"># 获取时间循环的引用</span></span><br><span class="line">    tasks = [</span><br><span class="line">        asyncio.ensure_future(fast_fib(<span class="number">10</span>)),</span><br><span class="line">        asyncio.ensure_future(slow_fib(<span class="number">10</span>))  </span><br><span class="line">        <span class="comment"># ensure_future 和create_task都可以，asyncio.async过时了</span></span><br><span class="line">        <span class="comment"># loop.create_task(fast_fib(10)),</span></span><br><span class="line">        <span class="comment"># loop.create_task(slow_fib(10)) </span></span><br><span class="line">    ]</span><br><span class="line">    loop.run_until_complete(asyncio.wait(tasks)) </span><br><span class="line">    print(<span class="string">'All fib finished.'</span>)</span><br><span class="line">    loop.close()</span><br></pre></td></tr></table></figure><p>运行结果如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">Fast one think 0.0393240884371622 secs to get 21</span><br><span class="line">Slow one think 0.12157996704037113 secs to get 5</span><br><span class="line">Fast one think 0.08259000223641344 secs to get 34</span><br><span class="line">Slow one think 0.15816909012449587 secs to get 8</span><br><span class="line">Fast one think 0.1967429201039252 secs to get 55</span><br><span class="line">Slow one think 0.25365548691367573 secs to get 13</span><br><span class="line">Slow one think 0.3235222687782598 secs to get 21</span><br><span class="line">Slow one think 0.35160632142878434 secs to get 34</span><br><span class="line">Slow one think 0.34477299780059134 secs to get 55</span><br><span class="line">All fib finished.</span><br></pre></td></tr></table></figure><h2 id="async-await"><a href="#async-await" class="headerlink" title="async/await"></a>async/await</h2><p>清楚了<code>asyncio.coroutine</code>和<code>yield from</code>之后，在Python3.5中引入的<code>async</code>和<code>await</code>就不难理解了：<br>可以将他们理解成<code>asyncio.coroutine/yield from</code>的完美替身。当然，从Python设计的角度来说，<code>async/await</code>让协程表面上独立于生成器而存在，将细节都隐藏于<code>asyncio</code>模块之下，语法更清晰明了。</p><p>async/await 示例:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 async/await 关键字</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">fast_fib</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="string">"""smart one"""</span></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    a, b = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> index &lt; n:</span><br><span class="line">        sleep_secs = random.uniform(<span class="number">0</span>, <span class="number">0.2</span>)</span><br><span class="line">        <span class="keyword">await</span> asyncio.sleep(sleep_secs)</span><br><span class="line">        print(<span class="string">'Fast one think &#123;&#125; secs to get &#123;&#125;'</span>.format(sleep_secs, b))</span><br><span class="line">        a, b = b, a + b</span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">slow_fib</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="string">"""slow one"""</span></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    a, b = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> index &lt; n:</span><br><span class="line">        sleep_secs = random.uniform(<span class="number">0</span>, random_sec)</span><br><span class="line">        <span class="keyword">await</span> asyncio.sleep(sleep_secs)</span><br><span class="line">        print(<span class="string">'Slow one think &#123;&#125; secs to get &#123;&#125;'</span>.format(sleep_secs, b))</span><br><span class="line">        a, b = b, a + b</span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    loop = asyncio.get_event_loop()  <span class="comment"># 获取时间循环的引用</span></span><br><span class="line">    tasks = [</span><br><span class="line">        asyncio.ensure_future(fast_fib(<span class="number">10</span>)),</span><br><span class="line">        asyncio.ensure_future(slow_fib(<span class="number">10</span>))  </span><br><span class="line">        <span class="comment"># ensure_future 和create_task都可以，asyncio.async过时了</span></span><br><span class="line">        <span class="comment"># loop.create_task(fast_fib(10)),</span></span><br><span class="line">        <span class="comment"># loop.create_task(slow_fib(10)) </span></span><br><span class="line">    ]</span><br><span class="line">    loop.run_until_complete(asyncio.wait(tasks)) </span><br><span class="line">    print(<span class="string">'All fib finished.'</span>)</span><br><span class="line">    loop.close()</span><br></pre></td></tr></table></figure><p>可以发现相比上面<code>yield from</code>的版本只改变了以下两点:</p><ul><li>函数定义前面加了<code>async</code>关键字，更加清晰表明这是一个协程</li><li><code>yield from</code> 换成了<code>await</code>关键字</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>示例程序中都是以sleep为异步I/O的代表，在实际项目中，可以使用协程异步的读写网络、读写文件、渲染界面等，而在等待协程完成的同时，CPU还可以进行其他的计算。协程的作用正在于此。</p>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;python协程的演化&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;&lt;div class=&quot;note info&quot;&gt;&lt;p&gt;&lt;/p&gt;
&lt;p&gt;Python由于众所周知的&lt;code&gt;GIL&lt;/code&gt;的原因,同一时刻只能有一个线程在运行，那么对于CPU密集的程序来说，线程之间的切换开销就成了拖累，而以I/O为瓶颈的程序正是协程所擅长的：&lt;/p&gt;
&lt;p&gt;多任务并发（非并行），每个任务在合适的时候挂起（发起I/O）和恢复(I/O结束)*&lt;/p&gt;
&lt;p&gt;Python中的协程经历了很长的一段发展历程。其大概经历了如下三个阶段：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;最初的生成器进化的yield/send&lt;/li&gt;
&lt;li&gt;python3.4引入@asyncio.coroutine和yield from&lt;/li&gt;
&lt;li&gt;在Python3.5版本中引入async/await关键字&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;/p&gt;&lt;/div&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Python" scheme="https://blog.writeathink.cn/categories/Python/"/>
    
      <category term="进程线程协程" scheme="https://blog.writeathink.cn/categories/Python/%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E5%8D%8F%E7%A8%8B/"/>
    
    
      <category term="yield from" scheme="https://blog.writeathink.cn/tags/yield-from/"/>
    
      <category term="yield/send" scheme="https://blog.writeathink.cn/tags/yield-send/"/>
    
      <category term="asyncio.coroutine" scheme="https://blog.writeathink.cn/tags/asyncio-coroutine/"/>
    
      <category term="async/await" scheme="https://blog.writeathink.cn/tags/async-await/"/>
    
      <category term="asyncio" scheme="https://blog.writeathink.cn/tags/asyncio/"/>
    
  </entry>
  
  <entry>
    <title>Python 并发 concurrent.futures</title>
    <link href="https://blog.writeathink.cn/2018/02/06/concurrent-futures/"/>
    <id>https://blog.writeathink.cn/2018/02/06/concurrent-futures/</id>
    <published>2018-02-06T09:02:42.000Z</published>
    <updated>2018-03-12T02:09:49.015Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p class="description">考虑用concurrent.futures来实现平行计算或并发处理<br></p><p><img src="" alt="" style="width:100%"></p><h2 id="导读"><a href="#导读" class="headerlink" title="导读"></a>导读</h2><p><div class="note info"><p><br>编写Python程序时,我们可以利用CPU的多核心通过平行计算来提升计算任务的速度。很遗憾，Python的全局解释器(<code>GIL</code>)的存在使得我们没有办法用<code>线程</code>实现真正的平行计算。</p><p>为了实现平行计算，我们可以考虑用C语言扩展或者使用诸如<code>Cython</code>和<code>Numba</code>等开源工具迁移到C语言。但是这样做大幅增加了测试量和风险。于是我们思考一下：有没有一种更好的方式，只需使用少量的Python代码，即可有效提升执行效率，并迅速解决复杂的计算问题。</p><p>我们可以试着通过内置的<code>concurrent.futures</code>模块来利用内置的<code>multiprocessing</code>模块实现这种需求。这样的做法会以子进程的形式，平行运行多个解释器，从而利用多核心CPU来提升执行速度(子进程与主解释器相分离，所以它们的全局解释器锁也是相互独立的)。<br></p></div><br><a id="more"></a><br>我们可以通过下面的例子来看一下效果。</p><h2 id="计算两数最大公约数"><a href="#计算两数最大公约数" class="headerlink" title="计算两数最大公约数"></a>计算两数最大公约数</h2><p>现在给出一个列表，列表里每个元素是一对数，求出每对数的最大公约数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">numbers = [(<span class="number">1963309</span>, <span class="number">2265973</span>), (<span class="number">2030677</span>, <span class="number">3814172</span>),</span><br><span class="line">            (<span class="number">1551645</span>, <span class="number">2229620</span>), (<span class="number">2039045</span>, <span class="number">2020802</span>)]</span><br></pre></td></tr></table></figure><h3 id="没有做平行计算的版本"><a href="#没有做平行计算的版本" class="headerlink" title="没有做平行计算的版本"></a>没有做平行计算的版本</h3><figure class="highlight python"><figcaption><span>求最大公约数</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gcd</span><span class="params">(pair)</span>:</span></span><br><span class="line">    a, b = pair</span><br><span class="line">    low = min(a, b)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(low, <span class="number">0</span>, <span class="number">-1</span>):</span><br><span class="line">        <span class="keyword">if</span> a % i == <span class="number">0</span> <span class="keyword">and</span> b % i == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> i</span><br></pre></td></tr></table></figure><p>我们用map来试运行一下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line">start = time.time()</span><br><span class="line">results = list(map(gcd, numbers))</span><br><span class="line">end = time.time()</span><br><span class="line">print(<span class="string">'Took %.3f seconds'</span> % (end - start))</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">Took <span class="number">0.530</span> seconds</span><br></pre></td></tr></table></figure><p>下面我们用conccurrent.futures来模拟多线程和多进程</p><h3 id="使用concurretn-futures的ThreadPoolExecutor"><a href="#使用concurretn-futures的ThreadPoolExecutor" class="headerlink" title="使用concurretn.futures的ThreadPoolExecutor"></a>使用<code>concurretn.futures</code>的<code>ThreadPoolExecutor</code></h3><figure class="highlight python"><figcaption><span>使用ThreadPoolExecutor多线程</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> concurrent.futures <span class="keyword">import</span> ThreadPoolExecutor</span><br><span class="line">start = time.time()</span><br><span class="line">pool = ThreadPoolExecutor(max_workers=<span class="number">2</span>) <span class="comment"># cpu核心数目个工作线程 </span></span><br><span class="line">results = list(pool.map(gcd, numbers))</span><br><span class="line">end = time.time()</span><br><span class="line">print(<span class="string">'Took %.3f seconds'</span> % (end - start))</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">Took <span class="number">0.535</span> seconds</span><br></pre></td></tr></table></figure><p>两个线程用了和上面差不多的时间，而且比上面还慢一些，说明多线程并不能平行计算，而且开线程也有耗费。</p><h3 id="使用concurrent-futures的ProcessPoollExecutor"><a href="#使用concurrent-futures的ProcessPoollExecutor" class="headerlink" title="使用concurrent.futures的ProcessPoollExecutor"></a>使用<code>concurrent.futures</code>的<code>ProcessPoollExecutor</code></h3><figure class="highlight python"><figcaption><span>将ThreadPoolExecutor换成ProcessPoolExecutor</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> concurrent.futures <span class="keyword">import</span> ProcessPoolExecutor</span><br><span class="line">start = time.time()</span><br><span class="line">pool = ProcessPoolExecutor(max_workers=<span class="number">2</span>) <span class="comment"># cpu核心数目个工作进程 </span></span><br><span class="line">results = list(pool.map(gcd, numbers))</span><br><span class="line">end = time.time()</span><br><span class="line">print(<span class="string">'Took %.3f seconds'</span> % (end - start))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span></span><br><span class="line">Took <span class="number">0.287</span> seconds</span><br></pre></td></tr></table></figure><p>在双核电脑上运行上面程序发现比之前两个版本运行快很多。这是因为<code>ProcessPoolExecutor</code>会利用<code>multiprocessing</code>模块所提供的的底层机制来逐步完成下列操作：</p><ol><li>把numbers列表中的每一项输入数据都传给map</li><li>用pickle模块对数据进行序列化，将其变成二进制形式。</li><li>通过本地套接字socket将序列化后的数据从主解释器所在的进程发送到子解释器所在的进程。</li><li>接下来在子进程中，用pickle对二进制数据进行反序列化操作,将其还原为Python对象</li><li>引入包含gcd函数的那个Python模块</li><li>各条子进程平行地针对各自的输入数据，来运行gcd函数</li><li>对运行结果进行序列化操作，将其变为字节</li><li>将这些字节通过socket复制到主进程中</li><li>主进程对这些字节执行反序列化操作，将其还原为Python对象。</li><li>最后，把每条子进程所求出的计算结果合并到一份列表中，返回给调用者</li></ol><h3 id="编后语"><a href="#编后语" class="headerlink" title="编后语"></a>编后语</h3><p>为了实现平行计算，<code>multiprocessing</code>模块和<code>ProcessPoolExecutor</code>类在幕后做了大量的工作。如果改用其他的语言来写，那么开发者只需一把同步锁或一项原子操作，就可以把线程之间的通信过程协调好。而在Python中，我们却必须使用开销较高的<code>multiprocessing</code>模块,其开销之所以大，原因就在于主进程与子进程之间，必须进行序列化和反序列化操作，这些是导致大量开销的来源。</p><p>对于某些较为孤立，且数据利用率高的任务来说，上述方案非常适合。如果执行的运算不符合上述特征，那么<code>multiprocessing</code>所产生的的开销可能并不能使程序加速。在这种情况下，可以求助multiprocessing所提供的的一些高级机制，如内存共享(<code>shared memory</code>)、跨进程锁定(<code>cross-process lock</code>)、队列(<code>queue</code>)和代理(<code>proxy</code>)等。</p><h2 id="下载进度条显示"><a href="#下载进度条显示" class="headerlink" title="下载进度条显示"></a>下载进度条显示</h2><p>用<code>concurrent.futures</code>的<code>ThreadPoolExecutor</code>类处理对于大量I/O操作的并发任务的示例。非常值得参考的实现。</p><p>flags_common.py是一些默认参数和函数接口以及argparse。<br>flags_sequential.py是单线程依序下载以及进度条显示实现。<br>flags_threadpool.py是利用concurrent.futures的多线程操作实现。</p><ul><li>flags_common.py</li></ul><figure class="highlight python"><figcaption><span>flags_common.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""Utilities for second set of flag examples.</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line"><span class="keyword">from</span> enum <span class="keyword">import</span> Enum</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Result = namedtuple(<span class="string">'Result'</span>, <span class="string">'status data'</span>)</span><br><span class="line"></span><br><span class="line">HTTPStatus = Enum(<span class="string">'Status'</span>, <span class="string">'ok not_found error'</span>)</span><br><span class="line"></span><br><span class="line">POP20_CC = (<span class="string">'CN IN US ID BR PK NG BD RU JP '</span></span><br><span class="line">            <span class="string">'MX PH VN ET EG DE IR TR CD FR'</span>).split()</span><br><span class="line"></span><br><span class="line">DEFAULT_CONCUR_REQ = <span class="number">1</span></span><br><span class="line">MAX_CONCUR_REQ = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">SERVERS = &#123;</span><br><span class="line">    <span class="string">'REMOTE'</span>: <span class="string">'http://flupy.org/data/flags'</span>,</span><br><span class="line">    <span class="string">'LOCAL'</span>:  <span class="string">'http://localhost:8001/flags'</span>,</span><br><span class="line">    <span class="string">'DELAY'</span>:  <span class="string">'http://localhost:8002/flags'</span>,</span><br><span class="line">    <span class="string">'ERROR'</span>:  <span class="string">'http://localhost:8003/flags'</span>,</span><br><span class="line">&#125;</span><br><span class="line">DEFAULT_SERVER = <span class="string">'LOCAL'</span></span><br><span class="line"></span><br><span class="line">DEST_DIR = <span class="string">'downloads/'</span></span><br><span class="line">COUNTRY_CODES_FILE = <span class="string">'country_codes.txt'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_flag</span><span class="params">(img, filename)</span>:</span></span><br><span class="line">    path = os.path.join(DEST_DIR, filename)</span><br><span class="line">    <span class="keyword">with</span> open(path, <span class="string">'wb'</span>) <span class="keyword">as</span> fp:</span><br><span class="line">        fp.write(img)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initial_report</span><span class="params">(cc_list, actual_req, server_label)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(cc_list) &lt;= <span class="number">10</span>:</span><br><span class="line">        cc_msg = <span class="string">', '</span>.join(cc_list)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        cc_msg = <span class="string">'from &#123;&#125; to &#123;&#125;'</span>.format(cc_list[<span class="number">0</span>], cc_list[<span class="number">-1</span>])</span><br><span class="line">    print(<span class="string">'&#123;&#125; site: &#123;&#125;'</span>.format(server_label, SERVERS[server_label]))</span><br><span class="line">    msg = <span class="string">'Searching for &#123;&#125; flag&#123;&#125;: &#123;&#125;'</span></span><br><span class="line">    plural = <span class="string">'s'</span> <span class="keyword">if</span> len(cc_list) != <span class="number">1</span> <span class="keyword">else</span> <span class="string">''</span></span><br><span class="line">    print(msg.format(len(cc_list), plural, cc_msg))</span><br><span class="line">    plural = <span class="string">'s'</span> <span class="keyword">if</span> actual_req != <span class="number">1</span> <span class="keyword">else</span> <span class="string">''</span></span><br><span class="line">    msg = <span class="string">'&#123;&#125; concurrent connection&#123;&#125; will be used.'</span></span><br><span class="line">    print(msg.format(actual_req, plural))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">final_report</span><span class="params">(cc_list, counter, start_time)</span>:</span></span><br><span class="line">    elapsed = time.time() - start_time</span><br><span class="line">    print(<span class="string">'-'</span> * <span class="number">20</span>)</span><br><span class="line">    msg = <span class="string">'&#123;&#125; flag&#123;&#125; downloaded.'</span></span><br><span class="line">    plural = <span class="string">'s'</span> <span class="keyword">if</span> counter[HTTPStatus.ok] != <span class="number">1</span> <span class="keyword">else</span> <span class="string">''</span></span><br><span class="line">    print(msg.format(counter[HTTPStatus.ok], plural))</span><br><span class="line">    <span class="keyword">if</span> counter[HTTPStatus.not_found]:</span><br><span class="line">        print(counter[HTTPStatus.not_found], <span class="string">'not found.'</span>)</span><br><span class="line">    <span class="keyword">if</span> counter[HTTPStatus.error]:</span><br><span class="line">        plural = <span class="string">'s'</span> <span class="keyword">if</span> counter[HTTPStatus.error] != <span class="number">1</span> <span class="keyword">else</span> <span class="string">''</span></span><br><span class="line">        print(<span class="string">'&#123;&#125; error&#123;&#125;.'</span>.format(counter[HTTPStatus.error], plural))</span><br><span class="line">    print(<span class="string">'Elapsed time: &#123;:.2f&#125;s'</span>.format(elapsed))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">expand_cc_args</span><span class="params">(every_cc, all_cc, cc_args, limit)</span>:</span></span><br><span class="line">    codes = set()</span><br><span class="line">    A_Z = string.ascii_uppercase</span><br><span class="line">    <span class="keyword">if</span> every_cc:</span><br><span class="line">        codes.update(a+b <span class="keyword">for</span> a <span class="keyword">in</span> A_Z <span class="keyword">for</span> b <span class="keyword">in</span> A_Z)</span><br><span class="line">    <span class="keyword">elif</span> all_cc:</span><br><span class="line">        <span class="keyword">with</span> open(COUNTRY_CODES_FILE) <span class="keyword">as</span> fp:</span><br><span class="line">            text = fp.read()</span><br><span class="line">        codes.update(text.split())</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> cc <span class="keyword">in</span> (c.upper() <span class="keyword">for</span> c <span class="keyword">in</span> cc_args):</span><br><span class="line">            <span class="keyword">if</span> len(cc) == <span class="number">1</span> <span class="keyword">and</span> cc <span class="keyword">in</span> A_Z:</span><br><span class="line">                codes.update(cc+c <span class="keyword">for</span> c <span class="keyword">in</span> A_Z)</span><br><span class="line">            <span class="keyword">elif</span> len(cc) == <span class="number">2</span> <span class="keyword">and</span> all(c <span class="keyword">in</span> A_Z <span class="keyword">for</span> c <span class="keyword">in</span> cc):</span><br><span class="line">                codes.add(cc)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                msg = <span class="string">'each CC argument must be A to Z or AA to ZZ.'</span></span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">'*** Usage error: '</span>+msg)</span><br><span class="line">    <span class="keyword">return</span> sorted(codes)[:limit]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_args</span><span class="params">(default_concur_req)</span>:</span></span><br><span class="line">    server_options = <span class="string">', '</span>.join(sorted(SERVERS))</span><br><span class="line">    parser = argparse.ArgumentParser(</span><br><span class="line">                description=<span class="string">'Download flags for country codes. '</span></span><br><span class="line">                <span class="string">'Default: top 20 countries by population.'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'cc'</span>, metavar=<span class="string">'CC'</span>, nargs=<span class="string">'*'</span>,</span><br><span class="line">                help=<span class="string">'country code or 1st letter (eg. B for BA...BZ)'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'-a'</span>, <span class="string">'--all'</span>, action=<span class="string">'store_true'</span>,</span><br><span class="line">                help=<span class="string">'get all available flags (AD to ZW)'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'-e'</span>, <span class="string">'--every'</span>, action=<span class="string">'store_true'</span>,</span><br><span class="line">                help=<span class="string">'get flags for every possible code (AA...ZZ)'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'-l'</span>, <span class="string">'--limit'</span>, metavar=<span class="string">'N'</span>, type=int,</span><br><span class="line">                help=<span class="string">'limit to N first codes'</span>, default=sys.maxsize)</span><br><span class="line">    parser.add_argument(<span class="string">'-m'</span>, <span class="string">'--max_req'</span>, metavar=<span class="string">'CONCURRENT'</span>, type=int,</span><br><span class="line">                default=default_concur_req,</span><br><span class="line">                help=<span class="string">'maximum concurrent requests (default=&#123;&#125;)'</span></span><br><span class="line">                      .format(default_concur_req))</span><br><span class="line">    parser.add_argument(<span class="string">'-s'</span>, <span class="string">'--server'</span>, metavar=<span class="string">'LABEL'</span>,</span><br><span class="line">                default=DEFAULT_SERVER,</span><br><span class="line">                help=<span class="string">'Server to hit; one of &#123;&#125; (default=&#123;&#125;)'</span></span><br><span class="line">                      .format(server_options, DEFAULT_SERVER))</span><br><span class="line">    parser.add_argument(<span class="string">'-v'</span>, <span class="string">'--verbose'</span>, action=<span class="string">'store_true'</span>,</span><br><span class="line">                help=<span class="string">'output detailed progress info'</span>)</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line">    <span class="keyword">if</span> args.max_req &lt; <span class="number">1</span>:</span><br><span class="line">        print(<span class="string">'*** Usage error: --max_req CONCURRENT must be &gt;= 1'</span>)</span><br><span class="line">        parser.print_usage()</span><br><span class="line">        sys.exit(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> args.limit &lt; <span class="number">1</span>:</span><br><span class="line">        print(<span class="string">'*** Usage error: --limit N must be &gt;= 1'</span>)</span><br><span class="line">        parser.print_usage()</span><br><span class="line">        sys.exit(<span class="number">1</span>)</span><br><span class="line">    args.server = args.server.upper()</span><br><span class="line">    <span class="keyword">if</span> args.server <span class="keyword">not</span> <span class="keyword">in</span> SERVERS:</span><br><span class="line">        print(<span class="string">'*** Usage error: --server LABEL must be one of'</span>,</span><br><span class="line">              server_options)</span><br><span class="line">        parser.print_usage()</span><br><span class="line">        sys.exit(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        cc_list = expand_cc_args(args.every, args.all, args.cc, args.limit)</span><br><span class="line">    <span class="keyword">except</span> ValueError <span class="keyword">as</span> exc:</span><br><span class="line">        print(exc.args[<span class="number">0</span>])</span><br><span class="line">        parser.print_usage()</span><br><span class="line">        sys.exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> cc_list:</span><br><span class="line">        cc_list = sorted(POP20_CC)</span><br><span class="line">    <span class="keyword">return</span> args, cc_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(download_many, default_concur_req, max_concur_req)</span>:</span></span><br><span class="line">    args, cc_list = process_args(default_concur_req)</span><br><span class="line">    actual_req = min(args.max_req, max_concur_req, len(cc_list))</span><br><span class="line">    initial_report(cc_list, actual_req, args.server)</span><br><span class="line">    base_url = SERVERS[args.server]</span><br><span class="line">    t0 = time.time()</span><br><span class="line">    counter = download_many(cc_list, base_url, args.verbose, actual_req)</span><br><span class="line">    <span class="keyword">assert</span> sum(counter.values()) == len(cc_list), \</span><br><span class="line">        <span class="string">'some downloads are unaccounted for'</span></span><br><span class="line">    final_report(cc_list, counter, t0)</span><br></pre></td></tr></table></figure><ul><li>falgs_sequential.py</li></ul><figure class="highlight python"><figcaption><span>flags_sequential.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""Download flags of countries (with error handling).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Sequential version</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Sample run::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    $ python3 flags_sequential.py -s DELAY b</span></span><br><span class="line"><span class="string">    DELAY site: http://localhost:8002/flags</span></span><br><span class="line"><span class="string">    Searching for 26 flags: from BA to BZ</span></span><br><span class="line"><span class="string">    1 concurrent connection will be used.</span></span><br><span class="line"><span class="string">    --------------------</span></span><br><span class="line"><span class="string">    17 flags downloaded.</span></span><br><span class="line"><span class="string">    9 not found.</span></span><br><span class="line"><span class="string">    Elapsed time: 13.36s</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> flags_common <span class="keyword">import</span> main, save_flag, HTTPStatus, Result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">DEFAULT_CONCUR_REQ = <span class="number">1</span></span><br><span class="line">MAX_CONCUR_REQ = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># BEGIN FLAGS2_BASIC_HTTP_FUNCTIONS</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_flag</span><span class="params">(base_url, cc)</span>:</span></span><br><span class="line">    url = <span class="string">'&#123;&#125;/&#123;cc&#125;/&#123;cc&#125;.gif'</span>.format(base_url, cc=cc.lower())</span><br><span class="line">    resp = requests.get(url)</span><br><span class="line">    <span class="keyword">if</span> resp.status_code != <span class="number">200</span>:  <span class="comment"># &lt;1&gt;</span></span><br><span class="line">        resp.raise_for_status()</span><br><span class="line">    <span class="keyword">return</span> resp.content</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_one</span><span class="params">(cc, base_url, verbose=False)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        image = get_flag(base_url, cc)</span><br><span class="line">    <span class="keyword">except</span> requests.exceptions.HTTPError <span class="keyword">as</span> exc:  <span class="comment"># &lt;2&gt;</span></span><br><span class="line">        res = exc.response</span><br><span class="line">        <span class="keyword">if</span> res.status_code == <span class="number">404</span>:</span><br><span class="line">            status = HTTPStatus.not_found  <span class="comment"># &lt;3&gt;</span></span><br><span class="line">            msg = <span class="string">'not found'</span></span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># &lt;4&gt;</span></span><br><span class="line">            <span class="keyword">raise</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        save_flag(image, cc.lower() + <span class="string">'.gif'</span>)</span><br><span class="line">        status = HTTPStatus.ok</span><br><span class="line">        msg = <span class="string">'OK'</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> verbose:  <span class="comment"># &lt;5&gt;</span></span><br><span class="line">        print(cc, msg)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Result(status, cc)  <span class="comment"># &lt;6&gt;</span></span><br><span class="line"><span class="comment"># END FLAGS2_BASIC_HTTP_FUNCTIONS</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># BEGIN FLAGS2_DOWNLOAD_MANY_SEQUENTIAL</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_many</span><span class="params">(cc_list, base_url, verbose, max_req)</span>:</span></span><br><span class="line">    counter = collections.Counter()  <span class="comment"># &lt;1&gt;</span></span><br><span class="line">    cc_iter = sorted(cc_list)  <span class="comment"># &lt;2&gt;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> verbose:</span><br><span class="line">        cc_iter = tqdm.tqdm(cc_iter)  <span class="comment"># &lt;3&gt;</span></span><br><span class="line">    <span class="keyword">for</span> cc <span class="keyword">in</span> cc_iter:  <span class="comment"># &lt;4&gt;</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            res = download_one(cc, base_url, verbose)  <span class="comment"># &lt;5&gt;</span></span><br><span class="line">        <span class="keyword">except</span> requests.exceptions.HTTPError <span class="keyword">as</span> exc:  <span class="comment"># &lt;6&gt;</span></span><br><span class="line">            error_msg = <span class="string">'HTTP error &#123;res.status_code&#125; - &#123;res.reason&#125;'</span></span><br><span class="line">            error_msg = error_msg.format(res=exc.response)</span><br><span class="line">        <span class="keyword">except</span> requests.exceptions.ConnectionError <span class="keyword">as</span> exc:  <span class="comment"># &lt;7&gt;</span></span><br><span class="line">            error_msg = <span class="string">'Connection error'</span></span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># &lt;8&gt;</span></span><br><span class="line">            error_msg = <span class="string">''</span></span><br><span class="line">            status = res.status</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> error_msg:</span><br><span class="line">            status = HTTPStatus.error  <span class="comment"># &lt;9&gt;</span></span><br><span class="line">        counter[status] += <span class="number">1</span>  <span class="comment"># &lt;10&gt;</span></span><br><span class="line">        <span class="keyword">if</span> verbose <span class="keyword">and</span> error_msg: <span class="comment"># &lt;11&gt;</span></span><br><span class="line">            print(<span class="string">'*** Error for &#123;&#125;: &#123;&#125;'</span>.format(cc, error_msg))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> counter  <span class="comment"># &lt;12&gt;</span></span><br><span class="line"><span class="comment"># END FLAGS2_DOWNLOAD_MANY_SEQUENTIAL</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main(download_many, DEFAULT_CONCUR_REQ, MAX_CONCUR_REQ)</span><br></pre></td></tr></table></figure><ul><li>flags_threadpool.py</li></ul><figure class="highlight python"><figcaption><span>flags_threadpool.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""Download flags of countries (with error handling).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ThreadPool version</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Sample run::</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    $ python3 flags_threadpool.py -s REMOTE -e</span></span><br><span class="line"><span class="string">    ERROR site: http://localhost:8003/flags</span></span><br><span class="line"><span class="string">    Searching for 676 flags: from AA to ZZ</span></span><br><span class="line"><span class="string">    30 concurrent connections will be used.</span></span><br><span class="line"><span class="string">    --------------------</span></span><br><span class="line"><span class="string">    150 flags downloaded.</span></span><br><span class="line"><span class="string">    361 not found.</span></span><br><span class="line"><span class="string">    165 errors.</span></span><br><span class="line"><span class="string">    Elapsed time: 7.46s</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># BEGIN FLAGS2_THREADPOOL</span></span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">from</span> concurrent <span class="keyword">import</span> futures</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> tqdm  <span class="comment"># &lt;1&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> flags_common <span class="keyword">import</span> main, HTTPStatus  <span class="comment"># &lt;2&gt;</span></span><br><span class="line"><span class="keyword">from</span> flags_sequential <span class="keyword">import</span> download_one  <span class="comment"># &lt;3&gt;</span></span><br><span class="line"></span><br><span class="line">DEFAULT_CONCUR_REQ = <span class="number">30</span>  <span class="comment"># &lt;4&gt;</span></span><br><span class="line">MAX_CONCUR_REQ = <span class="number">1000</span>  <span class="comment"># &lt;5&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_many</span><span class="params">(cc_list, base_url, verbose, concur_req)</span>:</span></span><br><span class="line">    counter = collections.Counter()</span><br><span class="line">    <span class="keyword">with</span> futures.ThreadPoolExecutor(max_workers=concur_req) <span class="keyword">as</span> executor:  <span class="comment"># &lt;6&gt;</span></span><br><span class="line">        to_do_map = &#123;&#125;  <span class="comment"># &lt;7&gt;</span></span><br><span class="line">        <span class="keyword">for</span> cc <span class="keyword">in</span> sorted(cc_list):  <span class="comment"># &lt;8&gt;</span></span><br><span class="line">            future = executor.submit(download_one,</span><br><span class="line">                            cc, base_url, verbose)  <span class="comment"># &lt;9&gt;</span></span><br><span class="line">            to_do_map[future] = cc  <span class="comment"># &lt;10&gt;</span></span><br><span class="line">        done_iter = futures.as_completed(to_do_map)  <span class="comment"># &lt;11&gt;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> verbose:</span><br><span class="line">            done_iter = tqdm.tqdm(done_iter, total=len(cc_list))  <span class="comment"># &lt;12&gt;</span></span><br><span class="line">        <span class="keyword">for</span> future <span class="keyword">in</span> done_iter:  <span class="comment"># &lt;13&gt;</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                res = future.result()  <span class="comment"># &lt;14&gt;</span></span><br><span class="line">            <span class="keyword">except</span> requests.exceptions.HTTPError <span class="keyword">as</span> exc:  <span class="comment"># &lt;15&gt;</span></span><br><span class="line">                error_msg = <span class="string">'HTTP &#123;res.status_code&#125; - &#123;res.reason&#125;'</span></span><br><span class="line">                error_msg = error_msg.format(res=exc.response)</span><br><span class="line">            <span class="keyword">except</span> requests.exceptions.ConnectionError <span class="keyword">as</span> exc:</span><br><span class="line">                error_msg = <span class="string">'Connection error'</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                error_msg = <span class="string">''</span></span><br><span class="line">                status = res.status</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> error_msg:</span><br><span class="line">                status = HTTPStatus.error</span><br><span class="line">            counter[status] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> verbose <span class="keyword">and</span> error_msg:</span><br><span class="line">                cc = to_do_map[future]  <span class="comment"># &lt;16&gt;</span></span><br><span class="line">                print(<span class="string">'*** Error for &#123;&#125;: &#123;&#125;'</span>.format(cc, error_msg))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> counter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main(download_many, DEFAULT_CONCUR_REQ, MAX_CONCUR_REQ)</span><br><span class="line"><span class="comment"># END FLAGS2_THREADPOOL</span></span><br></pre></td></tr></table></figure><h2 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h2>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;考虑用concurrent.futures来实现平行计算或并发处理&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;导读&quot;&gt;&lt;a href=&quot;#导读&quot; class=&quot;headerlink&quot; title=&quot;导读&quot;&gt;&lt;/a&gt;导读&lt;/h2&gt;&lt;p&gt;&lt;div class=&quot;note info&quot;&gt;&lt;p&gt;&lt;br&gt;编写Python程序时,我们可以利用CPU的多核心通过平行计算来提升计算任务的速度。很遗憾，Python的全局解释器(&lt;code&gt;GIL&lt;/code&gt;)的存在使得我们没有办法用&lt;code&gt;线程&lt;/code&gt;实现真正的平行计算。&lt;/p&gt;
&lt;p&gt;为了实现平行计算，我们可以考虑用C语言扩展或者使用诸如&lt;code&gt;Cython&lt;/code&gt;和&lt;code&gt;Numba&lt;/code&gt;等开源工具迁移到C语言。但是这样做大幅增加了测试量和风险。于是我们思考一下：有没有一种更好的方式，只需使用少量的Python代码，即可有效提升执行效率，并迅速解决复杂的计算问题。&lt;/p&gt;
&lt;p&gt;我们可以试着通过内置的&lt;code&gt;concurrent.futures&lt;/code&gt;模块来利用内置的&lt;code&gt;multiprocessing&lt;/code&gt;模块实现这种需求。这样的做法会以子进程的形式，平行运行多个解释器，从而利用多核心CPU来提升执行速度(子进程与主解释器相分离，所以它们的全局解释器锁也是相互独立的)。&lt;br&gt;&lt;/p&gt;&lt;/div&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Python" scheme="https://blog.writeathink.cn/categories/Python/"/>
    
      <category term="进程线程协程" scheme="https://blog.writeathink.cn/categories/Python/%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E5%8D%8F%E7%A8%8B/"/>
    
    
      <category term="concurrent.futures" scheme="https://blog.writeathink.cn/tags/concurrent-futures/"/>
    
      <category term="ProcessPoolExecutor" scheme="https://blog.writeathink.cn/tags/ProcessPoolExecutor/"/>
    
      <category term="ThreadPoolExecutor" scheme="https://blog.writeathink.cn/tags/ThreadPoolExecutor/"/>
    
      <category term="multiprocessing" scheme="https://blog.writeathink.cn/tags/multiprocessing/"/>
    
  </entry>
  
  <entry>
    <title>Python协程-coroutine</title>
    <link href="https://blog.writeathink.cn/2018/01/30/coroutine/"/>
    <id>https://blog.writeathink.cn/2018/01/30/coroutine/</id>
    <published>2018-01-30T02:45:38.000Z</published>
    <updated>2018-03-01T09:35:10.701Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p class="description">考虑用协程来并发的运行多个函数<br></p><p><img src="" alt="" style="width:100%"></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><div class="note primary"><p><br>我们可以用线程来运行多个函数，使这些函数看上去好像是在同一时间得到执行的。然而，线程有<code>三</code>个显著的缺点：<br><ul><br><li><i class="fa fa-minus-square"></i> 为了确保数据安全，我们必须使用特殊的工具(<code>Lock</code>, <code>Queue</code>等)来协调这些线程，这使得多线程的代码，要比单线程的过程式代码更加难懂。这些复杂的多线程代码，会逐渐令程序变得难以扩展和维护。</li><br><li><i class="fa fa-minus-square"></i> 线程需要<code>占用大量内存</code>，每个正在执行的线程，大约占据<code>8MB</code>内存。如果只开十几个线程，多数计算机还是可以承受的。</li><br><li><i class="fa fa-minus-square"></i> 线程<code>启动的开销比较大</code>。如果程序不停地依靠创建新线程来同时执行多个函数，并等待这些线程结束，那么使用线程所引发的开销，就会拖慢整个程序的速度。</li><br></ul></p></div><a id="more"></a><p>Python的<code>协程(coroutine)</code>可以避免上述问题，它使得Python程序看上去好像是在同时运行多个函数。协程的实现方式，实际上是对生成器的一种扩展。启动生成器协程所需的开销，与调用函数的开销相仿。处于活跃状态的协程，在其耗尽之前，只会占用不到<code>1KB</code>的内存。</p><h2 id="协程的工作原理"><a href="#协程的工作原理" class="headerlink" title="协程的工作原理"></a>协程的工作原理</h2><p>每当生成器函数执行到<code>yield</code>表达式的时候，消耗生成器的那段代码，就通过<code>send</code>方法给生成器回传一个值。而生成器在手熬了经由send函数所传进来的这个值后，这个值会绑定给<code>yield</code>关键字左边的变量；如果<code>yield</code>关键字右边有表达式，那么<code>yield</code>表达式右侧的内容会当成send方法的返回值(没有的话其实返回的是<code>None</code>)，返回给外界(调用方).关键的一点是，协程在 <code>yield</code> 关键字所在的位置暂停执行。在赋值语句中， <code>=</code> 右边的代码在赋值之前执行。下面我们结合两个例子来看看。</p><h3 id="简单的协程示例"><a href="#简单的协程示例" class="headerlink" title="简单的协程示例"></a>简单的协程示例</h3><figure class="highlight python"><figcaption><span>简单协程示例</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_coroutine</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        received = <span class="keyword">yield</span></span><br><span class="line">        print(<span class="string">'Received:'</span>, received)</span><br><span class="line"></span><br><span class="line">it = my_coroutine()</span><br><span class="line">next(it)  <span class="comment"># 1</span></span><br><span class="line">it.send(<span class="string">'First'</span>)  <span class="comment"># 2</span></span><br><span class="line">it.send(<span class="string">'Second'</span>)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">Received: First</span><br><span class="line">Received: Second</span><br></pre></td></tr></table></figure><p><i class="fa fa-pencil"></i>注1: 在生成器上面调用<code>send</code>方法，我们要先调用next函数(这叫<code>预激协程</code>)，以便将生成器推进到第一条<code>yield</code>表达式那里</p><h3 id="协程产出值"><a href="#协程产出值" class="headerlink" title="协程产出值"></a>协程产出值</h3><p>该示例在协程每收到一个数值，就会产出当前所统计到的最大值</p><figure class="highlight python"><figcaption><span>协程产出值</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maximize</span><span class="params">()</span>:</span></span><br><span class="line">    current = <span class="keyword">yield</span>  <span class="comment"># 1</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        value = <span class="keyword">yield</span> current  <span class="comment"># 2</span></span><br><span class="line">        current = max(value, current)  <span class="comment"># 3</span></span><br><span class="line"></span><br><span class="line">it = maximize()</span><br><span class="line">next(it)  <span class="comment"># 预激协程，执行到第一个yield处</span></span><br><span class="line">print(it.send(<span class="number">10</span>)) <span class="comment"># 执行到#2处产出current值，等待接收值</span></span><br><span class="line">print(it.send(<span class="number">12</span>)) <span class="comment"># 绑定12给value，计算current，执行到#2处产出current值，等待接收值</span></span><br><span class="line">print(it.send(<span class="number">4</span>))  <span class="comment"># 同上，即执行到yield表达式右边，等待左边输入绑定</span></span><br><span class="line">print(it.send(<span class="number">22</span>))</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="number">10</span></span><br><span class="line"><span class="number">12</span></span><br><span class="line"><span class="number">12</span></span><br><span class="line"><span class="number">22</span></span><br></pre></td></tr></table></figure><p>上面的代码范例中，第一条<code>yield</code>语句中的<code>yield</code>关键字后面没有跟随内容，其意思是，把外面传进来的首个值，当成目前的最大值。<br>此后生成器会屡次执行while循环中的那条<code>yield</code>语句，以便将当前统计到的最大值告诉外界，同时等候外界传入下一个待考察的值。</p><div class="note info"><p>协程在yield关键字所在的位置暂停执行。在赋值语句中， = 右边的代码在赋值之前执行。即各个阶段都在yield表达式中结束，先产出值然后在yield出暂停，等待外界传入值。下一个阶段都从那一行代码开始</p></div><h2 id="yield-from"><a href="#yield-from" class="headerlink" title="yield from"></a>yield from</h2><p>协程可以通过yield的输出值来推进其他的生成器函数，使得那些生成器函数也执行到它们各自的下一条yield比到时处。接连推进多个独立的生成器，即可模拟出Python线程的并发行为，令程序看上去好像是在同时运行多个函数</p><h3 id="使用yield-from计算平均值并输出统计报告"><a href="#使用yield-from计算平均值并输出统计报告" class="headerlink" title="使用yield from计算平均值并输出统计报告"></a>使用yield from计算平均值并输出统计报告</h3><p>从一个字典中读取虚构的七年级男女学生的体重和身高。例如，’boys;m’ 键对应于 9 个男学生的身高（单位是米）， ‘girls;kg’ 键对应于 10 个女学生的体重（单位是千克）。这个脚本把各组数据传给前面定义的 averager 协程，然后生成一个报告。</p><figure class="highlight python"><figcaption><span>使用yield from计算平均值并输出统计报告</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""使用yield from计算平均值并输出统计报告"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line"></span><br><span class="line">Result = namedtuple(<span class="string">'Result'</span>, <span class="string">'count average'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 子生成器</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">averager</span><span class="params">()</span>:</span>  <span class="comment"># 1</span></span><br><span class="line">    total = <span class="number">0.0</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    average = <span class="keyword">None</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        term = <span class="keyword">yield</span>  <span class="comment"># 2</span></span><br><span class="line">        <span class="keyword">if</span> term <span class="keyword">is</span> <span class="keyword">None</span>:  <span class="comment"># 3</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        total += term</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">        average = total / count</span><br><span class="line">    <span class="keyword">return</span> Result(count, average)  <span class="comment"># 4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 委派生成器</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">grouper</span><span class="params">(results, key)</span>:</span>  <span class="comment"># 5</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:  <span class="comment"># 6</span></span><br><span class="line">        results[key] = <span class="keyword">yield</span> <span class="keyword">from</span> averager()  <span class="comment"># 7</span></span><br><span class="line"><span class="comment"># 客户端代码，即调用方</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(data)</span>:</span>  <span class="comment"># 8</span></span><br><span class="line">    results = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> key, values <span class="keyword">in</span> data.items():</span><br><span class="line">        group = grouper(results, key)  <span class="comment"># 9</span></span><br><span class="line">        next(group)  <span class="comment"># 10</span></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> values:</span><br><span class="line">            group.send(value)  <span class="comment"># 11</span></span><br><span class="line">        group.send(<span class="keyword">None</span>)  <span class="comment"># 重要！ 12</span></span><br><span class="line">    print(results)  <span class="comment"># 如果要调试，去掉注释</span></span><br><span class="line">    report(results)</span><br><span class="line"><span class="comment"># 输出报告</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">report</span><span class="params">(results)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> key, result <span class="keyword">in</span> sorted(results.items()):</span><br><span class="line">        group, unit = key.split(<span class="string">';'</span>)</span><br><span class="line">        print(<span class="string">'&#123;:2&#125; &#123;:5&#125; averaging &#123;:.2f&#125;&#123;&#125;'</span>.format(</span><br><span class="line">            result.count, group, result.average, unit))</span><br><span class="line"></span><br><span class="line">DATA = &#123;</span><br><span class="line">    <span class="string">'girls;kg'</span>: [<span class="number">40.9</span>, <span class="number">38.5</span>, <span class="number">44.3</span>, <span class="number">42.2</span>, <span class="number">45.2</span>, <span class="number">41.7</span>, <span class="number">44.5</span>, <span class="number">38.0</span>, <span class="number">40.6</span>, <span class="number">44.5</span>],</span><br><span class="line">    <span class="string">'girls;m'</span>: [<span class="number">1.6</span>, <span class="number">1.51</span>, <span class="number">1.4</span>, <span class="number">1.3</span>, <span class="number">1.41</span>, <span class="number">1.39</span>, <span class="number">1.33</span>, <span class="number">1.46</span>, <span class="number">1.45</span>, <span class="number">1.43</span>],</span><br><span class="line">    <span class="string">'boys;kg'</span>: [<span class="number">39.0</span>, <span class="number">40.8</span>, <span class="number">43.2</span>, <span class="number">40.8</span>, <span class="number">43.1</span>, <span class="number">38.6</span>, <span class="number">41.4</span>, <span class="number">40.6</span>, <span class="number">36.3</span>],</span><br><span class="line">    <span class="string">'boys;m'</span>: [<span class="number">1.38</span>, <span class="number">1.5</span>, <span class="number">1.32</span>, <span class="number">1.25</span>, <span class="number">1.37</span>, <span class="number">1.48</span>, <span class="number">1.25</span>, <span class="number">1.49</span>, <span class="number">1.46</span>],</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main(DATA)</span><br></pre></td></tr></table></figure><div class="note info"><p><br>1-  与示例 16-13 中的 averager 协程一样。这里作为子生成器使用。<br>2-  main 函数中的客户代码发送的各个值绑定到这里的 term 变量上。<br>3-  至关重要的终止条件。如果不这么做，使用 yield from 调用这个协程的生成器会永<br>远阻塞。<br>4- 返回的 Result 会成为 grouper 函数中 yield from 表达式的值。<br>5-  grouper 是委派生成器。<br>6-  这个循环每次迭代时会新建一个 averager 实例；每个实例都是作为协程使用的生成器对象。<br>7-  grouper 发送的每个值都会经由 yield from 处理，通过管道传给 averager 实例。 grouper 会在 yield from 表达式处暂停，等待 averager 实例处理客户端发来的值。 averager 实例运行完毕后，返回的值绑定到 results[key] 上。 while 循环会不断创建 averager 实例，处理更多的值。<br>8- main 函数是客户端代码，用 PEP 380 定义的术语来说，是“调用方”。这是驱动一切的函数<br>9- group 是调用 grouper 函数得到的生成器对象，传给 grouper 函数的第一个参数是results，用于收集结果；第二个参数是某个键。 group 作为协程使用。<br>10- 预激 group 协程。<br>11- 把各个 value 传给 grouper。传入的值最终到达 averager 函数中 term = yield 那一行； grouper 永远不知道传入的值是什么。<br>12- 把 None 传入 grouper，导致当前的 averager 实例终止，也让 grouper 继续运行，再创建一个 averager 实例，处理下一组值。<br></p></div><h2 id="生命游戏：演示协程的协同运作效果。"><a href="#生命游戏：演示协程的协同运作效果。" class="headerlink" title="生命游戏：演示协程的协同运作效果。"></a>生命游戏：演示协程的协同运作效果。</h2><h3 id="游戏规则"><a href="#游戏规则" class="headerlink" title="游戏规则"></a>游戏规则</h3><ul><li>在一个任意尺寸的二维网格中，每个细胞(即每个单元格)都处于<code>生存(alive,用*表示)</code>或<code>空白(empty,用-表示)</code>状态。</li><li>时钟每走一步，生命游戏就向前进一步。向前推进时，我们要点算每个细胞周边的那八个单元格，看看该细胞附近有多少个存活的细胞。然后根据存活的数量来判断自己下一轮是继续存活、死亡还是再生。</li><li>具体判断规则<ul><li>若本细胞存活，且周围存活者不足两个，则本细胞下一轮死亡。</li><li>若本细胞存活，且周围的存活者多于3个，则本细胞下一轮死亡。</li><li>若本细胞死亡，且周围的存活者恰有3个，则本细胞下一轮再生。</li></ul></li></ul><h3 id="建模"><a href="#建模" class="headerlink" title="建模"></a>建模</h3><p>基于规则我们可以将整个程序分成三个阶段:<code>count_neighbors</code>, <code>step_cell</code>, <code>display</code></p><ul><li>count_neighbors: 计算每个细胞附近8个细胞存活的数目</li><li>step_cell: 根据细胞本轮状态和计算得到周围的细胞数量生成下一轮的状态</li><li>根据每轮的结果显示细胞状态</li></ul><h4 id="count-neighbors"><a href="#count-neighbors" class="headerlink" title="count_neighbors"></a>count_neighbors</h4><p>我们定义一个协程来获取周围细胞的生存状态。协程会产生一个自定义的<code>Query</code>对象，每个<code>yield</code>表达式的结果，要么是<code>ALIVE</code>，要么是<code>EMPTY</code>。其后count_neighbors生成器会根据相邻细胞的状态，来返回本细胞周围的存活细胞数(生成器return语句在python3中才可用，实际是把结果作为StopIteration异常的value属性传给了调用者)</p><figure class="highlight python"><figcaption><span>count_neighbors协程计算细胞周围的存活数目</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line"></span><br><span class="line">ALIVE = <span class="string">'*'</span></span><br><span class="line">EMPTY = <span class="string">'-'</span></span><br><span class="line"></span><br><span class="line">Query = namedtuple(<span class="string">'Query'</span>, (<span class="string">'y'</span>, <span class="string">'x'</span>))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count_neighbors</span><span class="params">(y, x)</span>:</span></span><br><span class="line">    n_ = <span class="keyword">yield</span> Query(y + <span class="number">1</span>, x + <span class="number">0</span>)  <span class="comment"># North</span></span><br><span class="line">    ne = <span class="keyword">yield</span> Query(y + <span class="number">1</span>, x + <span class="number">1</span>)  <span class="comment"># Northeast</span></span><br><span class="line">    e_ = <span class="keyword">yield</span> Query(y + <span class="number">0</span>, x + <span class="number">1</span>)  <span class="comment"># East</span></span><br><span class="line">    se = <span class="keyword">yield</span> Query(y - <span class="number">1</span>, x + <span class="number">1</span>)  <span class="comment"># Southeast</span></span><br><span class="line">    s_ = <span class="keyword">yield</span> Query(y - <span class="number">1</span>, x + <span class="number">0</span>)  <span class="comment"># South</span></span><br><span class="line">    sw = <span class="keyword">yield</span> Query(y - <span class="number">1</span>, x - <span class="number">1</span>)  <span class="comment"># Southwest</span></span><br><span class="line">    w_ = <span class="keyword">yield</span> Query(y + <span class="number">0</span>, x - <span class="number">1</span>)  <span class="comment"># West</span></span><br><span class="line">    nw = <span class="keyword">yield</span> Query(y + <span class="number">1</span>, x - <span class="number">1</span>)  <span class="comment"># Northwest</span></span><br><span class="line">    neighbor_states = [n_, ne, e_, se, s_, sw, w_, nw]</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> state <span class="keyword">in</span> neighbor_states:</span><br><span class="line">        <span class="keyword">if</span> state == ALIVE:</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> count</span><br></pre></td></tr></table></figure><p>我们用虚构的数据来测试一下这个count_neighbors协程.<br>下面这段代码，会针对本细胞的每个相邻细胞，向生成器索要一个<code>Query</code>对象，并产出<code>Query namedtuple</code>。然后通过<code>send</code>方法把状态发给协程，使<code>count_neighbors</code>协程可以收到上一个<code>Query</code>对象所对应的状态(注意我们上文提到的<code>yield</code>表达式一行执行顺序–先右再左)</p><figure class="highlight python"><figcaption><span>测试count_neighbors协程</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>it = count_neighbors(<span class="number">10</span>, <span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>next(it)  <span class="comment"># Get the first query, for q1</span></span><br><span class="line">Query(y=<span class="number">11</span>, x=<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>it.send(ALIVE)  <span class="comment"># Send q1 state, get q2</span></span><br><span class="line">Query(y=<span class="number">11</span>, x=<span class="number">6</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>it.send(ALIVE)  <span class="comment"># Send q2 state, get q3</span></span><br><span class="line">Query(y=<span class="number">10</span>, x=<span class="number">6</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span> <span class="comment"># Send q3 ... q7 states, get q4 ... q8</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>[it.send(state) <span class="keyword">for</span> state <span class="keyword">in</span> (EMPTY)*<span class="number">5</span>]  <span class="comment"># doctest: +ELLIPSIS</span></span><br><span class="line">[Query(y=<span class="number">9</span>, x=<span class="number">6</span>), Query(y=<span class="number">9</span>, x=<span class="number">5</span>), ..., Query(y=<span class="number">11</span>, x=<span class="number">4</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">try</span>:</span><br><span class="line"><span class="meta">... </span>    it.send(EMPTY)  <span class="comment"># Send q8 state, drive coroutine to end</span></span><br><span class="line"><span class="meta">... </span><span class="keyword">except</span> StopIteration <span class="keyword">as</span> e:</span><br><span class="line"><span class="meta">... </span>    count = e.value  <span class="comment"># Value from return statement</span></span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>count</span><br><span class="line"><span class="number">2</span></span><br></pre></td></tr></table></figure><h4 id="step-cell"><a href="#step-cell" class="headerlink" title="step_cell"></a>step_cell</h4><p>计算出了细胞周围的存活数量，我们就需要根据这个数量来更新细胞的状态。并把得到的状态传给外部调用者。<br>这里我们自定义了一个<code>Transition</code>对象，它表示坐标位于(y,x)的细胞的下一轮的状态。</p><figure class="highlight python"><figcaption><span>step_cell根据count_neighbors计算出来的存活状态数量产生下一轮的状态</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Transition = namedtuple(<span class="string">'Transition'</span>, (<span class="string">'y'</span>, <span class="string">'x'</span>, <span class="string">'state'</span>))  <span class="comment"># state即是下一轮的状态</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">step_cell</span><span class="params">(y, x)</span>:</span></span><br><span class="line">    current_state = <span class="keyword">yield</span> Query(y, x) <span class="comment"># 获取当前状态</span></span><br><span class="line">    neighbors = <span class="keyword">yield</span> <span class="keyword">from</span> count_neighbors(y, x)  <span class="comment"># 委派给子生成器count_neighbors </span></span><br><span class="line">    next_state = game_logic(state, neighbors)  <span class="comment"># game_logic根据规则判断下一轮状态</span></span><br><span class="line">    <span class="keyword">yield</span> Transition(y, x, next_state)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">game_logic</span><span class="params">(state, neighbors)</span>:</span></span><br><span class="line">    <span class="comment"># 这里其实我们可以使用是否等于3来简化判断</span></span><br><span class="line">    <span class="keyword">if</span> state == ALIVE:</span><br><span class="line">        <span class="keyword">if</span> neighbors &lt; <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> EMPTY     <span class="comment"># Die: Too few</span></span><br><span class="line">        <span class="keyword">elif</span> neighbors &gt; <span class="number">3</span>:</span><br><span class="line">            <span class="keyword">return</span> EMPTY     <span class="comment"># Die: Too many</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> neighbors == <span class="number">3</span>:</span><br><span class="line">            <span class="keyword">return</span> ALIVE     <span class="comment"># Regenerate</span></span><br><span class="line">    <span class="keyword">return</span> state</span><br></pre></td></tr></table></figure><p>下面我们用虚拟数据来测试一下<code>step_cell</code>协程：</p><figure class="highlight python"><figcaption><span>测试step_cell协程</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>it = step_cell(<span class="number">10</span>, <span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>next(it)  <span class="comment"># Initial location query</span></span><br><span class="line">Query(y=<span class="number">10</span>, x=<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>[it.send(st) <span class="keyword">for</span> st <span class="keyword">in</span> (ALIVE)*<span class="number">5</span> + (EMPTY)*<span class="number">3</span>]   <span class="comment"># doctest: +ELLIPSIS</span></span><br><span class="line">[Query(y=<span class="number">11</span>, x=<span class="number">5</span>), Query(y=<span class="number">11</span>, x=<span class="number">6</span>), ... Query(y=<span class="number">11</span>, x=<span class="number">4</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>it.send(EMPTY)  <span class="comment"># Send q8 state, get game decision</span></span><br><span class="line">Transition(y=<span class="number">10</span>, x=<span class="number">5</span>, state=<span class="string">'-'</span>)</span><br></pre></td></tr></table></figure><p>上面演示了在网格中一个细胞的一次前进。下面我们把<code>step_cell</code>组合到新的<code>simulate</code>协程之中。新的协程会多次通过yield from 表达式，来推进网格中的每一个细胞。把每个细胞处理完后，<code>simulate</code>协程会产生<code>TICK</code>对象，用以表示当前这一代的细胞已经全部迁移完毕。</p><figure class="highlight python"><figcaption><span>simulate</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">TICK = object()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">simulate</span><span class="params">(height, width)</span>:</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        <span class="keyword">for</span> y <span class="keyword">in</span> range(height):</span><br><span class="line">            <span class="keyword">for</span> x <span class="keyword">in</span> range(width):</span><br><span class="line">                <span class="keyword">yield</span> <span class="keyword">from</span> step_cell(y, x)  <span class="comment"># 委派给子生成器step_cell</span></span><br><span class="line">        <span class="keyword">yield</span> TICK</span><br></pre></td></tr></table></figure><h4 id="网格显示状态"><a href="#网格显示状态" class="headerlink" title="网格显示状态"></a>网格显示状态</h4><p>为了在真实环境中运行<code>simulate</code>，我们需要把网格中的每个细胞状态表示出来。我们定义一个Grid类，来代表整张网格：</p><figure class="highlight python"><figcaption><span>Grid类显示网格和细胞状态</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Grid</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, height, width)</span>:</span></span><br><span class="line">        self.height = height</span><br><span class="line">        self.width = width</span><br><span class="line">        self.rows = []</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> range(self.height):</span><br><span class="line">            self.rows.append([EMPTY] * self.width)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">        output = <span class="string">''</span></span><br><span class="line">        <span class="keyword">for</span> row <span class="keyword">in</span> self.rows:</span><br><span class="line">            <span class="keyword">for</span> cell <span class="keyword">in</span> row:</span><br><span class="line">                output += cell</span><br><span class="line">            output += <span class="string">'\n'</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, position)</span>:</span></span><br><span class="line">        y, x = position</span><br><span class="line">        <span class="comment"># 如果传入的坐标值越界，我们用取余来自动折回</span></span><br><span class="line">        <span class="keyword">return</span> self.rows[y % self.height][x % self.width]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__setitem__</span><span class="params">(self, position, state)</span>:</span></span><br><span class="line">        y, x = position</span><br><span class="line">        self.rows[y % self.height][x % self.width] = state</span><br></pre></td></tr></table></figure><p>我们定义了<code>__getitem__</code>和<code>__setitem__</code>两个元方法来设置和获取<code>state</code>。下面我们看一下<code>Grid</code>的显示：</p><figure class="highlight python"><figcaption><span>根据参数Grid生成网格和状态</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>grid = Grid(<span class="number">5</span>, <span class="number">9</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>grid[<span class="number">0</span>, <span class="number">3</span>] = ALIVE</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>grid[<span class="number">1</span>, <span class="number">4</span>] = ALIVE</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>grid[<span class="number">2</span>, <span class="number">2</span>] = ALIVE</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>grid[<span class="number">2</span>, <span class="number">3</span>] = ALIVE</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>grid[<span class="number">2</span>, <span class="number">4</span>] = ALIVE</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(grid)</span><br><span class="line">---*-----</span><br><span class="line">----*----</span><br><span class="line">--***----</span><br><span class="line">---------</span><br><span class="line">---------</span><br></pre></td></tr></table></figure><h4 id="live-a-generation"><a href="#live-a-generation" class="headerlink" title="live_a_generation"></a>live_a_generation</h4><p>这个函数把网格内的所有细胞都向前推进一步，待各细胞状态迁移完成后，这些细胞就构成了一张新的网格，该函数会把新的网格返回给调用者。</p><figure class="highlight python"><figcaption><span>live_a_generation</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">live_a_generation</span><span class="params">(grid, sim)</span>:</span></span><br><span class="line">    <span class="comment"># grid: 现阶段网格对象；sim: simulate生成器对象</span></span><br><span class="line">    progeny = Grid(grid.height, grid.width)  <span class="comment"># 下一代网格对象 </span></span><br><span class="line">    item = next(sim)</span><br><span class="line">    <span class="keyword">while</span> item <span class="keyword">is</span> <span class="keyword">not</span> TICK:</span><br><span class="line">        <span class="keyword">if</span> isinstance(item, Query):  <span class="comment">#计算附近细胞</span></span><br><span class="line">            state = grid[item.y, item.x]</span><br><span class="line">            item = sim.send(state)</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># Must be a Transition，附近细胞算完了,得到Transition对象</span></span><br><span class="line">            progeny[item.y, item.x] = item.state</span><br><span class="line">            item = next(sim) <span class="comment"># 生成器运行到下一个yield处，即simulate的下一个坐标处</span></span><br><span class="line">    <span class="keyword">return</span> progeny  <span class="comment">#返回下一轮的网格对象</span></span><br></pre></td></tr></table></figure><p><code>live_a_generation</code>是将当前细胞向前推进一步，现在我们把每一代的结果都显示出来</p><figure class="highlight python"><figcaption><span>ColumnPrinter</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ColumnPrinter</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.columns = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">append</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        self.columns.append(data)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">        row_count = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> self.columns:</span><br><span class="line">            row_count = max(row_count, len(data.splitlines()) + <span class="number">1</span>)</span><br><span class="line">        rows = [<span class="string">''</span>] * row_count</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(row_count):</span><br><span class="line">            <span class="keyword">for</span> i, data <span class="keyword">in</span> enumerate(self.columns):</span><br><span class="line">                line = data.splitlines()[max(<span class="number">0</span>, j - <span class="number">1</span>)]</span><br><span class="line">                <span class="keyword">if</span> j == <span class="number">0</span>:</span><br><span class="line">                    rows[j] += str(i).center(len(line))</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    rows[j] += line</span><br><span class="line">                <span class="keyword">if</span> (i + <span class="number">1</span>) &lt; len(self.columns):</span><br><span class="line">                    rows[j] += <span class="string">' | '</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">'\n'</span>.join(rows)</span><br></pre></td></tr></table></figure><p>我们来看看效果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>columns = ColumnPrinter()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sim = simulate(grid.height, grid.width)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line"><span class="meta">... </span>    columns.append(str(grid))</span><br><span class="line"><span class="meta">... </span>    grid = live_a_generation(grid, sim)</span><br><span class="line">...</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(columns)  <span class="comment"># doctest: +NORMALIZE_WHITESPACE</span></span><br><span class="line">    <span class="number">0</span>     |     <span class="number">1</span>     |     <span class="number">2</span>     |     <span class="number">3</span>     |     <span class="number">4</span></span><br><span class="line">---*----- | --------- | --------- | --------- | ---------</span><br><span class="line">----*---- | --*-*---- | ----*---- | ---*----- | ----*----</span><br><span class="line">--***---- | ---**---- | --*-*---- | ----**--- | -----*---</span><br><span class="line">--------- | ---*----- | ---**---- | ---**---- | ---***---</span><br><span class="line">--------- | --------- | --------- | --------- | ---------</span><br></pre></td></tr></table></figure><p>上面这套的实现方式，其最大优势在于：开发者能够在不修改game_logic函数的前提下，更新该函数外围的那些代码。<br>上面这套范例代码，演示了如何用协程来分离程序中的各个关注点，而关注点的分离，正是一条重要的原则。</p><h2 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h2>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;考虑用协程来并发的运行多个函数&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;div class=&quot;note primary&quot;&gt;&lt;p&gt;&lt;br&gt;我们可以用线程来运行多个函数，使这些函数看上去好像是在同一时间得到执行的。然而，线程有&lt;code&gt;三&lt;/code&gt;个显著的缺点：&lt;br&gt;&lt;ul&gt;&lt;br&gt;&lt;li&gt;&lt;i class=&quot;fa fa-minus-square&quot;&gt;&lt;/i&gt; 为了确保数据安全，我们必须使用特殊的工具(&lt;code&gt;Lock&lt;/code&gt;, &lt;code&gt;Queue&lt;/code&gt;等)来协调这些线程，这使得多线程的代码，要比单线程的过程式代码更加难懂。这些复杂的多线程代码，会逐渐令程序变得难以扩展和维护。&lt;/li&gt;&lt;br&gt;&lt;li&gt;&lt;i class=&quot;fa fa-minus-square&quot;&gt;&lt;/i&gt; 线程需要&lt;code&gt;占用大量内存&lt;/code&gt;，每个正在执行的线程，大约占据&lt;code&gt;8MB&lt;/code&gt;内存。如果只开十几个线程，多数计算机还是可以承受的。&lt;/li&gt;&lt;br&gt;&lt;li&gt;&lt;i class=&quot;fa fa-minus-square&quot;&gt;&lt;/i&gt; 线程&lt;code&gt;启动的开销比较大&lt;/code&gt;。如果程序不停地依靠创建新线程来同时执行多个函数，并等待这些线程结束，那么使用线程所引发的开销，就会拖慢整个程序的速度。&lt;/li&gt;&lt;br&gt;&lt;/ul&gt;&lt;/p&gt;&lt;/div&gt;
    
    </summary>
    
      <category term="Python" scheme="https://blog.writeathink.cn/categories/Python/"/>
    
      <category term="进程线程协程" scheme="https://blog.writeathink.cn/categories/Python/%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E5%8D%8F%E7%A8%8B/"/>
    
    
      <category term="yield" scheme="https://blog.writeathink.cn/tags/yield/"/>
    
      <category term="coroutine" scheme="https://blog.writeathink.cn/tags/coroutine/"/>
    
      <category term="yield from" scheme="https://blog.writeathink.cn/tags/yield-from/"/>
    
  </entry>
  
  <entry>
    <title>SparkMLlib-Advanced-Topics</title>
    <link href="https://blog.writeathink.cn/2018/01/23/SparkMLlib-Advanced-Topics/"/>
    <id>https://blog.writeathink.cn/2018/01/23/SparkMLlib-Advanced-Topics/</id>
    <published>2018-01-23T02:45:01.000Z</published>
    <updated>2018-03-01T09:35:47.765Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p class="description">线性方法的优化</p><p><img src="" alt="" style="width:100%"></p><p>三种线性方法的优化方法：</p><ul><li><code>Limited-memory BFGS(L-BFGS)</code>有限记忆BFGS</li><li><code>Normal equation solver for weighted least square</code>用于加权最小二乘法的正态方程求解器</li><li><code>Iteratively reweighted least squares(IRLS)</code>迭代重新加权最小二乘</li></ul><a id="more"></a><h2 id="Limited-memory-BFGS-L-BFGS-有限记忆BFGS"><a href="#Limited-memory-BFGS-L-BFGS-有限记忆BFGS" class="headerlink" title="Limited-memory BFGS (L-BFGS)有限记忆BFGS"></a>Limited-memory BFGS (L-BFGS)有限记忆BFGS</h2><p> <code>L-BFGS</code>是<code>拟牛顿方法家族</code>里的一个优化算法，解决<code>min w∈R d f(w)</code>形式的优化问题。<code>L-BFGS</code>方法以二次方程来逼近目标函数来构造<code>Hessian</code>矩阵，不考虑目标函数的二阶偏导数。<code>Hessian</code>矩阵由先前的迭代评估逼近，所以不像直接使用牛顿方法一样可垂直扩展（训练特征的数目）。所以<code>L-BFGS</code>通常比其他一阶优化方法能更快收敛。</p><p><a href="http://research-srv.microsoft.com/en-us/um/people/jfgao/paper/icml07scalable.pdf" target="_blank" rel="noopener">象限有限记忆拟牛顿(OWL-QN)</a>算法是L-BFGS的扩展，它可以有效处理L1和弹性网格正则化。<code>L-BFGS</code>在Spark MLlib中用于<code>线性回归</code>、<code>逻辑回归</code>、<code>AFT生存回归</code>和<code>多层感知器的求解</code>。</p><h2 id="Normal-equation-solver-for-weighted-least-square用于加权最小二乘法的正态方程求解器"><a href="#Normal-equation-solver-for-weighted-least-square用于加权最小二乘法的正态方程求解器" class="headerlink" title="Normal equation solver for weighted least square用于加权最小二乘法的正态方程求解器"></a>Normal equation solver for weighted least square用于加权最小二乘法的正态方程求解器</h2><p>MLlib 通过<a href="https://github.com/apache/spark/blob/v2.2.1/mllib/src/main/scala/org/apache/spark/ml/optim/WeightedLeastSquares.scala" target="_blank" rel="noopener">WeightedLeastSquares</a>实现了<a href="https://en.wikipedia.org/wiki/Least_squares#Weighted_least_squares" target="_blank" rel="noopener">加权最小二乘法</a>的方程求解器。</p><p>Spark MLlib目前支持正态方程的两种求解器：<code>Cholesky分解法</code>和拟<code>牛顿法(L-BFGS / OWL-QN)</code>。乔列斯基因式分解依赖于正定的协方差矩阵（即数据矩阵的列必须是线性无关的），并且如果违反这种条件将会失败。即使协方差矩阵不是正定的，准牛顿方法仍然能够提供合理的解，所以在这种情况下，正规方程求解器也可以退回到拟牛顿法。对于<code>LinearRegression</code>和<code>GeneralizedLinearRegression</code>估计，这种回退目前总是启用的。</p><p><code>WeightedLeastSquares</code>支持L1，L2和弹性网络正则化，并提供启用或禁用正则化和标准化的选项。在没有L1正则化的情况下（即α = 0），存在解析解，可以使用乔列斯基(Cholesky)或拟牛顿(Quasi-Newton)求解器。当α &gt; 0时 不存在解析解，而是使用拟牛顿求解器迭代地求出系数。</p><p>为了使正态方程有效，<code>WeightedLeastSquares</code>要求特征数不超过4096个。对于较大的问题，使用<code>L-BFGS</code>代替。</p><h2 id="Iteratively-reweighted-least-squares-IRLS-迭代重新加权最小二乘"><a href="#Iteratively-reweighted-least-squares-IRLS-迭代重新加权最小二乘" class="headerlink" title="Iteratively reweighted least squares (IRLS)迭代重新加权最小二乘"></a>Iteratively reweighted least squares (IRLS)迭代重新加权最小二乘</h2><p>MLlib 通过<a href="https://en.wikipedia.org/wiki/Iteratively_reweighted_least_squares" target="_blank" rel="noopener">IterativelyReweightedLeastSquares</a>实现<a href="https://github.com/apache/spark/blob/v2.2.1/mllib/src/main/scala/org/apache/spark/ml/optim/IterativelyReweightedLeastSquares.scala" target="_blank" rel="noopener">迭代重新加权最小二乘（IRLS）</a>。它可以用来找到广义线性模型(GLM)的最大似然估计，在鲁棒回归和其他优化问题中找到M估计。有关更多信息，请参阅<a href="http://www.jstor.org/stable/2345503" target="_blank" rel="noopener">迭代重新加权的最小二乘法以获得最大似然估计，以及一些鲁棒性和抗性替代方法</a>。</p><p>它通过以下过程迭代地解决某些优化问题：</p><ul><li>线性化目前的解决方案的目标，并更新相应的权重。</li><li>通过WeightedLeastSquares解决加权最小二乘（WLS）问题。</li><li>重复上述步骤直到收敛。</li></ul><p>由于它涉及到<code>WeightedLeastSquares</code>每次迭代求解加权最小二乘（WLS）问题，因此它还要求特征数不超过<code>4096</code>个。目前IRLS被用作<code>GeneralizedLinearRegression</code>的默认求解器。</p><p><strong>更多详细信息请查阅<a href="https://spark.apache.org/docs/latest/ml-advanced.html" target="_blank" rel="noopener">Spark ml-advanced</a></strong></p><h2 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h2>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;线性方法的优化&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
&lt;p&gt;三种线性方法的优化方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Limited-memory BFGS(L-BFGS)&lt;/code&gt;有限记忆BFGS&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Normal equation solver for weighted least square&lt;/code&gt;用于加权最小二乘法的正态方程求解器&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Iteratively reweighted least squares(IRLS)&lt;/code&gt;迭代重新加权最小二乘&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Spark" scheme="https://blog.writeathink.cn/categories/Spark/"/>
    
      <category term="MLlib" scheme="https://blog.writeathink.cn/categories/Spark/MLlib/"/>
    
    
      <category term="线性方法的优化" scheme="https://blog.writeathink.cn/tags/%E7%BA%BF%E6%80%A7%E6%96%B9%E6%B3%95%E7%9A%84%E4%BC%98%E5%8C%96/"/>
    
      <category term="有限记忆BFGS" scheme="https://blog.writeathink.cn/tags/%E6%9C%89%E9%99%90%E8%AE%B0%E5%BF%86BFGS/"/>
    
      <category term="用于加权最小二乘法的正态方程求解器" scheme="https://blog.writeathink.cn/tags/%E7%94%A8%E4%BA%8E%E5%8A%A0%E6%9D%83%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E7%9A%84%E6%AD%A3%E6%80%81%E6%96%B9%E7%A8%8B%E6%B1%82%E8%A7%A3%E5%99%A8/"/>
    
      <category term="迭代重新加权最小二乘" scheme="https://blog.writeathink.cn/tags/%E8%BF%AD%E4%BB%A3%E9%87%8D%E6%96%B0%E5%8A%A0%E6%9D%83%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98/"/>
    
  </entry>
  
  <entry>
    <title>SparkMLlib-ML-Tuning</title>
    <link href="https://blog.writeathink.cn/2018/01/23/SparkMLlib-ML-Tuning/"/>
    <id>https://blog.writeathink.cn/2018/01/23/SparkMLlib-ML-Tuning/</id>
    <published>2018-01-23T02:29:01.000Z</published>
    <updated>2018-03-01T09:37:05.697Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p class="description">模型选择, 超参调整<br></p><p><img src="" alt="" style="width:100%"><br><code>ML Tuning</code>: <code>model selection</code>(模型选择) and <code>hyperparameter tuning</code>(超参调整)<br>本节介绍如何使用MLlib的工具来调整ML算法和管道。内置的交叉验证和其他工具允许用户优化算法和管道中的超参数。</p><a id="more"></a><h2 id="Model-selection-又叫hyperparameter-tuning"><a href="#Model-selection-又叫hyperparameter-tuning" class="headerlink" title="Model selection(又叫hyperparameter tuning)"></a>Model selection(又叫hyperparameter tuning)</h2><p>ML中的一个重要任务是<code>Model Selection</code>(选择模型)，或者使用数据为给定任务找到最佳模型或参数。这也被称为<code>Tuning</code>(调整)。调整可以是以针对三个Estimators算子如LogisticRegression进行调整，也可以对整个Pipeline进行调整。用户可以一次对Pipeline整体进行调整，而不是对Pipeline的每个元素单独进行调整。</p><p>MLlib支持使用<a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.tuning.CrossValidator" target="_blank" rel="noopener">CrossValidator</a>和<a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.tuning.TrainValidationSplit" target="_blank" rel="noopener">TrainValidationSplit</a>的工具进行模型选择。这些工具需要下列项目：</p><ul><li>Estimator: 需要调整的算法或Pipeline</li><li>Set of ParamMaps: 可供选择的参数，有时称为“parameter grid”来搜索</li><li>Evaluator: 度量标准,衡量一个拟合Model在测试数据上的表现</li></ul><p>在较高层面上，这些模型选择工具的工作如下：</p><ul><li>他们将输入数据分成单独的训练和测试数据集。</li><li>对每组训练数据与测试数据对，对参数表集合，用相应参数来拟合估计器，得到训练后的模型，再使用评估器来评估模型表现。</li><li>选择最好的一组参数生成的模型。</li></ul><p>其中，对于回归问题评估器可选择<code>RegressionEvaluator</code>，二值数据可选择<code>BinaryClassificationEvaluator</code>，多分类问题可选择<code>MulticlassClassificationEvaluator</code>。评估器里默认的评估准则可通过<code>setMetricName</code>方法重写。</p><p>用户可通过<a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.tuning.ParamGridBuilder" target="_blank" rel="noopener">ParamGridBuilder</a>构建参数网格。</p><h2 id="Cross-Validation"><a href="#Cross-Validation" class="headerlink" title="Cross-Validation"></a>Cross-Validation</h2><p><code>CrossValidator</code>将数据集划分为若干子集分别地进行训练和测试。如当k＝3时，CrossValidator产生3个训练数据与测试数据对，每个数据对使用2/3的数据来训练，1/3的数据来测试。对于一组特定的参数表，CrossValidator计算基于三组不同训练数据与测试数据对训练得到的模型的评估准则的平均值。确定最佳参数表后，CrossValidator最后使用最佳参数表基于全部数据来重新拟合Estimator。</p><p>示例：</p><p>注意对参数网格进行交叉验证的成本是很高的。如下面例子中，参数网格<code>hashingTF.numFeatures</code>有3个值，<code>lr.regParam</code>有2个值，CrossValidator使用2折交叉验证。这样就会产生<code>(3*2)*2 = 12</code>中不同的模型需要进行训练。在实际的设置中，通常有更多的参数需要设置，且我们可能会使用更多的交叉验证折数（3折或者10折都是经使用的）。所以CrossValidator的成本是很高的，尽管如此，比起启发式的手工验证，交叉验证仍然是目前存在的参数选择方法中非常有用的一种。</p><h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><p>有关API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.tuning.CrossValidator" target="_blank" rel="noopener">CrossValidatorPython</a>文档。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> BinaryClassificationEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> HashingTF, Tokenizer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.tuning <span class="keyword">import</span> CrossValidator, ParamGridBuilder</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"CrossValidatorExample"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Prepare training documents, which are labeled.</span></span><br><span class="line">training = spark.createDataFrame([</span><br><span class="line">    (<span class="number">0</span>, <span class="string">"a b c d e spark"</span>, <span class="number">1.0</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="string">"b d"</span>, <span class="number">0.0</span>),</span><br><span class="line">    (<span class="number">2</span>, <span class="string">"spark f g h"</span>, <span class="number">1.0</span>),</span><br><span class="line">    (<span class="number">3</span>, <span class="string">"hadoop mapreduce"</span>, <span class="number">0.0</span>),</span><br><span class="line">    (<span class="number">4</span>, <span class="string">"b spark who"</span>, <span class="number">1.0</span>),</span><br><span class="line">    (<span class="number">5</span>, <span class="string">"g d a y"</span>, <span class="number">0.0</span>),</span><br><span class="line">    (<span class="number">6</span>, <span class="string">"spark fly"</span>, <span class="number">1.0</span>),</span><br><span class="line">    (<span class="number">7</span>, <span class="string">"was mapreduce"</span>, <span class="number">0.0</span>),</span><br><span class="line">    (<span class="number">8</span>, <span class="string">"e spark program"</span>, <span class="number">1.0</span>),</span><br><span class="line">    (<span class="number">9</span>, <span class="string">"a e c l"</span>, <span class="number">0.0</span>),</span><br><span class="line">    (<span class="number">10</span>, <span class="string">"spark compile"</span>, <span class="number">1.0</span>),</span><br><span class="line">    (<span class="number">11</span>, <span class="string">"hadoop software"</span>, <span class="number">0.0</span>)</span><br><span class="line">], [<span class="string">"id"</span>, <span class="string">"text"</span>, <span class="string">"label"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and lr.</span></span><br><span class="line">tokenizer = Tokenizer(inputCol=<span class="string">"text"</span>, outputCol=<span class="string">"words"</span>)</span><br><span class="line">hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=<span class="string">"features"</span>)</span><br><span class="line">lr = LogisticRegression(maxIter=<span class="number">10</span>)</span><br><span class="line">pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])</span><br><span class="line"></span><br><span class="line"><span class="comment"># We now treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.</span></span><br><span class="line"><span class="comment"># This will allow us to jointly choose parameters for all Pipeline stages.</span></span><br><span class="line"><span class="comment"># A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.</span></span><br><span class="line"><span class="comment"># We use a ParamGridBuilder to construct a grid of parameters to search over.</span></span><br><span class="line"><span class="comment"># With 3 values for hashingTF.numFeatures and 2 values for lr.regParam,</span></span><br><span class="line"><span class="comment"># this grid will have 3 x 2 = 6 parameter settings for CrossValidator to choose from.</span></span><br><span class="line">paramGrid = ParamGridBuilder() \</span><br><span class="line">    .addGrid(hashingTF.numFeatures, [<span class="number">10</span>, <span class="number">100</span>, <span class="number">1000</span>]) \</span><br><span class="line">    .addGrid(lr.regParam, [<span class="number">0.1</span>, <span class="number">0.01</span>]) \</span><br><span class="line">    .build()</span><br><span class="line"></span><br><span class="line">crossval = CrossValidator(estimator=pipeline,</span><br><span class="line">                          estimatorParamMaps=paramGrid,</span><br><span class="line">                          evaluator=BinaryClassificationEvaluator(),</span><br><span class="line">                          numFolds=<span class="number">2</span>)  <span class="comment"># use 3+ folds in practice</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Run cross-validation, and choose the best set of parameters.</span></span><br><span class="line">cvModel = crossval.fit(training)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare test documents, which are unlabeled.</span></span><br><span class="line">test = spark.createDataFrame([</span><br><span class="line">    (<span class="number">4</span>, <span class="string">"spark i j k"</span>),</span><br><span class="line">    (<span class="number">5</span>, <span class="string">"l m n"</span>),</span><br><span class="line">    (<span class="number">6</span>, <span class="string">"mapreduce spark"</span>),</span><br><span class="line">    (<span class="number">7</span>, <span class="string">"apache hadoop"</span>)</span><br><span class="line">], [<span class="string">"id"</span>, <span class="string">"text"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make predictions on test documents. cvModel uses the best model found (lrModel).</span></span><br><span class="line">prediction = cvModel.transform(test)</span><br><span class="line">selected = prediction.select(<span class="string">"id"</span>, <span class="string">"text"</span>, <span class="string">"probability"</span>, <span class="string">"prediction"</span>)</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> selected.collect():</span><br><span class="line">    print(row)</span><br><span class="line">selected.show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Row(id=<span class="number">4</span>, text=<span class="string">'spark i j k'</span>, probability=DenseVector([<span class="number">0.627</span>, <span class="number">0.373</span>]), prediction=<span class="number">0.0</span>)</span><br><span class="line">Row(id=<span class="number">5</span>, text=<span class="string">'l m n'</span>, probability=DenseVector([<span class="number">0.3451</span>, <span class="number">0.6549</span>]), prediction=<span class="number">1.0</span>)</span><br><span class="line">Row(id=<span class="number">6</span>, text=<span class="string">'mapreduce spark'</span>, probability=DenseVector([<span class="number">0.3351</span>, <span class="number">0.6649</span>]), prediction=<span class="number">1.0</span>)</span><br><span class="line">Row(id=<span class="number">7</span>, text=<span class="string">'apache hadoop'</span>, probability=DenseVector([<span class="number">0.2767</span>, <span class="number">0.7233</span>]), prediction=<span class="number">1.0</span>)</span><br><span class="line">+---+---------------+--------------------+----------+</span><br><span class="line">| id|           text|         probability|prediction|</span><br><span class="line">+---+---------------+--------------------+----------+</span><br><span class="line">|  <span class="number">4</span>|    spark i j k|[<span class="number">0.62703425702535</span>...|       <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">5</span>|          l m n|[<span class="number">0.34509123755317</span>...|       <span class="number">1.0</span>|</span><br><span class="line">|  <span class="number">6</span>|mapreduce spark|[<span class="number">0.33514123783842</span>...|       <span class="number">1.0</span>|</span><br><span class="line">|  <span class="number">7</span>|  apache hadoop|[<span class="number">0.27672019766802</span>...|       <span class="number">1.0</span>|</span><br><span class="line">+---+---------------+--------------------+----------+</span><br></pre></td></tr></table></figure><p>Find full example code at “examples/src/main/python/ml/cross_validator.py” in the Spark repo.</p><h2 id="Train-Validation-Split"><a href="#Train-Validation-Split" class="headerlink" title="Train-Validation Split"></a>Train-Validation Split</h2><p>除了交叉验证以外，Spark还提供 <code>TrainValidationSplit</code> 用以进行超参数调整。和交叉验证评估K次不同， <code>TrainValidationSplit</code> 只对每组参数评估一次。因此它计算代价更低，但当训练数据集不是足够大时，其结果可靠性不高。</p><p>与交叉验证不同， <code>TrainValidationSplit</code>仅需要一个训练数据与验证数据对。使用训练比率参数将原始数据划分为两个部分。如当训练比率为0.75时，训练验证分裂使用75%数据以训练，25%数据以验证。</p><p>与交叉验证相同，确定最佳参数表后，训练验证分裂最后使用最佳参数表基于全部数据来重新拟合Estimator。</p><h3 id="Examples-1"><a href="#Examples-1" class="headerlink" title="Examples"></a>Examples</h3><p>有关API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.tuning.TrainValidationSplit" target="_blank" rel="noopener">TrainValidationSplitPython</a>文档。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> RegressionEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.tuning <span class="keyword">import</span> ParamGridBuilder, TrainValidationSplit</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"TrainValidationSplitExample"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Prepare training and test data.</span></span><br><span class="line">data = spark.read.format(<span class="string">"libsvm"</span>)\</span><br><span class="line">    .load(<span class="string">"data/mllib/sample_linear_regression_data.txt"</span>)</span><br><span class="line">train, test = data.randomSplit([<span class="number">0.9</span>, <span class="number">0.1</span>], seed=<span class="number">12345</span>)</span><br><span class="line"></span><br><span class="line">lr = LinearRegression(maxIter=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># We use a ParamGridBuilder to construct a grid of parameters to search over.</span></span><br><span class="line"><span class="comment"># TrainValidationSplit will try all combinations of values and determine best model using</span></span><br><span class="line"><span class="comment"># the evaluator.</span></span><br><span class="line">paramGrid = ParamGridBuilder()\</span><br><span class="line">    .addGrid(lr.regParam, [<span class="number">0.1</span>, <span class="number">0.01</span>]) \</span><br><span class="line">    .addGrid(lr.fitIntercept, [<span class="keyword">False</span>, <span class="keyword">True</span>])\</span><br><span class="line">    .addGrid(lr.elasticNetParam, [<span class="number">0.0</span>, <span class="number">0.5</span>, <span class="number">1.0</span>])\</span><br><span class="line">    .build()</span><br><span class="line"></span><br><span class="line"><span class="comment"># In this case the estimator is simply the linear regression.</span></span><br><span class="line"><span class="comment"># A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.</span></span><br><span class="line">tvs = TrainValidationSplit(estimator=lr,</span><br><span class="line">                           estimatorParamMaps=paramGrid,</span><br><span class="line">                           evaluator=RegressionEvaluator(),</span><br><span class="line">                           <span class="comment"># 80% of the data will be used for training, 20% for validation.</span></span><br><span class="line">                           trainRatio=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run TrainValidationSplit, and choose the best set of parameters.</span></span><br><span class="line">model = tvs.fit(train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make predictions on test data. model is the model with combination of parameters</span></span><br><span class="line"><span class="comment"># that performed best.</span></span><br><span class="line">model.transform(test)\</span><br><span class="line">    .select(<span class="string">"features"</span>, <span class="string">"label"</span>, <span class="string">"prediction"</span>)\</span><br><span class="line">    .show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">+--------------------+--------------------+--------------------+</span><br><span class="line">|            features|               label|          prediction|</span><br><span class="line">+--------------------+--------------------+--------------------+</span><br><span class="line">|(<span class="number">10</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,...|  <span class="number">-23.51088409032297</span>| <span class="number">-1.6659388625179559</span>|</span><br><span class="line">|(<span class="number">10</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,...| <span class="number">-21.432387764165806</span>|  <span class="number">0.3400877302576284</span>|</span><br><span class="line">|(<span class="number">10</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,...| <span class="number">-12.977848725392104</span>|<span class="number">-0.02335359093652395</span>|</span><br><span class="line">|(<span class="number">10</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,...| <span class="number">-11.827072996392571</span>|  <span class="number">2.5642684021108417</span>|</span><br><span class="line">|(<span class="number">10</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,...| <span class="number">-10.945919657782932</span>| <span class="number">-0.1631314487734783</span>|</span><br><span class="line">|(<span class="number">10</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,...|  <span class="number">-10.58331129986813</span>|   <span class="number">2.517790654691453</span>|</span><br><span class="line">|(<span class="number">10</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,...| <span class="number">-10.288657252388708</span>| <span class="number">-0.9443474180536754</span>|</span><br><span class="line">|(<span class="number">10</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,...|  <span class="number">-8.822357870425154</span>|  <span class="number">0.6872889429113783</span>|</span><br><span class="line">|(<span class="number">10</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,...|  <span class="number">-8.772667465932606</span>|  <span class="number">-1.485408580416465</span>|</span><br><span class="line">|(<span class="number">10</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,...|  <span class="number">-8.605713514762092</span>|   <span class="number">1.110272909026478</span>|</span><br><span class="line">|(<span class="number">10</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,...|  <span class="number">-6.544633229269576</span>|  <span class="number">3.0454559778611285</span>|</span><br><span class="line">|(<span class="number">10</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,...|  <span class="number">-5.055293333055445</span>|  <span class="number">0.6441174575094268</span>|</span><br><span class="line">|(<span class="number">10</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,...|  <span class="number">-5.039628433467326</span>|  <span class="number">0.9572366607107066</span>|</span><br><span class="line">|(<span class="number">10</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,...|  <span class="number">-4.937258492902948</span>|  <span class="number">0.2292114538379546</span>|</span><br><span class="line">|(<span class="number">10</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,...|  <span class="number">-3.741044592262687</span>|   <span class="number">3.343205816009816</span>|</span><br><span class="line">|(<span class="number">10</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,...|  <span class="number">-3.731112242951253</span>| <span class="number">-2.6826413698701064</span>|</span><br><span class="line">|(<span class="number">10</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,...|  <span class="number">-2.109441044710089</span>| <span class="number">-2.1930034039595445</span>|</span><br><span class="line">|(<span class="number">10</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,...| <span class="number">-1.8722161156986976</span>| <span class="number">0.49547270330052423</span>|</span><br><span class="line">|(<span class="number">10</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,...| <span class="number">-1.1009750789589774</span>| <span class="number">-0.9441633113006601</span>|</span><br><span class="line">|(<span class="number">10</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,...|<span class="number">-0.48115211266405217</span>| <span class="number">-0.6756196573079968</span>|</span><br><span class="line">+--------------------+--------------------+--------------------+</span><br></pre></td></tr></table></figure><p>Find full example code at “examples/src/main/python/ml/train_validation_split.py” in the Spark repo.</p><p><strong>更多相关信息请查阅<a href="https://spark.apache.org/docs/latest/ml-tuning.html" target="_blank" rel="noopener">Spark ml-tuning</a></strong></p><h2 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h2>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;模型选择, 超参调整&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;br&gt;&lt;code&gt;ML Tuning&lt;/code&gt;: &lt;code&gt;model selection&lt;/code&gt;(模型选择) and &lt;code&gt;hyperparameter tuning&lt;/code&gt;(超参调整)&lt;br&gt;本节介绍如何使用MLlib的工具来调整ML算法和管道。内置的交叉验证和其他工具允许用户优化算法和管道中的超参数。&lt;/p&gt;
    
    </summary>
    
      <category term="Spark" scheme="https://blog.writeathink.cn/categories/Spark/"/>
    
      <category term="MLlib" scheme="https://blog.writeathink.cn/categories/Spark/MLlib/"/>
    
    
      <category term="模型选择" scheme="https://blog.writeathink.cn/tags/%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9/"/>
    
      <category term="交叉验证" scheme="https://blog.writeathink.cn/tags/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/"/>
    
      <category term="训练-验证集划分" scheme="https://blog.writeathink.cn/tags/%E8%AE%AD%E7%BB%83-%E9%AA%8C%E8%AF%81%E9%9B%86%E5%88%92%E5%88%86/"/>
    
  </entry>
  
  <entry>
    <title>SparkMLlib-Frequent-Pattern-Mining</title>
    <link href="https://blog.writeathink.cn/2018/01/23/SparkMLlib-Frequent-Pattern-Mining/"/>
    <id>https://blog.writeathink.cn/2018/01/23/SparkMLlib-Frequent-Pattern-Mining/</id>
    <published>2018-01-23T02:02:05.000Z</published>
    <updated>2018-03-01T09:36:53.828Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p class="description">Frequent Pattern Mining<br></p><p><img src="" alt="" style="width:100%"><br><code>Frequent Pattern Mining</code>：频繁项目，项目集，子序列或其他子结构的挖掘通常是分析大规模数据集的第一步，这已经成为<code>数据挖掘</code>领域的一个活跃的研究课题。我们将用户引用到Wikipedia的<a href="http://en.wikipedia.org/wiki/Association_rule_learning" target="_blank" rel="noopener">关联规则学习</a>中以获取更多信息。</p><a id="more"></a><h2 id="FP-Growth"><a href="#FP-Growth" class="headerlink" title="FP-Growth"></a>FP-Growth</h2><p>FP-growth算法在Han等人的文章<a href="http://dx.doi.org/10.1145/335191.335372" target="_blank" rel="noopener">“ Mining frequent patterns without candidate generation”</a>中描述，其中“FP”代表频繁模式。给定交易数据集，FP增长的第一步是计算项目频率并识别频繁项目。与为同样目的而设计的<a href="http://en.wikipedia.org/wiki/Apriori_algorithm" target="_blank" rel="noopener">Apriori-like</a>算法不同，FP-growth的第二步使用后缀树（FP-tree）结构来编码事务，而不显式生成候选集合，这通常是耗费的。第二步之后，可以从FP-tree中提取频繁项目集。在这里spark.mllib，我们实现了FP-growth的并行版本，称为PFP(详细请查看Li等人：<a href="http://dx.doi.org/10.1145/1454008.1454027" target="_blank" rel="noopener">PFP:Parallel FP-growth for query recommendation</a>)。PFP根据事务的后缀分配增长的FP-树的工作，因此比单机实现更具可扩展性。</p><ul><li><p>spark.ml FP的增长实现需要以下（超）参数：</p><ul><li><p><code>minSupport</code><br>一个项目组的最小支持被确定为频繁的。例如，如果一个项目在5个交易中出现3个，则它具有3/5 = 0.6的支持。</p></li><li><p><code>minConfidence</code><br>生成关联规则的最低置信度。信心是一个关联规则被发现是真实的指标。例如，如果交易项目集X出现4次，X 并且Y只出现2次，则规则的置信度为X =&gt; Y2/4 = 0.5。该参数不会影响对频繁项目集的挖掘，但指定从频繁项集生成关联规则的最小置信度。</p></li><li><p><code>numPartitions</code><br>用于分配工作的分区数量。默认情况下，param未设置，并使用输入数据集的分区数量。</p></li></ul></li><li><p>FPGrowthModel规定：</p><ul><li><p><code>freqItemsets</code><br>DataFrame格式的频繁项目集(“items”[Array]，“freq”[Long])</p></li><li><p><code>associationRules</code><br><code>minConfidence</code>以<code>DataFrame</code>(“antecedent”[Array],”consequent”[Array],<br>“confidence”[Double])格式在上面生成的关联规则。</p></li><li><p><code>transform</code><br>对于每个交易itemsCol，transform方法将比较其项目与每个关联规则的前提。如果记录包含特定关联规则的所有前提条件，则该规则将被视为适用，并将其结果添加到预测结果中。变换法将所有适用规则的后果总结为预测。预测列具有相同的数据类型，itemsCol并且不包含中的现有项目itemsCol。</p></li></ul></li></ul><h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.fpm <span class="keyword">import</span> FPGrowth</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"FrequentPatternMiningExample"</span>).getOrCreate()</span><br><span class="line">df = spark.createDataFrame([</span><br><span class="line">    (<span class="number">0</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>]),</span><br><span class="line">    (<span class="number">1</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>]),</span><br><span class="line">    (<span class="number">2</span>, [<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">], [<span class="string">"id"</span>, <span class="string">"items"</span>])</span><br><span class="line"></span><br><span class="line">fpGrowth = FPGrowth(itemsCol=<span class="string">"items"</span>, minSupport=<span class="number">0.5</span>, minConfidence=<span class="number">0.6</span>)</span><br><span class="line">model = fpGrowth.fit(df)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display frequent itemsets.</span></span><br><span class="line">model.freqItemsets.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display generated association rules.</span></span><br><span class="line">model.associationRules.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># transform examines the input items against all the association rules and summarize the</span></span><br><span class="line"><span class="comment"># consequents as prediction</span></span><br><span class="line">model.transform(df).show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">+---------+----+</span><br><span class="line">|    items|freq|</span><br><span class="line">+---------+----+</span><br><span class="line">|      [<span class="number">5</span>]|   <span class="number">2</span>|</span><br><span class="line">|   [<span class="number">5</span>, <span class="number">1</span>]|   <span class="number">2</span>|</span><br><span class="line">|[<span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>]|   <span class="number">2</span>|</span><br><span class="line">|   [<span class="number">5</span>, <span class="number">2</span>]|   <span class="number">2</span>|</span><br><span class="line">|      [<span class="number">2</span>]|   <span class="number">3</span>|</span><br><span class="line">|      [<span class="number">1</span>]|   <span class="number">3</span>|</span><br><span class="line">|   [<span class="number">1</span>, <span class="number">2</span>]|   <span class="number">3</span>|</span><br><span class="line">+---------+----+</span><br><span class="line"></span><br><span class="line">+----------+----------+------------------+</span><br><span class="line">|antecedent|consequent|        confidence|</span><br><span class="line">+----------+----------+------------------+</span><br><span class="line">|       [<span class="number">5</span>]|       [<span class="number">1</span>]|               <span class="number">1.0</span>|</span><br><span class="line">|       [<span class="number">5</span>]|       [<span class="number">2</span>]|               <span class="number">1.0</span>|</span><br><span class="line">|    [<span class="number">1</span>, <span class="number">2</span>]|       [<span class="number">5</span>]|<span class="number">0.6666666666666666</span>|</span><br><span class="line">|    [<span class="number">5</span>, <span class="number">2</span>]|       [<span class="number">1</span>]|               <span class="number">1.0</span>|</span><br><span class="line">|    [<span class="number">5</span>, <span class="number">1</span>]|       [<span class="number">2</span>]|               <span class="number">1.0</span>|</span><br><span class="line">|       [<span class="number">2</span>]|       [<span class="number">5</span>]|<span class="number">0.6666666666666666</span>|</span><br><span class="line">|       [<span class="number">2</span>]|       [<span class="number">1</span>]|               <span class="number">1.0</span>|</span><br><span class="line">|       [<span class="number">1</span>]|       [<span class="number">5</span>]|<span class="number">0.6666666666666666</span>|</span><br><span class="line">|       [<span class="number">1</span>]|       [<span class="number">2</span>]|               <span class="number">1.0</span>|</span><br><span class="line">+----------+----------+------------------+</span><br><span class="line"></span><br><span class="line">+---+------------+----------+</span><br><span class="line">| id|       items|prediction|</span><br><span class="line">+---+------------+----------+</span><br><span class="line">|  <span class="number">0</span>|   [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>]|        []|</span><br><span class="line">|  <span class="number">1</span>|[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>]|        []|</span><br><span class="line">|  <span class="number">2</span>|      [<span class="number">1</span>, <span class="number">2</span>]|       [<span class="number">5</span>]|</span><br><span class="line">+---+------------+----------+</span><br></pre></td></tr></table></figure><p>Find full example code at “examples/src/main/python/ml/fpgrowth_example.py” in the Spark repo.</p><p><strong>更多相关信息请查阅<a href="https://spark.apache.org/docs/latest/ml-frequent-pattern-mining.html" target="_blank" rel="noopener">Spark FPGrowth</a></strong></p><h2 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h2>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;Frequent Pattern Mining&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;br&gt;&lt;code&gt;Frequent Pattern Mining&lt;/code&gt;：频繁项目，项目集，子序列或其他子结构的挖掘通常是分析大规模数据集的第一步，这已经成为&lt;code&gt;数据挖掘&lt;/code&gt;领域的一个活跃的研究课题。我们将用户引用到Wikipedia的&lt;a href=&quot;http://en.wikipedia.org/wiki/Association_rule_learning&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;关联规则学习&lt;/a&gt;中以获取更多信息。&lt;/p&gt;
    
    </summary>
    
      <category term="Spark" scheme="https://blog.writeathink.cn/categories/Spark/"/>
    
      <category term="MLlib" scheme="https://blog.writeathink.cn/categories/Spark/MLlib/"/>
    
    
      <category term="数据挖掘" scheme="https://blog.writeathink.cn/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
      <category term="频繁项集" scheme="https://blog.writeathink.cn/tags/%E9%A2%91%E7%B9%81%E9%A1%B9%E9%9B%86/"/>
    
      <category term="关联规则" scheme="https://blog.writeathink.cn/tags/%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99/"/>
    
      <category term="FP-Growth" scheme="https://blog.writeathink.cn/tags/FP-Growth/"/>
    
  </entry>
  
  <entry>
    <title>SparkMLlib-Collaborative-Filtering</title>
    <link href="https://blog.writeathink.cn/2018/01/22/SparkMLlib-Collaborative-Filtering/"/>
    <id>https://blog.writeathink.cn/2018/01/22/SparkMLlib-Collaborative-Filtering/</id>
    <published>2018-01-22T03:36:52.000Z</published>
    <updated>2018-03-01T09:36:37.827Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p class="description">推荐算法<br></p><p><img src="" alt="" style="width:100%"><br><a href="http://en.wikipedia.org/wiki/Recommender_system#Collaborative_filtering" target="_blank" rel="noopener">协同过滤</a>常被用于<code>推荐系统</code>。这类技术目标在于填充“用户－商品”联系矩阵中的缺失项。Spark.ml目前支持基于模型的协同过滤，其中用户和商品以少量的潜在因子来描述，用以预测缺失项。Spark.ml使用<a href="http://dl.acm.org/citation.cfm?id=1608614" target="_blank" rel="noopener">交替最小二乘（ALS）</a>算法来学习这些潜在因子。<br><a id="more"></a><br>spark.ml有以下参数：</p><ul><li>numBlocks是为了并行化计算而将用户和项目分割成的块的数量（默认为10）。</li><li>rank是模型中潜在因素的数量（默认为10）。</li><li>maxIter是要运行的最大迭代次数（默认为10）。</li><li>regParam指定ALS中的正则化参数（默认为1.0）。</li><li>implicitPrefs指定是使用显式反馈ALS变体还是用于隐式反馈数据的变体 （默认false使用显式反馈）。</li><li>alpha是适用于ALS的隐式反馈变体的参数，其支配偏好观察值的 基线置信度（默认为1.0）。</li><li>非负指定是否对最小二乘使用非负约束（默认为false）。</li></ul><p>注意：用于ALS的基于DataFrame的API目前仅支持整数类型的用户和项目ID。用户和项目ID列支持其他数字类型，但ID必须在整数值范围内。</p><h2 id="Explicit-vs-Implict-feedfack-显示与隐式反馈"><a href="#Explicit-vs-Implict-feedfack-显示与隐式反馈" class="headerlink" title="Explicit vs Implict feedfack(显示与隐式反馈)"></a><strong>Explicit vs Implict feedfack(显示与隐式反馈)</strong></h2><p>基于矩阵分解的协同过滤的标准方法中，“用户－商品”矩阵中的条目是用户给予商品的显式偏好，例如，用户给电影评级。然而在现实世界中使用时，我们常常只能访问隐式反馈（如意见、点击、购买、喜欢以及分享等），在spark.ml中我们使用“隐式反馈数据集的协同过滤“来处理这类数据。本质上来说它不是直接对评分矩阵进行建模，而是将数据当作数值来看待，这些数值代表用户行为的观察值（如点击次数，用户观看一部电影的持续时间）。这些数值被用来衡量用户偏好观察值的置信水平，而不是显式地给商品一个评分。然后，模型用来寻找可以用来预测用户对商品预期偏好的潜在因子。</p><h2 id="Scaling-of-the-regularization-parameter-正则化参数缩放"><a href="#Scaling-of-the-regularization-parameter-正则化参数缩放" class="headerlink" title="Scaling of the regularization parameter(正则化参数缩放)"></a><strong>Scaling of the regularization parameter(正则化参数缩放)</strong></h2><p>我们调整正则化参数regParam来解决用户在更新用户因子时产生新评分或者商品更新商品因子时收到的新评分带来的最小二乘问题。这个方法叫做<a href="http://dx.doi.org/10.1007/978-3-540-68880-8_32" target="_blank" rel="noopener">“ALS-WR”</a>,它降低regParam对数据集规模的依赖，所以我们可以将从部分子集中学习到的最佳参数应用到整个数据集中时获得同样的性能。</p><h2 id="Cold-start-strategy-冷启动策略"><a href="#Cold-start-strategy-冷启动策略" class="headerlink" title="Cold-start strategy(冷启动策略)"></a>Cold-start strategy(冷启动策略)</h2><p>在使用ALSModel进行预测时，通常会遇到测试数据集中用户和/或物品在训练模型期间不存在的情况。这通常发生在两种情况下：</p><ol><li>在生产中，对于没有评分历史记录且尚未训练的新用户或物品（这是“冷启动问题”）。</li><li>在交叉验证过程中，数据分为训练集和评估集。当Spark的CrossValidator或者TrainValidationSplit中的使用简单随机拆分，实际上在评估集中普遍遇到用户或物品不存在的问题，而在训练集中并未出现这样的问题</li></ol><p>默认情况下，Spark NaN在当用户和/或物品因素不存在于模型中时，Spark在ALSModel.transform时使用NAN作为预测。这在生产系统中可能是有用的，因为它表示一个新的用户或物品，所以系统可以做出一个决定，作为预测。</p><p>然而，这在交叉验证期间是不好的，因为任何NaN预测值都将导致NaN评估度量的结果（例如在使用RegressionEvaluator时）。这使得模型无法作出选择。</p><p>Spark允许用户将coldStartStrategy参数设置为“drop”，以便删除DataFrame包含NaN值的预测中的任何行。评估指标然后在非NaN数据上计算，并且这是有效的。下面的例子说明了这个参数的用法。</p><p>注意：目前支持的冷启动策略是“nan”（上面提到的默认行为）和“drop”。未来可能会支持进一步的策略。</p><h2 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h2><p>在以下示例中，我们将从<a href="http://grouplens.org/datasets/movielens/" target="_blank" rel="noopener">MovieLens数据集</a>中加载评分数据 ，每行由用户，电影，评分和时间戳组成。然后，我们训练一个ALS模型，默认情况下，这个模型的评级是明确的（implicitPrefs是false）。我们通过测量评级预测的均方根误差来评估推荐模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> RegressionEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.recommendation <span class="keyword">import</span> ALS</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> Row, SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"CollaborativeFilteringExample"</span>).getOrCreate()</span><br><span class="line">lines = spark.read.text(<span class="string">"data/mllib/als/sample_movielens_ratings.txt"</span>).rdd</span><br><span class="line">parts = lines.map(<span class="keyword">lambda</span> row: row.value.split(<span class="string">"::"</span>))</span><br><span class="line">ratingsRDD = parts.map(<span class="keyword">lambda</span> p: Row(userId=int(p[<span class="number">0</span>]), movieId=int(p[<span class="number">1</span>]),</span><br><span class="line">                                     rating=float(p[<span class="number">2</span>]), timestamp=int(p[<span class="number">3</span>])))</span><br><span class="line">ratings = spark.createDataFrame(ratingsRDD)</span><br><span class="line">(training, test) = ratings.randomSplit([<span class="number">0.8</span>, <span class="number">0.2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Build the recommendation model using ALS on the training data</span></span><br><span class="line"><span class="comment"># Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics</span></span><br><span class="line">als = ALS(maxIter=<span class="number">5</span>, regParam=<span class="number">0.01</span>, userCol=<span class="string">"userId"</span>, itemCol=<span class="string">"movieId"</span>, ratingCol=<span class="string">"rating"</span>,</span><br><span class="line">          coldStartStrategy=<span class="string">"drop"</span>)</span><br><span class="line">model = als.fit(training)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Evaluate the model by computing the RMSE on the test data</span></span><br><span class="line">predictions = model.transform(test)</span><br><span class="line">evaluator = RegressionEvaluator(metricName=<span class="string">"rmse"</span>, labelCol=<span class="string">"rating"</span>,</span><br><span class="line">                                predictionCol=<span class="string">"prediction"</span>)</span><br><span class="line">rmse = evaluator.evaluate(predictions)</span><br><span class="line">print(<span class="string">"Root-mean-square error = "</span> + str(rmse))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate top 10 movie recommendations for each user</span></span><br><span class="line">userRecs = model.recommendForAllUsers(<span class="number">10</span>)</span><br><span class="line">userRecs.show()</span><br><span class="line"><span class="comment"># userRecs.filter(userRecs['userId'] == 1).select('recommendations').show(truncate=False)  # 看看给userId==1的用户推荐了哪10部电影</span></span><br><span class="line"><span class="comment"># Generate top 10 user recommendations for each movie</span></span><br><span class="line">movieRecs = model.recommendForAllItems(<span class="number">10</span>)</span><br><span class="line">movieRecs.show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">Root-mean-square error = <span class="number">1.742790392299329</span></span><br><span class="line">+------+--------------------+</span><br><span class="line">|userId|     recommendations|</span><br><span class="line">+------+--------------------+</span><br><span class="line">|    <span class="number">28</span>|[[<span class="number">92</span>,<span class="number">5.0226665</span>], ...|</span><br><span class="line">|    <span class="number">26</span>|[[<span class="number">81</span>,<span class="number">5.6422243</span>], ...|</span><br><span class="line">|    <span class="number">27</span>|[[<span class="number">18</span>,<span class="number">4.069487</span>], [...|</span><br><span class="line">|    <span class="number">12</span>|[[<span class="number">19</span>,<span class="number">6.6280622</span>], ...|</span><br><span class="line">|    <span class="number">22</span>|[[<span class="number">74</span>,<span class="number">5.141776</span>], [...|</span><br><span class="line">|     <span class="number">1</span>|[[<span class="number">46</span>,<span class="number">4.550467</span>], [...|</span><br><span class="line">|    <span class="number">13</span>|[[<span class="number">93</span>,<span class="number">3.4347346</span>], ...|</span><br><span class="line">|     <span class="number">6</span>|[[<span class="number">25</span>,<span class="number">5.163864</span>], [...|</span><br><span class="line">|    <span class="number">16</span>|[[<span class="number">54</span>,<span class="number">4.865331</span>], [...|</span><br><span class="line">|     <span class="number">3</span>|[[<span class="number">75</span>,<span class="number">5.5034533</span>], ...|</span><br><span class="line">|    <span class="number">20</span>|[[<span class="number">22</span>,<span class="number">4.563996</span>], [...|</span><br><span class="line">|     <span class="number">5</span>|[[<span class="number">46</span>,<span class="number">6.402665</span>], [...|</span><br><span class="line">|    <span class="number">19</span>|[[<span class="number">94</span>,<span class="number">4.0123057</span>], ...|</span><br><span class="line">|    <span class="number">15</span>|[[<span class="number">46</span>,<span class="number">4.932741</span>], [...|</span><br><span class="line">|    <span class="number">17</span>|[[<span class="number">46</span>,<span class="number">5.196739</span>], [...|</span><br><span class="line">|     <span class="number">9</span>|[[<span class="number">65</span>,<span class="number">4.703967</span>], [...|</span><br><span class="line">|     <span class="number">4</span>|[[<span class="number">85</span>,<span class="number">4.958973</span>], [...|</span><br><span class="line">|     <span class="number">8</span>|[[<span class="number">43</span>,<span class="number">5.747457</span>], [...|</span><br><span class="line">|    <span class="number">23</span>|[[<span class="number">32</span>,<span class="number">5.279368</span>], [...|</span><br><span class="line">|     <span class="number">7</span>|[[<span class="number">62</span>,<span class="number">5.059422</span>], [...|</span><br><span class="line">+------+--------------------+</span><br><span class="line">only showing top <span class="number">20</span> rows</span><br><span class="line"></span><br><span class="line">+-------+--------------------+</span><br><span class="line">|movieId|     recommendations|</span><br><span class="line">+-------+--------------------+</span><br><span class="line">|     <span class="number">31</span>|[[<span class="number">12</span>,<span class="number">3.5030043</span>], ...|</span><br><span class="line">|     <span class="number">85</span>|[[<span class="number">14</span>,<span class="number">5.6425133</span>], ...|</span><br><span class="line">|     <span class="number">65</span>|[[<span class="number">23</span>,<span class="number">4.9570875</span>], ...|</span><br><span class="line">|     <span class="number">53</span>|[[<span class="number">14</span>,<span class="number">5.271897</span>], [...|</span><br><span class="line">|     <span class="number">78</span>|[[<span class="number">12</span>,<span class="number">1.4262005</span>], ...|</span><br><span class="line">|     <span class="number">34</span>|[[<span class="number">2</span>,<span class="number">3.9721959</span>], [...|</span><br><span class="line">|     <span class="number">81</span>|[[<span class="number">26</span>,<span class="number">5.6422243</span>], ...|</span><br><span class="line">|     <span class="number">28</span>|[[<span class="number">18</span>,<span class="number">5.0155253</span>], ...|</span><br><span class="line">|     <span class="number">76</span>|[[<span class="number">14</span>,<span class="number">4.9423637</span>], ...|</span><br><span class="line">|     <span class="number">26</span>|[[<span class="number">5</span>,<span class="number">4.06113</span>], [<span class="number">15.</span>..|</span><br><span class="line">|     <span class="number">27</span>|[[<span class="number">11</span>,<span class="number">5.220525</span>], [...|</span><br><span class="line">|     <span class="number">44</span>|[[<span class="number">18</span>,<span class="number">3.830072</span>], [...|</span><br><span class="line">|     <span class="number">12</span>|[[<span class="number">28</span>,<span class="number">4.8217144</span>], ...|</span><br><span class="line">|     <span class="number">91</span>|[[<span class="number">12</span>,<span class="number">3.090134</span>], [...|</span><br><span class="line">|     <span class="number">22</span>|[[<span class="number">18</span>,<span class="number">8.003841</span>], [...|</span><br><span class="line">|     <span class="number">93</span>|[[<span class="number">2</span>,<span class="number">4.621838</span>], [<span class="number">2.</span>..|</span><br><span class="line">|     <span class="number">47</span>|[[<span class="number">6</span>,<span class="number">4.48774</span>], [<span class="number">25.</span>..|</span><br><span class="line">|      <span class="number">1</span>|[[<span class="number">27</span>,<span class="number">3.527709</span>], [...|</span><br><span class="line">|     <span class="number">52</span>|[[<span class="number">8</span>,<span class="number">5.0824013</span>], [...|</span><br><span class="line">|     <span class="number">13</span>|[[<span class="number">23</span>,<span class="number">4.004786</span>], [...|</span><br><span class="line">+-------+--------------------+</span><br><span class="line">only showing top <span class="number">20</span> rows</span><br></pre></td></tr></table></figure><p>Find full example code at “examples/src/main/python/ml/als_example.py” in the Spark repo.</p><p>如果评分矩阵是从另一个信息源（即它是从其他信号推断）得出，可以设置implicitPrefs以true获得更好的效果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">als = ALS(maxIter=<span class="number">5</span>, regParam=<span class="number">0.01</span>, implicitPrefs=<span class="keyword">True</span>,</span><br><span class="line">          userCol=<span class="string">"userId"</span>, itemCol=<span class="string">"movieId"</span>, ratingCol=<span class="string">"rating"</span>)</span><br></pre></td></tr></table></figure><p><strong>更多相关信息请查阅<a href="https://spark.apache.org/docs/latest/ml-collaborative-filtering.html" target="_blank" rel="noopener">spark 协同过滤</a></strong></p><h2 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h2>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;推荐算法&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;br&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Recommender_system#Collaborative_filtering&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;协同过滤&lt;/a&gt;常被用于&lt;code&gt;推荐系统&lt;/code&gt;。这类技术目标在于填充“用户－商品”联系矩阵中的缺失项。Spark.ml目前支持基于模型的协同过滤，其中用户和商品以少量的潜在因子来描述，用以预测缺失项。Spark.ml使用&lt;a href=&quot;http://dl.acm.org/citation.cfm?id=1608614&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;交替最小二乘（ALS）&lt;/a&gt;算法来学习这些潜在因子。&lt;br&gt;
    
    </summary>
    
      <category term="Spark" scheme="https://blog.writeathink.cn/categories/Spark/"/>
    
      <category term="MLlib" scheme="https://blog.writeathink.cn/categories/Spark/MLlib/"/>
    
    
      <category term="协同过滤" scheme="https://blog.writeathink.cn/tags/%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4/"/>
    
      <category term="推荐系统" scheme="https://blog.writeathink.cn/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>SparkMLlib-Clustering</title>
    <link href="https://blog.writeathink.cn/2018/01/22/SparkMLlib-Clustering/"/>
    <id>https://blog.writeathink.cn/2018/01/22/SparkMLlib-Clustering/</id>
    <published>2018-01-22T03:09:09.000Z</published>
    <updated>2018-03-01T09:36:26.302Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p class="description">聚类算法<br></p><p><img src="" alt="" style="width:100%"></p><p>本节介绍MLlib中的聚类算法(<code>KMeans</code>, <code>LDA</code>, <code>GMM</code>)。在<a href="https://spark.apache.org/docs/latest/mllib-clustering.html" target="_blank" rel="noopener">基于RDD-API聚类指南</a>里还提供了有关这些算法的相关信息。</p><a id="more"></a><h2 id="K-means"><a href="#K-means" class="headerlink" title="K-means"></a>K-means</h2><p><code>K-means</code>是一个常用的聚类算法来将数据点按预定的簇数进行聚集。K-means算法的基本思想是：以空间中k个点为中心进行聚类，对最靠近他们的对象归类。通过迭代的方法，逐次更新各聚类中心的值，直至得到最好的聚类结果。</p><p>假设要把样本集分为c个类别，算法描述如下：</p><p>（1）适当选择c个类的初始中心；</p><p>（2）在第k次迭代中，对任意一个样本，求其到c个中心的距离，将该样本归到距离最短的中心所在的类；</p><p>（3）利用均值等方法更新该类的中心值；</p><p>（4）对于所有的c个聚类中心，如果利用（2）（3）的迭代法更新后，值保持不变，则迭代结束，否则继续迭代。</p><p>MLlib工具包含并行的K-means++算法，称为kmeans||。Kmeans是一个Estimator，它在基础模型之上产生一个KMeansModel。</p><ul><li><strong>Input Columns(输入列)</strong></li></ul><table><thead><tr><th>Param name(参数名称)</th><th>Type(s)(类型)</th><th>Default(默认)</th><th>Description(描述)</th></tr></thead><tbody><tr><td>featuresCol</td><td>Vector</td><td>“features”</td><td>Feature vector(特征向量)</td></tr></tbody></table><ul><li><strong>Output Columns(输出列)</strong></li></ul><table><thead><tr><th>Param name(参数名称)</th><th>Type(s)(类型)</th><th>Default(默认)</th><th>Description(描述)</th></tr></thead><tbody><tr><td>predictionCol</td><td>Int</td><td>“prediction”</td><td>Predicted cluster center(预测的聚类中心)</td></tr></tbody></table><h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.clustering <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"ClusterExample"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Loads data.</span></span><br><span class="line">dataset = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"data/mllib/sample_kmeans_data.txt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Trains a k-means model.</span></span><br><span class="line">kmeans = KMeans().setK(<span class="number">2</span>).setSeed(<span class="number">1</span>)</span><br><span class="line">model = kmeans.fit(dataset)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Evaluate clustering by computing Within Set Sum of Squared Errors.</span></span><br><span class="line">wssse = model.computeCost(dataset)</span><br><span class="line">print(<span class="string">"Within Set Sum of Squared Errors = "</span> + str(wssse))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Shows the result.</span></span><br><span class="line">centers = model.clusterCenters()</span><br><span class="line">print(<span class="string">"Cluster Centers: "</span>)</span><br><span class="line"><span class="keyword">for</span> center <span class="keyword">in</span> centers:</span><br><span class="line">    print(center)</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Within Set Sum of Squared Errors = <span class="number">0.11999999999994547</span></span><br><span class="line">Cluster Centers: </span><br><span class="line">[ <span class="number">0.1</span>  <span class="number">0.1</span>  <span class="number">0.1</span>]</span><br><span class="line">[ <span class="number">9.1</span>  <span class="number">9.1</span>  <span class="number">9.1</span>]</span><br></pre></td></tr></table></figure><p>Find full example code at “examples/src/main/python/ml/kmeans_example.py” in the Spark repo.</p><h2 id="Latent-Dirichlet-allocation-LDA"><a href="#Latent-Dirichlet-allocation-LDA" class="headerlink" title="Latent Dirichlet allocation(LDA)"></a>Latent Dirichlet allocation(LDA)</h2><p><code>LDA</code>（Latent Dirichlet Allocation）是一种文档主题生成模型，也称为一个三层贝叶斯概率模型，包含词、主题和文档三层结构。所谓生成模型，就是说，我们认为一篇文章的每个词都是通过“以一定概率选择了某个主题，并从这个主题中以一定概率选择某个词语”这样一个过程得到。文档到主题服从多项式分布，主题到词服从多项式分布。</p><p>LDA是一种非监督机器学习技术，可以用来识别大规模文档集（document collection）或语料库（corpus）中潜藏的主题信息。它采用了词袋（bag of words）的方法，这种方法将每一篇文档视为一个词频向量，从而将文本信息转化为了易于建模的数字信息。但是词袋方法没有考虑词与词之间的顺序，这简化了问题的复杂性，同时也为模型的改进提供了契机。每一篇文档代表了一些主题所构成的一个概率分布，而每一个主题又代表了很多单词所构成的一个概率分布。</p><p>LDA被实现为一个Estimator,既支持EMLDAOptimizer和OnlineLDAOptimizer，并生成一个LDAModel作为基础模型。如果需要的话，专家用户可以将EMLDAOptimizer生成的LDAModel映射到一个DistributedLDAModel</p><h3 id="Examples-1"><a href="#Examples-1" class="headerlink" title="Examples"></a>Examples</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.clustering <span class="keyword">import</span> LDA</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"LDAExample"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Loads data.</span></span><br><span class="line">dataset = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"data/mllib/sample_lda_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Trains a LDA model.</span></span><br><span class="line">lda = LDA(k=<span class="number">10</span>, maxIter=<span class="number">10</span>)</span><br><span class="line">model = lda.fit(dataset)</span><br><span class="line"></span><br><span class="line">ll = model.logLikelihood(dataset)</span><br><span class="line">lp = model.logPerplexity(dataset)</span><br><span class="line">print(<span class="string">"The lower bound on the log likelihood of the entire corpus: "</span> + str(ll))</span><br><span class="line">print(<span class="string">"The upper bound on perplexity: "</span> + str(lp))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe topics.</span></span><br><span class="line">topics = model.describeTopics(<span class="number">3</span>)</span><br><span class="line">print(<span class="string">"The topics described by their top-weighted terms:"</span>)</span><br><span class="line">topics.show(truncate=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Shows the result</span></span><br><span class="line">transformed = model.transform(dataset)</span><br><span class="line">transformed.show(truncate=<span class="keyword">False</span>)</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">The lower bound on the log likelihood of the entire corpus: <span class="number">-797.8018456907539</span></span><br><span class="line">The upper bound on perplexity: <span class="number">3.068468635551357</span></span><br><span class="line">The topics described by their top-weighted terms:</span><br><span class="line">+-----+-----------+---------------------------------------------------------------+</span><br><span class="line">|topic|termIndices|termWeights                                                    |</span><br><span class="line">+-----+-----------+---------------------------------------------------------------+</span><br><span class="line">|<span class="number">0</span>    |[<span class="number">0</span>, <span class="number">4</span>, <span class="number">7</span>]  |[<span class="number">0.13939487929625935</span>, <span class="number">0.13346874874963285</span>, <span class="number">0.11911498796394984</span>]|</span><br><span class="line">|<span class="number">1</span>    |[<span class="number">8</span>, <span class="number">6</span>, <span class="number">0</span>]  |[<span class="number">0.09761719173430919</span>, <span class="number">0.09664530483154511</span>, <span class="number">0.0959033498887414</span>] |</span><br><span class="line">|<span class="number">2</span>    |[<span class="number">5</span>, <span class="number">9</span>, <span class="number">1</span>]  |[<span class="number">0.09763288175177705</span>, <span class="number">0.0967699480930826</span>, <span class="number">0.09474971437446654</span>] |</span><br><span class="line">|<span class="number">3</span>    |[<span class="number">6</span>, <span class="number">2</span>, <span class="number">5</span>]  |[<span class="number">0.09993087551790403</span>, <span class="number">0.09802667103524504</span>, <span class="number">0.09669791743434605</span>]|</span><br><span class="line">|<span class="number">4</span>    |[<span class="number">10</span>, <span class="number">5</span>, <span class="number">8</span>] |[<span class="number">0.10838084105098059</span>, <span class="number">0.1065719519796393</span>, <span class="number">0.10564271921581836</span>] |</span><br><span class="line">|<span class="number">5</span>    |[<span class="number">2</span>, <span class="number">5</span>, <span class="number">3</span>]  |[<span class="number">0.09975664174839147</span>, <span class="number">0.09917147147531298</span>, <span class="number">0.09482946730767593</span>]|</span><br><span class="line">|<span class="number">6</span>    |[<span class="number">1</span>, <span class="number">7</span>, <span class="number">3</span>]  |[<span class="number">0.1025918379349122</span>, <span class="number">0.09670884980694468</span>, <span class="number">0.09661321616852961</span>] |</span><br><span class="line">|<span class="number">7</span>    |[<span class="number">3</span>, <span class="number">10</span>, <span class="number">6</span>] |[<span class="number">0.18074276445784626</span>, <span class="number">0.17140880975201497</span>, <span class="number">0.11846617165050731</span>]|</span><br><span class="line">|<span class="number">8</span>    |[<span class="number">7</span>, <span class="number">9</span>, <span class="number">1</span>]  |[<span class="number">0.10376667278659339</span>, <span class="number">0.10266984655859988</span>, <span class="number">0.10261491999135175</span>]|</span><br><span class="line">|<span class="number">9</span>    |[<span class="number">5</span>, <span class="number">9</span>, <span class="number">4</span>]  |[<span class="number">0.17217259005160918</span>, <span class="number">0.11130983487715354</span>, <span class="number">0.10625585388024414</span>]|</span><br><span class="line">+-----+-----------+---------------------------------------------------------------+</span><br><span class="line"></span><br><span class="line">+-----+---------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">|label|features                                                       |topicDistribution                                                                                                                                                                                                      |</span><br><span class="line">+-----+---------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">|<span class="number">0.0</span>  |(<span class="number">11</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">10</span>],[<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">6.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">3.0</span>])      |[<span class="number">0.004834482522877391</span>,<span class="number">0.004775061546874506</span>,<span class="number">0.0047750850624618665</span>,<span class="number">0.00477508209536724</span>,<span class="number">0.004775110752126829</span>,<span class="number">0.0047751198765325934</span>,<span class="number">0.0047750802565546275</span>,<span class="number">0.44999380128294686</span>,<span class="number">0.004775119757841731</span>,<span class="number">0.5117460568464164</span>]     |</span><br><span class="line">|<span class="number">1.0</span>  |(<span class="number">11</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">7</span>,<span class="number">10</span>],[<span class="number">1.0</span>,<span class="number">3.0</span>,<span class="number">1.0</span>,<span class="number">3.0</span>,<span class="number">2.0</span>,<span class="number">1.0</span>])                  |[<span class="number">0.9268994208923648</span>,<span class="number">0.007965511763080765</span>,<span class="number">0.007965521320089061</span>,<span class="number">0.007965447383722308</span>,<span class="number">0.007965587789582014</span>,<span class="number">0.007965461329343004</span>,<span class="number">0.00796558757403698</span>,<span class="number">0.009276986136774072</span>,<span class="number">0.007965614108681227</span>,<span class="number">0.008064861702326028</span>]       |</span><br><span class="line">|<span class="number">2.0</span>  |(<span class="number">11</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">8</span>,<span class="number">9</span>],[<span class="number">1.0</span>,<span class="number">4.0</span>,<span class="number">1.0</span>,<span class="number">4.0</span>,<span class="number">9.0</span>,<span class="number">1.0</span>,<span class="number">2.0</span>])             |[<span class="number">0.004202815262490896</span>,<span class="number">0.004151229704235803</span>,<span class="number">0.004151279248440336</span>,<span class="number">0.004151250849060332</span>,<span class="number">0.004151298320120848</span>,<span class="number">0.004151248811452763</span>,<span class="number">0.004151213592542253</span>,<span class="number">0.6501025149437936</span>,<span class="number">0.00415114952939257</span>,<span class="number">0.3166359997384707</span>]         |</span><br><span class="line">|<span class="number">3.0</span>  |(<span class="number">11</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">6</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>],[<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">3.0</span>,<span class="number">5.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">9.0</span>])            |[<span class="number">0.0037170513237456872</span>,<span class="number">0.0036715329471578005</span>,<span class="number">0.0036715360552429213</span>,<span class="number">0.003671511493261907</span>,<span class="number">0.003671797370463146</span>,<span class="number">0.0036715102318871204</span>,<span class="number">0.0036715134308361727</span>,<span class="number">0.9668647838101413</span>,<span class="number">0.003671504403863317</span>,<span class="number">0.003717258933400576</span>] |</span><br><span class="line">|<span class="number">4.0</span>  |(<span class="number">11</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">9</span>,<span class="number">10</span>],[<span class="number">3.0</span>,<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">9.0</span>,<span class="number">3.0</span>,<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">3.0</span>])      |[<span class="number">0.004027376743557338</span>,<span class="number">0.003977866599137274</span>,<span class="number">0.003977850254362953</span>,<span class="number">0.003977835428829377</span>,<span class="number">0.0039778820932092175</span>,<span class="number">0.003977853048840427</span>,<span class="number">0.003977852184563374</span>,<span class="number">0.9641001717255747</span>,<span class="number">0.0039778458818949</span>,<span class="number">0.004027466040030248</span>]       |</span><br><span class="line">|<span class="number">5.0</span>  |(<span class="number">11</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>],[<span class="number">4.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">4.0</span>,<span class="number">5.0</span>,<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">4.0</span>]) |[<span class="number">0.003717509832713523</span>,<span class="number">0.0036716615407946934</span>,<span class="number">0.0036716846624067615</span>,<span class="number">0.0036716395255962085</span>,<span class="number">0.0036717149575019995</span>,<span class="number">0.0036716664005927474</span>,<span class="number">0.0036716667567801204</span>,<span class="number">0.27461258177043146</span>,<span class="number">0.0036716647781321666</span>,<span class="number">0.6959682097750503</span>]|</span><br><span class="line">|<span class="number">6.0</span>  |(<span class="number">11</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">6</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>],[<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">3.0</span>,<span class="number">5.0</span>,<span class="number">2.0</span>,<span class="number">2.0</span>,<span class="number">9.0</span>])            |[<span class="number">0.0038659082828356533</span>,<span class="number">0.003818570338009387</span>,<span class="number">0.0038185658000222077</span>,<span class="number">0.0038185390646671936</span>,<span class="number">0.003818726199778954</span>,<span class="number">0.0038185379956121677</span>,<span class="number">0.003818554784511252</span>,<span class="number">0.9655379642100607</span>,<span class="number">0.003818526437489602</span>,<span class="number">0.003866106887012979</span>]  |</span><br><span class="line">|<span class="number">7.0</span>  |(<span class="number">11</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">9</span>,<span class="number">10</span>],[<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">9.0</span>,<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">3.0</span>])|[<span class="number">0.004394125793389081</span>,<span class="number">0.004340066102223131</span>,<span class="number">0.004340117929521572</span>,<span class="number">0.004340091402319875</span>,<span class="number">0.004340183500883856</span>,<span class="number">0.004340117374988447</span>,<span class="number">0.004340096103563213</span>,<span class="number">0.9608305723851966</span>,<span class="number">0.004340058125232322</span>,<span class="number">0.004394571282681922</span>]      |</span><br><span class="line">|<span class="number">8.0</span>  |(<span class="number">11</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>],[<span class="number">4.0</span>,<span class="number">4.0</span>,<span class="number">3.0</span>,<span class="number">4.0</span>,<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">3.0</span>])             |[<span class="number">0.9601715212707249</span>,<span class="number">0.0043400767428901635</span>,<span class="number">0.004340086711133699</span>,<span class="number">0.004340041546373581</span>,<span class="number">0.004340093118553618</span>,<span class="number">0.004340077924408194</span>,<span class="number">0.004340099543124161</span>,<span class="number">0.005053547015193133</span>,<span class="number">0.004340064942938327</span>,<span class="number">0.004394391184660286</span>]     |</span><br><span class="line">|<span class="number">9.0</span>  |(<span class="number">11</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>],[<span class="number">2.0</span>,<span class="number">8.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">2.0</span>,<span class="number">2.0</span>,<span class="number">7.0</span>,<span class="number">2.0</span>])      |[<span class="number">0.003332384443784424</span>,<span class="number">0.0032914608990001755</span>,<span class="number">0.003291474583522146</span>,<span class="number">0.003291442358715674</span>,<span class="number">0.003291502923651029</span>,<span class="number">0.0032914477446806248</span>,<span class="number">0.003291451230227242</span>,<span class="number">0.9702948142666302</span>,<span class="number">0.0032914840138979083</span>,<span class="number">0.0033325375358905047</span>]  |</span><br><span class="line">|<span class="number">10.0</span> |(<span class="number">11</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">9</span>,<span class="number">10</span>],[<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">9.0</span>,<span class="number">2.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">3.0</span>])      |[<span class="number">0.004202933475197545</span>,<span class="number">0.004151218860618786</span>,<span class="number">0.004151338270182237</span>,<span class="number">0.004151288340705789</span>,<span class="number">0.004151431515312671</span>,<span class="number">0.004151332888945593</span>,<span class="number">0.00415129142785515</span>,<span class="number">0.9625342071313459</span>,<span class="number">0.0041512327632204984</span>,<span class="number">0.004203725326615945</span>]      |</span><br><span class="line">|<span class="number">11.0</span> |(<span class="number">11</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">9</span>],[<span class="number">4.0</span>,<span class="number">1.0</span>,<span class="number">4.0</span>,<span class="number">5.0</span>,<span class="number">1.0</span>,<span class="number">3.0</span>,<span class="number">1.0</span>])             |[<span class="number">0.5794463100207559</span>,<span class="number">0.004774699657046339</span>,<span class="number">0.004774740812070836</span>,<span class="number">0.0047746922036681246</span>,<span class="number">0.004774755044701768</span>,<span class="number">0.004774721978296648</span>,<span class="number">0.0047747158288502884</span>,<span class="number">0.0055583559655138</span>,<span class="number">0.004774694223725667</span>,<span class="number">0.38157231426537064</span>]       |</span><br><span class="line">+-----+---------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure><p>Find full example code at “examples/src/main/python/ml/lda_example.py” in the Spark repo.</p><h2 id="Bisecting-k-means"><a href="#Bisecting-k-means" class="headerlink" title="Bisecting k-means"></a>Bisecting k-means</h2><p><code>二分K均值</code>算法是一种<code>层次聚类算法</code>，使用自顶向下的逼近：所有的观察值开始是一个簇，递归地向下一个层级分裂。分裂依据为选择能最大程度降低聚类代价函数（也就是误差平方和）的簇划分为两个簇。以此进行下去，直到簇的数目等于用户给定的数目k为止。二分K均值常常比传统K均值算法有更快的计算速度，但产生的簇群与传统K均值算法往往也是不同的。</p><p>BisectingKMeans是一个Estimator，在基础模型上训练得到BisectingKMeansModel。</p><h3 id="Examples-2"><a href="#Examples-2" class="headerlink" title="Examples"></a>Examples</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.clustering <span class="keyword">import</span> BisectingKMeans</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"BisectingKMeansExample"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Loads data.</span></span><br><span class="line">dataset = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"data/mllib/sample_kmeans_data.txt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Trains a bisecting k-means model.</span></span><br><span class="line">bkm = BisectingKMeans().setK(<span class="number">2</span>).setSeed(<span class="number">1</span>)</span><br><span class="line">model = bkm.fit(dataset)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Evaluate clustering.</span></span><br><span class="line">cost = model.computeCost(dataset)</span><br><span class="line">print(<span class="string">"Within Set Sum of Squared Errors = "</span> + str(cost))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Shows the result.</span></span><br><span class="line">print(<span class="string">"Cluster Centers: "</span>)</span><br><span class="line">centers = model.clusterCenters()</span><br><span class="line"><span class="keyword">for</span> center <span class="keyword">in</span> centers:</span><br><span class="line">    print(center)</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Within Set Sum of Squared Errors = <span class="number">0.11999999999994547</span></span><br><span class="line">Cluster Centers: </span><br><span class="line">[ <span class="number">0.1</span>  <span class="number">0.1</span>  <span class="number">0.1</span>]</span><br><span class="line">[ <span class="number">9.1</span>  <span class="number">9.1</span>  <span class="number">9.1</span>]</span><br></pre></td></tr></table></figure><p>Find full example code at “examples/src/main/python/ml/bisecting_k_means_example.py” in the Spark repo.</p><h2 id="Gaussian-Mixture-Model-GMM"><a href="#Gaussian-Mixture-Model-GMM" class="headerlink" title="Gaussian Mixture Model(GMM)"></a>Gaussian Mixture Model(GMM)</h2><p><code>混合高斯模型</code>描述数据点以一定的概率服从k种高斯子分布的一种混合分布。Spark.ml使用EM算法给出一组样本的极大似然模型。</p><p>GaussianMixture被实现为一个Estimator,并生成一个GaussianMixtureModel基本模型。</p><ul><li><strong>Input Columns</strong></li></ul><table><thead><tr><th>Param name</th><th>Type(s)</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>featuresCol</td><td>Vector</td><td>“features”</td><td>Feature vector</td></tr></tbody></table><ul><li><strong>Output Columns</strong></li></ul><table><thead><tr><th>Param name</th><th>Type(s)</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td>predictionCol</td><td>Int</td><td>“prediction”</td><td>Predicted cluster center</td></tr><tr><td>probabilityCol</td><td>Vector</td><td>“probability”</td><td>Probability of each cluster</td></tr></tbody></table><h3 id="Examples-3"><a href="#Examples-3" class="headerlink" title="Examples"></a>Examples</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.clustering <span class="keyword">import</span> GaussianMixture</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"GaussianMixtureExample"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># loads data</span></span><br><span class="line">dataset = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"data/mllib/sample_kmeans_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">gmm = GaussianMixture().setK(<span class="number">2</span>).setSeed(<span class="number">538009335</span>)</span><br><span class="line">model = gmm.fit(dataset)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Gaussians shown as a DataFrame: "</span>)</span><br><span class="line">model.gaussiansDF.show(truncate=<span class="keyword">False</span>)</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Gaussians shown <span class="keyword">as</span> a DataFrame: </span><br><span class="line">+-------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">|mean                                                         |cov                                                                                                                                                                                                     |</span><br><span class="line">+-------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">|[<span class="number">0.10000000000001552</span>,<span class="number">0.10000000000001552</span>,<span class="number">0.10000000000001552</span>]|<span class="number">0.006666666666806454</span>  <span class="number">0.006666666666806454</span>  <span class="number">0.006666666666806454</span>  </span><br><span class="line"><span class="number">0.006666666666806454</span>  <span class="number">0.006666666666806454</span>  <span class="number">0.006666666666806454</span>  </span><br><span class="line"><span class="number">0.006666666666806454</span>  <span class="number">0.006666666666806454</span>  <span class="number">0.006666666666806454</span>  |</span><br><span class="line">|[<span class="number">9.099999999999984</span>,<span class="number">9.099999999999984</span>,<span class="number">9.099999999999984</span>]      |<span class="number">0.006666666666812185</span>  <span class="number">0.006666666666812185</span>  <span class="number">0.006666666666812185</span>  </span><br><span class="line"><span class="number">0.006666666666812185</span>  <span class="number">0.006666666666812185</span>  <span class="number">0.006666666666812185</span>  </span><br><span class="line"><span class="number">0.006666666666812185</span>  <span class="number">0.006666666666812185</span>  <span class="number">0.006666666666812185</span>  |</span><br><span class="line">+-------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure><p>Find full example code at “examples/src/main/python/ml/gaussian_mixture_example.py” in the Spark repo.</p><p><strong>更多相关信息请查阅<a href="https://spark.apache.org/docs/latest/ml-clustering.html" target="_blank" rel="noopener">Spark Clustering文档</a></strong></p><h2 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h2>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;聚类算法&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
&lt;p&gt;本节介绍MLlib中的聚类算法(&lt;code&gt;KMeans&lt;/code&gt;, &lt;code&gt;LDA&lt;/code&gt;, &lt;code&gt;GMM&lt;/code&gt;)。在&lt;a href=&quot;https://spark.apache.org/docs/latest/mllib-clustering.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;基于RDD-API聚类指南&lt;/a&gt;里还提供了有关这些算法的相关信息。&lt;/p&gt;
    
    </summary>
    
      <category term="Spark" scheme="https://blog.writeathink.cn/categories/Spark/"/>
    
      <category term="MLlib" scheme="https://blog.writeathink.cn/categories/Spark/MLlib/"/>
    
    
      <category term="KMeans" scheme="https://blog.writeathink.cn/tags/KMeans/"/>
    
      <category term="LDA" scheme="https://blog.writeathink.cn/tags/LDA/"/>
    
      <category term="Bisecting KMeans" scheme="https://blog.writeathink.cn/tags/Bisecting-KMeans/"/>
    
      <category term="GMM" scheme="https://blog.writeathink.cn/tags/GMM/"/>
    
  </entry>
  
  <entry>
    <title>SparkMLlib-Classification-and-Regression</title>
    <link href="https://blog.writeathink.cn/2018/01/22/SparkMLlib-Classification-and-Regression/"/>
    <id>https://blog.writeathink.cn/2018/01/22/SparkMLlib-Classification-and-Regression/</id>
    <published>2018-01-22T02:31:37.000Z</published>
    <updated>2018-03-01T09:36:14.503Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p class="description">本节涵盖分类和回归算法。它还包括讨论特定类别算法的部分，例如线性方法，树和集成方法。<br></p><p><img src="https://pic4.zhimg.com/v2-19d700cb25582df73feeb3a8ac96d6fe_r.jpg" alt="" style="width:100%"></p><a id="more"></a><h2 id="Classfication"><a href="#Classfication" class="headerlink" title="Classfication"></a><strong>Classfication</strong></h2><h3 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h3><p><code>Logistic Regression</code>(逻辑回归)是一个流行的分类问题预测方法。它是<a href="https://en.wikipedia.org/wiki/Generalized_linear_model" target="_blank" rel="noopener">Generalized Linear models</a>(广义线性模型)的一个特殊应用以预测结果概率。在spark.ml逻辑回归中，可以使用二分类逻辑回归来预测二分类问题，或者可以使用多分类逻辑回归来预测多类别分类问题。使用family 参数来选择这两个算法，或者不设置，Spark会推断出正确的变量。</p><ol><li><p>将family参数设置为“multinomial”时，多分类逻辑回归可以用于二分类问题。它会产生两套coeficients(w)和两个inercepts(b)。</p></li><li><p>当在具无拦截的连续非零列的数据集上训练LogisticRegressionModel时，Spark MLlib输出连续非零列零系数。这种行为与R glmnet相同，但与LIBSVM不同。</p></li></ol><h4 id="Binomial-Logistic-Regression"><a href="#Binomial-Logistic-Regression" class="headerlink" title="Binomial Logistic Regression"></a>Binomial Logistic Regression</h4><p>有关二项逻辑回归实现的更多背景和更多细节，请参阅中的<a href="https://spark.apache.org/docs/latest/mllib-linear-methods.html#logistic-regression" target="_blank" rel="noopener">logistic regression spark.mllib文档</a>。</p><ul><li>Examples</li></ul><p>下面的例子显示了如何用弹性网络正则化的二元分类问题训练二项和多项逻辑回归模型。elasticNetParam参数对应于α(学习率)，regParam参数对应于λ(正则化参数)。有关参数的更多细节可以在<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.classification.LogisticRegression" target="_blank" rel="noopener">Python API文档</a>中找到。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"LogisticRegressionWithElasticNetExample"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Load training data</span></span><br><span class="line">training = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">lr = LogisticRegression(maxIter=<span class="number">10</span>, regParam=<span class="number">0.3</span>, elasticNetParam=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit the model</span></span><br><span class="line">lrModel = lr.fit(training)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the coefficients and intercept for logistic regression</span></span><br><span class="line">print(<span class="string">"Coefficients: "</span> + str(lrModel.coefficients))</span><br><span class="line">print(<span class="string">"Intercept: "</span> + str(lrModel.intercept))</span><br><span class="line"></span><br><span class="line"><span class="comment"># We can also use the multinomial family for binary classification</span></span><br><span class="line">mlr = LogisticRegression(maxIter=<span class="number">10</span>, regParam=<span class="number">0.3</span>, elasticNetParam=<span class="number">0.8</span>, family=<span class="string">"multinomial"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit the model</span></span><br><span class="line">mlrModel = mlr.fit(training)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the coefficients and intercepts for logistic regression with multinomial family</span></span><br><span class="line">print(<span class="string">"Multinomial coefficients: "</span> + str(mlrModel.coefficientMatrix))</span><br><span class="line">print(<span class="string">"Multinomial intercepts: "</span> + str(mlrModel.interceptVector))</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Coefficients: (<span class="number">692</span>,[<span class="number">244</span>,<span class="number">263</span>,<span class="number">272</span>,<span class="number">300</span>,<span class="number">301</span>,<span class="number">328</span>,<span class="number">350</span>,<span class="number">351</span>,<span class="number">378</span>,<span class="number">379</span>,<span class="number">405</span>,<span class="number">406</span>,<span class="number">407</span>,<span class="number">428</span>,<span class="number">433</span>,<span class="number">434</span>,<span class="number">455</span>,<span class="number">456</span>,<span class="number">461</span>,<span class="number">462</span>,<span class="number">483</span>,<span class="number">484</span>,<span class="number">489</span>,<span class="number">490</span>,<span class="number">496</span>,<span class="number">511</span>,<span class="number">512</span>,<span class="number">517</span>,<span class="number">539</span>,<span class="number">540</span>,<span class="number">568</span>],[<span class="number">-7.35398352419e-05</span>,<span class="number">-9.10273850559e-05</span>,<span class="number">-0.000194674305469</span>,<span class="number">-0.000203006424735</span>,<span class="number">-3.14761833149e-05</span>,<span class="number">-6.84297760266e-05</span>,<span class="number">1.58836268982e-05</span>,<span class="number">1.40234970914e-05</span>,<span class="number">0.00035432047525</span>,<span class="number">0.000114432728982</span>,<span class="number">0.000100167123837</span>,<span class="number">0.00060141093038</span>,<span class="number">0.000284024817912</span>,<span class="number">-0.000115410847365</span>,<span class="number">0.000385996886313</span>,<span class="number">0.000635019557424</span>,<span class="number">-0.000115064123846</span>,<span class="number">-0.00015271865865</span>,<span class="number">0.000280493380899</span>,<span class="number">0.000607011747119</span>,<span class="number">-0.000200845966325</span>,<span class="number">-0.000142107557929</span>,<span class="number">0.000273901034116</span>,<span class="number">0.00027730456245</span>,<span class="number">-9.83802702727e-05</span>,<span class="number">-0.000380852244352</span>,<span class="number">-0.000253151980086</span>,<span class="number">0.000277477147708</span>,<span class="number">-0.000244361976392</span>,<span class="number">-0.00153947446876</span>,<span class="number">-0.000230733284113</span>])</span><br><span class="line">Intercept: <span class="number">0.22456315961250325</span></span><br><span class="line">Multinomial coefficients: <span class="number">2</span> X <span class="number">692</span> CSRMatrix</span><br><span class="line">(<span class="number">0</span>,<span class="number">244</span>) <span class="number">0.0</span></span><br><span class="line">(<span class="number">0</span>,<span class="number">263</span>) <span class="number">0.0001</span></span><br><span class="line">(<span class="number">0</span>,<span class="number">272</span>) <span class="number">0.0001</span></span><br><span class="line">(<span class="number">0</span>,<span class="number">300</span>) <span class="number">0.0001</span></span><br><span class="line">(<span class="number">0</span>,<span class="number">350</span>) <span class="number">-0.0</span></span><br><span class="line">(<span class="number">0</span>,<span class="number">351</span>) <span class="number">-0.0</span></span><br><span class="line">(<span class="number">0</span>,<span class="number">378</span>) <span class="number">-0.0</span></span><br><span class="line">(<span class="number">0</span>,<span class="number">379</span>) <span class="number">-0.0</span></span><br><span class="line">(<span class="number">0</span>,<span class="number">405</span>) <span class="number">-0.0</span></span><br><span class="line">(<span class="number">0</span>,<span class="number">406</span>) <span class="number">-0.0006</span></span><br><span class="line">(<span class="number">0</span>,<span class="number">407</span>) <span class="number">-0.0001</span></span><br><span class="line">(<span class="number">0</span>,<span class="number">428</span>) <span class="number">0.0001</span></span><br><span class="line">(<span class="number">0</span>,<span class="number">433</span>) <span class="number">-0.0</span></span><br><span class="line">(<span class="number">0</span>,<span class="number">434</span>) <span class="number">-0.0007</span></span><br><span class="line">(<span class="number">0</span>,<span class="number">455</span>) <span class="number">0.0001</span></span><br><span class="line">(<span class="number">0</span>,<span class="number">456</span>) <span class="number">0.0001</span></span><br><span class="line">..</span><br><span class="line">..</span><br><span class="line">Multinomial intercepts: [<span class="number">-0.120658794459</span>,<span class="number">0.120658794459</span>]</span><br></pre></td></tr></table></figure><p>Find full example code at “examples/src/main/python/ml/logistic_regression_with_elastic_net.py” in the Spark repo.</p><p>spark.ml逻辑回归工具还支持在训练集上提取模型的总结。请注意，在 BinaryLogisticRegressionSummary中存储为DataFrame的预测结果和指标被注释@transient(临时的)，因此仅适用于驱动程序。</p><p><a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.classification.LogisticRegressionSummary" target="_blank" rel="noopener">LogisticRegressionTrainingSummary</a> 为 <a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.classification.LogisticRegressionModel" target="_blank" rel="noopener">LogisticRegressionModel</a>提供了一个summary。目前只支持二分类问题。将来会增加对多分类问题模型summary的支持。</p><p>继续上面的例子</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession \</span><br><span class="line">    .builder \</span><br><span class="line">    .appName(<span class="string">"LogisticRegressionSummary"</span>) \</span><br><span class="line">    .getOrCreate()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load training data</span></span><br><span class="line">training = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">lr = LogisticRegression(maxIter=<span class="number">10</span>, regParam=<span class="number">0.3</span>, elasticNetParam=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit the model</span></span><br><span class="line">lrModel = lr.fit(training)</span><br><span class="line"></span><br><span class="line"><span class="comment"># $example on$</span></span><br><span class="line"><span class="comment"># Extract the summary from the returned LogisticRegressionModel instance trained</span></span><br><span class="line"><span class="comment"># in the earlier example</span></span><br><span class="line">trainingSummary = lrModel.summary</span><br><span class="line"></span><br><span class="line"><span class="comment"># Obtain the objective per iteration</span></span><br><span class="line">objectiveHistory = trainingSummary.objectiveHistory</span><br><span class="line">print(<span class="string">"objectiveHistory:"</span>)</span><br><span class="line"><span class="keyword">for</span> objective <span class="keyword">in</span> objectiveHistory:</span><br><span class="line">    print(objective)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.</span></span><br><span class="line">trainingSummary.roc.show()</span><br><span class="line">print(<span class="string">"areaUnderROC: "</span> + str(trainingSummary.areaUnderROC))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the model threshold to maximize F-Measure</span></span><br><span class="line">fMeasure = trainingSummary.fMeasureByThreshold</span><br><span class="line">maxFMeasure = fMeasure.groupBy().max(<span class="string">'F-Measure'</span>).select(<span class="string">'max(F-Measure)'</span>).head()</span><br><span class="line">bestThreshold = fMeasure.where(fMeasure[<span class="string">'F-Measure'</span>] == maxFMeasure[<span class="string">'max(F-Measure)'</span>]) \</span><br><span class="line">    .select(<span class="string">'threshold'</span>).head()[<span class="string">'threshold'</span>]</span><br><span class="line">lr.setThreshold(bestThreshold)</span><br><span class="line"><span class="comment"># $example off$</span></span><br><span class="line"></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">objectiveHistory:</span><br><span class="line"><span class="number">0.6833149135741672</span></span><br><span class="line"><span class="number">0.6662875751473734</span></span><br><span class="line"><span class="number">0.6217068546034618</span></span><br><span class="line"><span class="number">0.6127265245887887</span></span><br><span class="line"><span class="number">0.6060347986802873</span></span><br><span class="line"><span class="number">0.6031750687571562</span></span><br><span class="line"><span class="number">0.5969621534836274</span></span><br><span class="line"><span class="number">0.5940743031983118</span></span><br><span class="line"><span class="number">0.5906089243339022</span></span><br><span class="line"><span class="number">0.5894724576491042</span></span><br><span class="line"><span class="number">0.5882187775729587</span></span><br><span class="line">+---+--------------------+</span><br><span class="line">|FPR|                 TPR|</span><br><span class="line">+---+--------------------+</span><br><span class="line">|<span class="number">0.0</span>|                 <span class="number">0.0</span>|</span><br><span class="line">|<span class="number">0.0</span>|<span class="number">0.017543859649122806</span>|</span><br><span class="line">|<span class="number">0.0</span>| <span class="number">0.03508771929824561</span>|</span><br><span class="line">|<span class="number">0.0</span>| <span class="number">0.05263157894736842</span>|</span><br><span class="line">|<span class="number">0.0</span>| <span class="number">0.07017543859649122</span>|</span><br><span class="line">|<span class="number">0.0</span>| <span class="number">0.08771929824561403</span>|</span><br><span class="line">|<span class="number">0.0</span>| <span class="number">0.10526315789473684</span>|</span><br><span class="line">|<span class="number">0.0</span>| <span class="number">0.12280701754385964</span>|</span><br><span class="line">|<span class="number">0.0</span>| <span class="number">0.14035087719298245</span>|</span><br><span class="line">|<span class="number">0.0</span>| <span class="number">0.15789473684210525</span>|</span><br><span class="line">|<span class="number">0.0</span>| <span class="number">0.17543859649122806</span>|</span><br><span class="line">|<span class="number">0.0</span>| <span class="number">0.19298245614035087</span>|</span><br><span class="line">|<span class="number">0.0</span>| <span class="number">0.21052631578947367</span>|</span><br><span class="line">|<span class="number">0.0</span>| <span class="number">0.22807017543859648</span>|</span><br><span class="line">|<span class="number">0.0</span>| <span class="number">0.24561403508771928</span>|</span><br><span class="line">|<span class="number">0.0</span>|  <span class="number">0.2631578947368421</span>|</span><br><span class="line">|<span class="number">0.0</span>|  <span class="number">0.2807017543859649</span>|</span><br><span class="line">|<span class="number">0.0</span>|  <span class="number">0.2982456140350877</span>|</span><br><span class="line">|<span class="number">0.0</span>|  <span class="number">0.3157894736842105</span>|</span><br><span class="line">|<span class="number">0.0</span>|  <span class="number">0.3333333333333333</span>|</span><br><span class="line">+---+--------------------+</span><br><span class="line">only showing top <span class="number">20</span> rows</span><br><span class="line"></span><br><span class="line">areaUnderROC: <span class="number">1.0</span></span><br></pre></td></tr></table></figure><p>Find full example code at “examples/src/main/python/ml/logistic_regression_summary_example.py” in the Spark repo.</p><h4 id="Multinomial-Logistic-Regression"><a href="#Multinomial-Logistic-Regression" class="headerlink" title="Multinomial Logistic Regression"></a>Multinomial Logistic Regression</h4><p>多分类通过多项逻辑（softmax）回归来支持。在多项逻辑回归中，算法产生K sets的系数集合(类似机器学习中的W)或维度K × J的矩阵其中K是结果分类数量和J是特征的数量。如果算法拟合时使用了偏置(类似机器学习中的b)，则偏置b也是一个K长度的向量。</p><ol><li><p>多项逻辑回归的系数(coefficients)：coefficientMatrix，偏置(intercepts):interceptVector。</p></li><li><p>coefficients和intercept在用多项逻辑回归训练模型中不适用。请使用coefficientMatrix，interceptVector</p></li></ol><p>结果的条件概率使用的是softmax function建模，我们使用多分类响应模型将加权负对数似然最小化，并使用elastic-net penalty来控制过拟合。</p><p><img src="https://github.com/cgDeepLearn/LearnSpark/blob/master/pics/logisticregressionsoftmax.png?raw=true" alt="Multinomial Logistic Regression"><br>关于推导的细节请查阅<a href="https://en.wikipedia.org/wiki/Multinomial_logistic_regression#As_a_log-linear_model" target="_blank" rel="noopener">这里</a>.</p><p>下面的例子展示了如何训练具有弹性网络正则化的多类逻辑回归模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"MultinomialLogisticRegression"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Load training data</span></span><br><span class="line">training = spark \</span><br><span class="line">    .read \</span><br><span class="line">    .format(<span class="string">"libsvm"</span>) \</span><br><span class="line">    .load(<span class="string">"data/mllib/sample_multiclass_classification_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">lr = LogisticRegression(maxIter=<span class="number">10</span>, regParam=<span class="number">0.3</span>, elasticNetParam=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit the model</span></span><br><span class="line">lrModel = lr.fit(training)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the coefficients and intercept for multinomial logistic regression</span></span><br><span class="line">print(<span class="string">"Coefficients: \n"</span> + str(lrModel.coefficientMatrix))</span><br><span class="line">print(<span class="string">"Intercept: "</span> + str(lrModel.interceptVector))</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Coefficients: </span><br><span class="line"><span class="number">3</span> X <span class="number">4</span> CSRMatrix</span><br><span class="line">(<span class="number">0</span>,<span class="number">3</span>) <span class="number">0.3176</span></span><br><span class="line">(<span class="number">1</span>,<span class="number">2</span>) <span class="number">-0.7804</span></span><br><span class="line">(<span class="number">1</span>,<span class="number">3</span>) <span class="number">-0.377</span></span><br><span class="line">Intercept: [<span class="number">0.0516523165983</span>,<span class="number">-0.123912249909</span>,<span class="number">0.0722599333102</span>]</span><br></pre></td></tr></table></figure><p>Find full example code at “examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py” in the Spark repo.</p><h2 id="Decision-Tree-Classifier"><a href="#Decision-Tree-Classifier" class="headerlink" title="Decision Tree Classifier"></a>Decision Tree Classifier</h2><p><code>决策树</code>是一种流行的分类和回归方法。关于spark.ml实现的更多信息可以在<a href="https://spark.apache.org/docs/latest/ml-classification-regression.html#decision-trees" target="_blank" rel="noopener">决策树部分</a>进一步找到。</p><ul><li>Examples</li></ul><p>以下示例以<code>LibSVM</code>格式加载数据集，将其分解为训练集和测试集，在训练数据集上训练，然后在保留的测试集上进行评估。我们使用两个特征变换器来准备数据; 这些帮助建立对标签和分类特征的索引，添加元数据到决策树算法可以识别的DataFrame上。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StringIndexer, VectorIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> MulticlassClassificationEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"DecisionTreeExample"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Load the data stored in LIBSVM format as a DataFrame.</span></span><br><span class="line">data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Index labels, adding metadata to the label column.</span></span><br><span class="line"><span class="comment"># Fit on whole dataset to include all labels in index.</span></span><br><span class="line">labelIndexer = StringIndexer(inputCol=<span class="string">"label"</span>, outputCol=<span class="string">"indexedLabel"</span>).fit(data)</span><br><span class="line"><span class="comment"># Automatically identify categorical features, and index them.</span></span><br><span class="line"><span class="comment"># We specify maxCategories so features with &gt; 4 distinct values are treated as continuous.</span></span><br><span class="line">featureIndexer =\</span><br><span class="line">    VectorIndexer(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"indexedFeatures"</span>, maxCategories=<span class="number">4</span>).fit(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split the data into training and test sets (30% held out for testing)</span></span><br><span class="line">(trainingData, testData) = data.randomSplit([<span class="number">0.7</span>, <span class="number">0.3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train a DecisionTree model.</span></span><br><span class="line">dt = DecisionTreeClassifier(labelCol=<span class="string">"indexedLabel"</span>, featuresCol=<span class="string">"indexedFeatures"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Chain indexers and tree in a Pipeline</span></span><br><span class="line">pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train model.  This also runs the indexers.</span></span><br><span class="line">model = pipeline.fit(trainingData)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make predictions.</span></span><br><span class="line">predictions = model.transform(testData)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select example rows to display.</span></span><br><span class="line">predictions.select(<span class="string">"prediction"</span>, <span class="string">"indexedLabel"</span>, <span class="string">"features"</span>).show(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select (prediction, true label) and compute test error</span></span><br><span class="line">evaluator = MulticlassClassificationEvaluator(</span><br><span class="line">    labelCol=<span class="string">"indexedLabel"</span>, predictionCol=<span class="string">"prediction"</span>, metricName=<span class="string">"accuracy"</span>)</span><br><span class="line">accuracy = evaluator.evaluate(predictions)</span><br><span class="line">print(<span class="string">"Test Error = %g "</span> % (<span class="number">1.0</span> - accuracy))</span><br><span class="line"></span><br><span class="line">treeModel = model.stages[<span class="number">2</span>]</span><br><span class="line"><span class="comment"># summary only</span></span><br><span class="line">print(treeModel)</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">+----------+------------+--------------------+</span><br><span class="line">|prediction|indexedLabel|            features|</span><br><span class="line">+----------+------------+--------------------+</span><br><span class="line">|       <span class="number">1.0</span>|         <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">95</span>,<span class="number">96</span>,<span class="number">97</span>,<span class="number">12.</span>..|</span><br><span class="line">|       <span class="number">1.0</span>|         <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">100</span>,<span class="number">101</span>,<span class="number">102.</span>..|</span><br><span class="line">|       <span class="number">1.0</span>|         <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">122</span>,<span class="number">123</span>,<span class="number">124.</span>..|</span><br><span class="line">|       <span class="number">1.0</span>|         <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">125</span>,<span class="number">126</span>,<span class="number">127.</span>..|</span><br><span class="line">|       <span class="number">1.0</span>|         <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">126</span>,<span class="number">127</span>,<span class="number">128.</span>..|</span><br><span class="line">+----------+------------+--------------------+</span><br><span class="line">only showing top <span class="number">5</span> rows</span><br><span class="line"></span><br><span class="line">Test Error = <span class="number">0.0454545</span> </span><br><span class="line">DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4b29a1e1d3b0e6e09baf) of depth <span class="number">1</span> <span class="keyword">with</span> <span class="number">3</span> nodes</span><br></pre></td></tr></table></figure><p>Find full example code at “examples/src/main/python/ml/decision_tree_classification_example.py” in the Spark repo.</p><h3 id="Random-Forest-Classifier"><a href="#Random-Forest-Classifier" class="headerlink" title="Random Forest Classifier"></a>Random Forest Classifier</h3><p><code>随机森林</code>是一种流行的分类和回归方法。关于spark.ml实现的更多信息可以在关于<a href="https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forests" target="_blank" rel="noopener">随机森林的章节</a>中进一步找到。</p><ul><li>Examples</li></ul><p>以下示例以LibSVM格式加载数据集，将其分解为训练集和测试集，在训练数据集上训练，然后在测试集上进行评估。我们使用两个特征变换器来准备数据,这有助于帮助索引标签和分类特征的类别，添加元数据到DtaFrame(基于树的算法可以识别的)。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> IndexToString, StringIndexer, VectorIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> MulticlassClassificationEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">'RandomForestExample'</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Load and parse the data file, converting it to a DataFrame.</span></span><br><span class="line">data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Index labels, adding metadata to the label column.</span></span><br><span class="line"><span class="comment"># Fit on whole dataset to include all labels in index.</span></span><br><span class="line">labelIndexer = StringIndexer(inputCol=<span class="string">"label"</span>, outputCol=<span class="string">"indexedLabel"</span>).fit(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Automatically identify categorical features, and index them.</span></span><br><span class="line"><span class="comment"># Set maxCategories so features with &gt; 4 distinct values are treated as continuous.</span></span><br><span class="line">featureIndexer =\</span><br><span class="line">    VectorIndexer(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"indexedFeatures"</span>, maxCategories=<span class="number">4</span>).fit(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split the data into training and test sets (30% held out for testing)</span></span><br><span class="line">(trainingData, testData) = data.randomSplit([<span class="number">0.7</span>, <span class="number">0.3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train a RandomForest model.</span></span><br><span class="line">rf = RandomForestClassifier(labelCol=<span class="string">"indexedLabel"</span>, featuresCol=<span class="string">"indexedFeatures"</span>, numTrees=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert indexed labels back to original labels.</span></span><br><span class="line">labelConverter = IndexToString(inputCol=<span class="string">"prediction"</span>, outputCol=<span class="string">"predictedLabel"</span>,</span><br><span class="line">                               labels=labelIndexer.labels)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Chain indexers and forest in a Pipeline</span></span><br><span class="line">pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train model.  This also runs the indexers.</span></span><br><span class="line">model = pipeline.fit(trainingData)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make predictions.</span></span><br><span class="line">predictions = model.transform(testData)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select example rows to display.</span></span><br><span class="line">predictions.select(<span class="string">"predictedLabel"</span>, <span class="string">"label"</span>, <span class="string">"features"</span>).show(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select (prediction, true label) and compute test error</span></span><br><span class="line">evaluator = MulticlassClassificationEvaluator(</span><br><span class="line">    labelCol=<span class="string">"indexedLabel"</span>, predictionCol=<span class="string">"prediction"</span>, metricName=<span class="string">"accuracy"</span>)</span><br><span class="line">accuracy = evaluator.evaluate(predictions)</span><br><span class="line">print(<span class="string">"Test Error = %g"</span> % (<span class="number">1.0</span> - accuracy))</span><br><span class="line"></span><br><span class="line">rfModel = model.stages[<span class="number">2</span>]</span><br><span class="line">print(rfModel)  <span class="comment"># summary only</span></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">+--------------+-----+--------------------+</span><br><span class="line">|predictedLabel|label|            features|</span><br><span class="line">+--------------+-----+--------------------+</span><br><span class="line">|           <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">98</span>,<span class="number">99</span>,<span class="number">100</span>,<span class="number">1.</span>..|</span><br><span class="line">|           <span class="number">1.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">100</span>,<span class="number">101</span>,<span class="number">102.</span>..|</span><br><span class="line">|           <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">124</span>,<span class="number">125</span>,<span class="number">126.</span>..|</span><br><span class="line">|           <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">124</span>,<span class="number">125</span>,<span class="number">126.</span>..|</span><br><span class="line">|           <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">124</span>,<span class="number">125</span>,<span class="number">126.</span>..|</span><br><span class="line">+--------------+-----+--------------------+</span><br><span class="line">only showing top <span class="number">5</span> rows</span><br><span class="line"></span><br><span class="line">Test Error = <span class="number">0.0416667</span></span><br><span class="line">RandomForestClassificationModel (uid=RandomForestClassifier_4e8ca5bee5432b4471d3) <span class="keyword">with</span> <span class="number">10</span> trees</span><br></pre></td></tr></table></figure><p>Find full example code at “examples/src/main/python/ml/random_forest_classifier_example.py” in the Spark repo.</p><h3 id="Gradient-Boosted-Tree-Classifier"><a href="#Gradient-Boosted-Tree-Classifier" class="headerlink" title="Gradient-Boosted Tree Classifier"></a>Gradient-Boosted Tree Classifier</h3><p><code>Gradient-boosted trees (GBTs)</code> 是一种流行的分类和回归方法，是一种决策树的集成算法。关于spark.ml实现的更多信息可以在<a href="https://spark.apache.org/docs/latest/ml-classification-regression.html#gradient-boosted-trees-gbts" target="_blank" rel="noopener">GBT</a>的一节中找到。</p><ul><li>Examples</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> GBTClassifier</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StringIndexer, VectorIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> MulticlassClassificationEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">'GBTExample'</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Load and parse the data file, converting it to a DataFrame.</span></span><br><span class="line">data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Index labels, adding metadata to the label column.</span></span><br><span class="line"><span class="comment"># Fit on whole dataset to include all labels in index.</span></span><br><span class="line">labelIndexer = StringIndexer(inputCol=<span class="string">"label"</span>, outputCol=<span class="string">"indexedLabel"</span>).fit(data)</span><br><span class="line"><span class="comment"># Automatically identify categorical features, and index them.</span></span><br><span class="line"><span class="comment"># Set maxCategories so features with &gt; 4 distinct values are treated as continuous.</span></span><br><span class="line">featureIndexer =\</span><br><span class="line">    VectorIndexer(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"indexedFeatures"</span>, maxCategories=<span class="number">4</span>).fit(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split the data into training and test sets (30% held out for testing)</span></span><br><span class="line">(trainingData, testData) = data.randomSplit([<span class="number">0.7</span>, <span class="number">0.3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train a GBT model.</span></span><br><span class="line">gbt = GBTClassifier(labelCol=<span class="string">"indexedLabel"</span>, featuresCol=<span class="string">"indexedFeatures"</span>, maxIter=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Chain indexers and GBT in a Pipeline</span></span><br><span class="line">pipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train model.  This also runs the indexers.</span></span><br><span class="line">model = pipeline.fit(trainingData)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make predictions.</span></span><br><span class="line">predictions = model.transform(testData)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select example rows to display.</span></span><br><span class="line">predictions.select(<span class="string">"prediction"</span>, <span class="string">"indexedLabel"</span>, <span class="string">"features"</span>).show(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select (prediction, true label) and compute test error</span></span><br><span class="line">evaluator = MulticlassClassificationEvaluator(</span><br><span class="line">    labelCol=<span class="string">"indexedLabel"</span>, predictionCol=<span class="string">"prediction"</span>, metricName=<span class="string">"accuracy"</span>)</span><br><span class="line">accuracy = evaluator.evaluate(predictions)</span><br><span class="line">print(<span class="string">"Test Error = %g"</span> % (<span class="number">1.0</span> - accuracy))</span><br><span class="line"></span><br><span class="line">gbtModel = model.stages[<span class="number">2</span>]</span><br><span class="line">print(gbtModel)  <span class="comment"># summary only</span></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">+----------+------------+--------------------+</span><br><span class="line">|prediction|indexedLabel|            features|</span><br><span class="line">+----------+------------+--------------------+</span><br><span class="line">|       <span class="number">1.0</span>|         <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">98</span>,<span class="number">99</span>,<span class="number">100</span>,<span class="number">1.</span>..|</span><br><span class="line">|       <span class="number">1.0</span>|         <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">100</span>,<span class="number">101</span>,<span class="number">102.</span>..|</span><br><span class="line">|       <span class="number">1.0</span>|         <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">124</span>,<span class="number">125</span>,<span class="number">126.</span>..|</span><br><span class="line">|       <span class="number">1.0</span>|         <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">124</span>,<span class="number">125</span>,<span class="number">126.</span>..|</span><br><span class="line">|       <span class="number">1.0</span>|         <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">124</span>,<span class="number">125</span>,<span class="number">126.</span>..|</span><br><span class="line">+----------+------------+--------------------+</span><br><span class="line">only showing top <span class="number">5</span> rows</span><br><span class="line"></span><br><span class="line">Test Error = <span class="number">0.030303</span></span><br><span class="line">GBTClassificationModel (uid=GBTClassifier_439db0c5094b1786e321) <span class="keyword">with</span> <span class="number">10</span> trees</span><br></pre></td></tr></table></figure><p>Find full example code at “examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py” in the Spark repo</p><h3 id="Multilayer-Perception-Classifier"><a href="#Multilayer-Perception-Classifier" class="headerlink" title="Multilayer Perception Classifier"></a>Multilayer Perception Classifier</h3><p><code>多层感知器分类器（MLPC）</code>是基于<a href="https://en.wikipedia.org/wiki/Feedforward_neural_network" target="_blank" rel="noopener">前馈人工神经网络</a>的分类器。MLPC由多层节点组成。每层完全连接到网络中的下一层。输入层中的节点表示输入数据。所有其他节点通过输入与节点权重<strong>w</strong> 和偏差<strong>b</strong>的线性组合并应用激活函数将输入映射到输出。<strong>K + 1</strong>层的MPLC可写成如下的矩阵形式：<br><img src="https://github.com/cgDeepLearn/LearnSpark/blob/master/pics/MLPC.png?raw=true" alt="MLPC"></p><p> 中间层节点使用sigmoid（logistic）函数：f(zi) = 1/(1 + e^-zi)\<br>  输出层中的节点使用softmax函数：f(zi) = e^zi/(∑e^zi) \<br> 输出层中N代表类别数目\<br> 多层感知机通过方向向传播来学习模型，我们使用逻辑损失函数优化,L-BFGS作为优化程序.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> MultilayerPerceptronClassifier</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> MulticlassClassificationEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">'MLPCExample'</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Load training dat</span></span><br><span class="line">data = spark.read.format(<span class="string">"libsvm"</span>)\</span><br><span class="line">    .load(<span class="string">"data/mllib/sample_multiclass_classification_data.txt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split the data into train and test</span></span><br><span class="line">splits = data.randomSplit([<span class="number">0.6</span>, <span class="number">0.4</span>], <span class="number">1234</span>)</span><br><span class="line">train = splits[<span class="number">0</span>]</span><br><span class="line">test = splits[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># specify layers for the neural network:</span></span><br><span class="line"><span class="comment"># input layer of size 4 (features), two intermediate of size 5 and 4</span></span><br><span class="line"><span class="comment"># and output of size 3 (classes)</span></span><br><span class="line">layers = [<span class="number">4</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># create the trainer and set its parameters</span></span><br><span class="line">trainer = MultilayerPerceptronClassifier(maxIter=<span class="number">100</span>, layers=layers, blockSize=<span class="number">128</span>, seed=<span class="number">1234</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># train the model</span></span><br><span class="line">model = trainer.fit(train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># compute accuracy on the test set</span></span><br><span class="line">result = model.transform(test)</span><br><span class="line">predictionAndLabels = result.select(<span class="string">"prediction"</span>, <span class="string">"label"</span>)</span><br><span class="line">evaluator = MulticlassClassificationEvaluator(metricName=<span class="string">"accuracy"</span>)</span><br><span class="line">print(<span class="string">"Test set accuracy = "</span> + str(evaluator.evaluate(predictionAndLabels)))</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Test set accuracy = <span class="number">0.8627450980392157</span></span><br></pre></td></tr></table></figure><p> Find full example code at “examples/src/main/python/ml/multilayer_perceptron_classification.py” in the Spark repo.</p><h3 id="Linear-Support-Vector-Machine"><a href="#Linear-Support-Vector-Machine" class="headerlink" title="Linear Support Vector Machine"></a>Linear Support Vector Machine</h3><p>一个<a href="https://en.wikipedia.org/wiki/Support_vector_machine" target="_blank" rel="noopener">支持向量机</a>在高或无限维空间构建一个或一簇超平面，该空间可用于分类，回归或其他任务。直觉上，通过寻找距离任何类别的最近的训练数据点（所谓的functional margin）最大距离的超平面来实现良好的分离，因为一般而言，margin越大，分类器的泛化误差越低。Spark ML中的LinearSVC支持线性SVM的二元分类。在内部，它使用OWLQN优化器来优化<a href="https://en.wikipedia.org/wiki/Hinge_loss" target="_blank" rel="noopener">hinge loss</a>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LinearSVC</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"linearSVCExample"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Load training data</span></span><br><span class="line">training = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">lsvc = LinearSVC(maxIter=<span class="number">10</span>, regParam=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit the model</span></span><br><span class="line">lsvcModel = lsvc.fit(training)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the coefficients and intercept for linearsSVC</span></span><br><span class="line">print(<span class="string">"Coefficients: "</span> + str(lsvcModel.coefficients))</span><br><span class="line">print(<span class="string">"Intercept: "</span> + str(lsvcModel.intercept))</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Coefficients:</span><br><span class="line">[<span class="number">0.0</span>,<span class="number">0.0</span>,......,<span class="number">-5.83656045253e-05</span>,<span class="number">-0.000123781942165</span>,<span class="number">-0.000117507049533</span>,<span class="number">-6.19711523061e-05</span>,<span class="number">-5.04200964581e-05</span>,<span class="number">-0.000140552602236</span>,<span class="number">-0.000141033094247</span>,<span class="number">-0.000192723082389</span>,<span class="number">-0.000480248996468</span>]</span><br><span class="line">Intercept: <span class="number">0.012911305214513969</span></span><br></pre></td></tr></table></figure><p>Find full example code at “examples/src/main/python/ml/linearsvc.py” in the Spark repo.</p><h3 id="One-vs-Rest-Classifier-又叫-One-vs-All"><a href="#One-vs-Rest-Classifier-又叫-One-vs-All" class="headerlink" title="One-vs-Rest Classifier(又叫 One-vs-All)"></a>One-vs-Rest Classifier(又叫 One-vs-All)</h3><p><a href="http://en.wikipedia.org/wiki/Multiclass_classification#One-vs.-rest" target="_blank" rel="noopener">OneVsRest</a>是一个将一个给定的二分类算法有效地扩展到多分类问题应用中的算法，也叫做“One-vs-All”算法。</p><p><code>OneVsRest</code>是一个被实现为Estimator。它采用一个基础的Classifier然后对于k个类别分别创建二分类问题。类别i的二分类分类器用来预测类别为i还是不为i，即将i类和其他类别区分开来。最后，通过依次对k个二分类分类器进行评估，取置信最高的分类器的标签作为i类别的标签。</p><ul><li>Examples</li></ul><p>下面的示例演示了如何加载<a href="http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/iris.scale" target="_blank" rel="noopener">Iris数据集</a>，将其解析为DataFrame并使用其执行多类别分类OneVsRest。计算测试误差以测量算法精度。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression, OneVsRest</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> MulticlassClassificationEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"oneVsRestExample"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># load data file.</span></span><br><span class="line">inputData = spark.read.format(<span class="string">"libsvm"</span>) \</span><br><span class="line">    .load(<span class="string">"data/mllib/sample_multiclass_classification_data.txt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># generate the train/test split.</span></span><br><span class="line">(train, test) = inputData.randomSplit([<span class="number">0.8</span>, <span class="number">0.2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># instantiate the base classifier.</span></span><br><span class="line">lr = LogisticRegression(maxIter=<span class="number">10</span>, tol=<span class="number">1E-6</span>, fitIntercept=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># instantiate the One Vs Rest Classifier.</span></span><br><span class="line">ovr = OneVsRest(classifier=lr)</span><br><span class="line"></span><br><span class="line"><span class="comment"># train the multiclass model.</span></span><br><span class="line">ovrModel = ovr.fit(train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># score the model on test data.</span></span><br><span class="line">predictions = ovrModel.transform(test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># obtain evaluator.</span></span><br><span class="line">evaluator = MulticlassClassificationEvaluator(metricName=<span class="string">"accuracy"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># compute the classification error on test data.</span></span><br><span class="line">accuracy = evaluator.evaluate(predictions)</span><br><span class="line">print(<span class="string">"Test Error = %g"</span> % (<span class="number">1.0</span> - accuracy))</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Test Error = 0.0625</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/one_vs_rest_example.py” in the Spark repo.</p><h3 id="Naive-Bayes"><a href="#Naive-Bayes" class="headerlink" title="Naive Bayes"></a>Naive Bayes</h3><p><a href="http://en.wikipedia.org/wiki/Naive_Bayes_classifier" target="_blank" rel="noopener">朴素贝叶斯分类器</a>是一个简单的基于贝叶斯定理与特征条件独立假设的概率分类器。spark.ml目前的实现支持<a href="http://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html" target="_blank" rel="noopener">多项式朴素贝叶斯</a>和<a href="http://nlp.stanford.edu/IR-book/html/htmledition/the-bernoulli-model-1.html" target="_blank" rel="noopener">伯努利朴素贝叶斯</a>。更多的信息可以在MLlib的<a href="https://spark.apache.org/docs/latest/mllib-naive-bayes.html#naive-bayes-sparkmllib" target="_blank" rel="noopener">Naive Bayes</a>一节中找到。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> NaiveBayes</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> MulticlassClassificationEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"NaiveBayesExample"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Load training data</span></span><br><span class="line">data = spark.read.format(<span class="string">"libsvm"</span>) \</span><br><span class="line">    .load(<span class="string">"data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split the data into train and test</span></span><br><span class="line">splits = data.randomSplit([<span class="number">0.6</span>, <span class="number">0.4</span>], <span class="number">1234</span>)</span><br><span class="line">train = splits[<span class="number">0</span>]</span><br><span class="line">test = splits[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># create the trainer and set its parameters</span></span><br><span class="line">nb = NaiveBayes(smoothing=<span class="number">1.0</span>, modelType=<span class="string">"multinomial"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># train the model</span></span><br><span class="line">model = nb.fit(train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># select example rows to display.</span></span><br><span class="line">predictions = model.transform(test)</span><br><span class="line">predictions.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># compute accuracy on the test set</span></span><br><span class="line">evaluator = MulticlassClassificationEvaluator(labelCol=<span class="string">"label"</span>, predictionCol=<span class="string">"prediction"</span>,</span><br><span class="line">                                              metricName=<span class="string">"accuracy"</span>)</span><br><span class="line">accuracy = evaluator.evaluate(predictions)</span><br><span class="line">print(<span class="string">"Test set accuracy = "</span> + str(accuracy))</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+-----+--------------------+--------------------+-----------+----------+</span><br><span class="line">|label|            features|       rawPrediction|probability|prediction|</span><br><span class="line">+-----+--------------------+--------------------+-----------+----------+</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">95</span>,<span class="number">96</span>,<span class="number">97</span>,<span class="number">12.</span>..|[<span class="number">-174115.98587057</span>...|  [<span class="number">1.0</span>,<span class="number">0.0</span>]|       <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">98</span>,<span class="number">99</span>,<span class="number">100</span>,<span class="number">1.</span>..|[<span class="number">-178402.52307196</span>...|  [<span class="number">1.0</span>,<span class="number">0.0</span>]|       <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">100</span>,<span class="number">101</span>,<span class="number">102.</span>..|[<span class="number">-100905.88974016</span>...|  [<span class="number">1.0</span>,<span class="number">0.0</span>]|       <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">123</span>,<span class="number">124</span>,<span class="number">125.</span>..|[<span class="number">-244784.29791241</span>...|  [<span class="number">1.0</span>,<span class="number">0.0</span>]|       <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">123</span>,<span class="number">124</span>,<span class="number">125.</span>..|[<span class="number">-196900.88506109</span>...|  [<span class="number">1.0</span>,<span class="number">0.0</span>]|       <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">124</span>,<span class="number">125</span>,<span class="number">126.</span>..|[<span class="number">-238164.45338794</span>...|  [<span class="number">1.0</span>,<span class="number">0.0</span>]|       <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">124</span>,<span class="number">125</span>,<span class="number">126.</span>..|[<span class="number">-184206.87833381</span>...|  [<span class="number">1.0</span>,<span class="number">0.0</span>]|       <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">127</span>,<span class="number">128</span>,<span class="number">129.</span>..|[<span class="number">-214174.52863813</span>...|  [<span class="number">1.0</span>,<span class="number">0.0</span>]|       <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">127</span>,<span class="number">128</span>,<span class="number">129.</span>..|[<span class="number">-182844.62193963</span>...|  [<span class="number">1.0</span>,<span class="number">0.0</span>]|       <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">128</span>,<span class="number">129</span>,<span class="number">130.</span>..|[<span class="number">-246557.10990301</span>...|  [<span class="number">1.0</span>,<span class="number">0.0</span>]|       <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">152</span>,<span class="number">153</span>,<span class="number">154.</span>..|[<span class="number">-208282.08496711</span>...|  [<span class="number">1.0</span>,<span class="number">0.0</span>]|       <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">152</span>,<span class="number">153</span>,<span class="number">154.</span>..|[<span class="number">-243457.69885665</span>...|  [<span class="number">1.0</span>,<span class="number">0.0</span>]|       <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">153</span>,<span class="number">154</span>,<span class="number">155.</span>..|[<span class="number">-260933.50931276</span>...|  [<span class="number">1.0</span>,<span class="number">0.0</span>]|       <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">154</span>,<span class="number">155</span>,<span class="number">156.</span>..|[<span class="number">-220274.72552901</span>...|  [<span class="number">1.0</span>,<span class="number">0.0</span>]|       <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">181</span>,<span class="number">182</span>,<span class="number">183.</span>..|[<span class="number">-154830.07125175</span>...|  [<span class="number">1.0</span>,<span class="number">0.0</span>]|       <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">99</span>,<span class="number">100</span>,<span class="number">101</span>,...|[<span class="number">-145978.24563975</span>...|  [<span class="number">0.0</span>,<span class="number">1.0</span>]|       <span class="number">1.0</span>|</span><br><span class="line">|  <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">100</span>,<span class="number">101</span>,<span class="number">102.</span>..|[<span class="number">-147916.32657832</span>...|  [<span class="number">0.0</span>,<span class="number">1.0</span>]|       <span class="number">1.0</span>|</span><br><span class="line">|  <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">123</span>,<span class="number">124</span>,<span class="number">125.</span>..|[<span class="number">-139663.27471685</span>...|  [<span class="number">0.0</span>,<span class="number">1.0</span>]|       <span class="number">1.0</span>|</span><br><span class="line">|  <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">124</span>,<span class="number">125</span>,<span class="number">126.</span>..|[<span class="number">-129013.44238751</span>...|  [<span class="number">0.0</span>,<span class="number">1.0</span>]|       <span class="number">1.0</span>|</span><br><span class="line">|  <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">125</span>,<span class="number">126</span>,<span class="number">127.</span>..|[<span class="number">-81829.799906049</span>...|  [<span class="number">0.0</span>,<span class="number">1.0</span>]|       <span class="number">1.0</span>|</span><br><span class="line">+-----+--------------------+--------------------+-----------+----------+</span><br><span class="line">only showing top <span class="number">20</span> rows</span><br><span class="line"></span><br><span class="line">Test set accuracy = <span class="number">1.0</span></span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/naive_bayes_example.py” in the Spark repo.</p><h2 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a><strong>Regression</strong></h2><h3 id="Linear-regression"><a href="#Linear-regression" class="headerlink" title="Linear regression"></a>Linear regression</h3><p>用于处理线性回归模型和模型摘要的界面与逻辑回归情况类似。</p><ul><li><p>When fitting LinearRegressionModel without intercept on dataset with constant nonzero column by “l-bfgs” solver, Spark MLlib outputs zero coefficients for constant nonzero columns. This behavior is the same as R glmnet but different from LIBSVM.</p></li><li><p>Examples</p></li></ul><p>下面的例子演示了训练弹性网络正则化线性回归模型和提取模型总结统计。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"LinearRegressionExample"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Load training data</span></span><br><span class="line">training = spark.read.format(<span class="string">"libsvm"</span>)\</span><br><span class="line">    .load(<span class="string">"data/mllib/sample_linear_regression_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">lr = LinearRegression(maxIter=<span class="number">10</span>, regParam=<span class="number">0.3</span>, elasticNetParam=<span class="number">0.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit the model</span></span><br><span class="line">lrModel = lr.fit(training)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the coefficients and intercept for linear regression</span></span><br><span class="line">print(<span class="string">"Coefficients: %s"</span> % str(lrModel.coefficients))</span><br><span class="line">print(<span class="string">"Intercept: %s"</span> % str(lrModel.intercept))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Summarize the model over the training set and print out some metrics</span></span><br><span class="line">trainingSummary = lrModel.summary</span><br><span class="line">print(<span class="string">"numIterations: %d"</span> % trainingSummary.totalIterations)</span><br><span class="line">print(<span class="string">"objectiveHistory: %s"</span> % str(trainingSummary.objectiveHistory))</span><br><span class="line">trainingSummary.residuals.show()</span><br><span class="line">print(<span class="string">"RMSE: %f"</span> % trainingSummary.rootMeanSquaredError)</span><br><span class="line">print(<span class="string">"r2: %f"</span> % trainingSummary.r2)</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Coefficients: [<span class="number">0.0</span>,<span class="number">0.322925166774</span>,<span class="number">-0.343854803456</span>,<span class="number">1.91560170235</span>,<span class="number">0.0528805868039</span>,<span class="number">0.76596272046</span>,<span class="number">0.0</span>,<span class="number">-0.151053926692</span>,<span class="number">-0.215879303609</span>,<span class="number">0.220253691888</span>]</span><br><span class="line">Intercept: <span class="number">0.1598936844239736</span></span><br><span class="line">numIterations: <span class="number">7</span></span><br><span class="line">objectiveHistory: [<span class="number">0.49999999999999994</span>, <span class="number">0.4967620357443381</span>, <span class="number">0.4936361664340463</span>, <span class="number">0.4936351537897608</span>, <span class="number">0.4936351214177871</span>, <span class="number">0.49363512062528014</span>, <span class="number">0.4936351206216114</span>]</span><br><span class="line">+--------------------+</span><br><span class="line">|           residuals|</span><br><span class="line">+--------------------+</span><br><span class="line">|  <span class="number">-9.889232683103197</span>|</span><br><span class="line">|  <span class="number">0.5533794340053554</span>|</span><br><span class="line">|  <span class="number">-5.204019455758823</span>|</span><br><span class="line">| <span class="number">-20.566686715507508</span>|</span><br><span class="line">|    <span class="number">-9.4497405180564</span>|</span><br><span class="line">|  <span class="number">-6.909112502719486</span>|</span><br><span class="line">|  <span class="number">-10.00431602969873</span>|</span><br><span class="line">|   <span class="number">2.062397807050484</span>|</span><br><span class="line">|  <span class="number">3.1117508432954772</span>|</span><br><span class="line">| <span class="number">-15.893608229419382</span>|</span><br><span class="line">|  <span class="number">-5.036284254673026</span>|</span><br><span class="line">|   <span class="number">6.483215876994333</span>|</span><br><span class="line">|  <span class="number">12.429497299109002</span>|</span><br><span class="line">|  <span class="number">-20.32003219007654</span>|</span><br><span class="line">| <span class="number">-2.0049838218725005</span>|</span><br><span class="line">| <span class="number">-17.867901734183793</span>|</span><br><span class="line">|   <span class="number">7.646455887420495</span>|</span><br><span class="line">| <span class="number">-2.2653482182417406</span>|</span><br><span class="line">|<span class="number">-0.10308920436195645</span>|</span><br><span class="line">|  <span class="number">-1.380034070385301</span>|</span><br><span class="line">+--------------------+</span><br><span class="line">only showing top <span class="number">20</span> rows</span><br><span class="line"></span><br><span class="line">RMSE: <span class="number">10.189077</span></span><br><span class="line">r2: <span class="number">0.022861</span></span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/linear_regression_with_elastic_net.py” in the Spark repo.</p><h3 id="Generalized-linear-regression"><a href="#Generalized-linear-regression" class="headerlink" title="Generalized linear regression"></a>Generalized linear regression</h3><p>与线性回归假设输出服从高斯分布不同，广义线性模型（GLMs）指定线性模型的因变量服从指数分布。<br>Spark的GeneralizedLinearRegression接口允许指定GLMs包括线性回归、泊松回归、逻辑回归等来处理多种预测问题。目前spark.ml仅支持指数型分布家族中的一部分类型，如下：</p><table><thead><tr><th>Family</th><th>Response Type</th><th>Supported Links</th></tr></thead><tbody><tr><td>Gaussian(高斯)</td><td>Continuous(连续)</td><td>Identity*, Log, Inverse</td></tr><tr><td>Binomial(二项)</td><td>Binary(二进制)</td><td>Logit*, Probit, CLogLog</td></tr><tr><td>Poisson(泊松)</td><td>Count(计数)</td><td>Log*, Identity, Sqrt</td></tr><tr><td>Gamma(伽马)</td><td>Continuous(连续)</td><td>Inverse*, Idenity, Log</td></tr><tr><td>Tweedie</td><td>Zero-inflated continuous(零膨胀连续)</td><td>Power link function</td></tr></tbody></table><p>注意：目前Spark在 GeneralizedLinearRegression仅支持最多4096个特征，如果特征超过4096个将会引发异常。对于线性回归和逻辑回归，如果模型特征数量会不断增长，则可通过 LinearRegression 和LogisticRegression来训练。</p><p>GLMs要求的指数型分布可以为正则或者自然形式。自然指数型分布为如下形式：<br><img src="https://github.com/cgDeepLearn/LearnSpark/blob/master/pics/GLM.png?raw=true" alt="广义线性模型"></p><p>Spark的GeneralizedLinearRegression接口提供汇总统计来诊断GLM模型的拟合程度，包括残差、p值、残差、Akaike信息准则及其它。</p><ul><li>Examples</li></ul><p>以下示例演示使用高斯响应和标识链接函数训练GLM并提取模型摘要统计信息。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> GeneralizedLinearRegression</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"GeneralizedLinearRegression"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Load training data</span></span><br><span class="line">dataset = spark.read.format(<span class="string">"libsvm"</span>)\</span><br><span class="line">    .load(<span class="string">"data/mllib/sample_linear_regression_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">glr = GeneralizedLinearRegression(family=<span class="string">"gaussian"</span>, link=<span class="string">"identity"</span>, maxIter=<span class="number">10</span>, regParam=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit the model</span></span><br><span class="line">model = glr.fit(dataset)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the coefficients and intercept for generalized linear regression model</span></span><br><span class="line">print(<span class="string">"Coefficients: "</span> + str(model.coefficients))</span><br><span class="line">print(<span class="string">"Intercept: "</span> + str(model.intercept))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Summarize the model over the training set and print out some metrics</span></span><br><span class="line">summary = model.summary</span><br><span class="line">print(<span class="string">"Coefficient Standard Errors: "</span> + str(summary.coefficientStandardErrors))</span><br><span class="line">print(<span class="string">"T Values: "</span> + str(summary.tValues))</span><br><span class="line">print(<span class="string">"P Values: "</span> + str(summary.pValues))</span><br><span class="line">print(<span class="string">"Dispersion: "</span> + str(summary.dispersion))</span><br><span class="line">print(<span class="string">"Null Deviance: "</span> + str(summary.nullDeviance))</span><br><span class="line">print(<span class="string">"Residual Degree Of Freedom Null: "</span> + str(summary.residualDegreeOfFreedomNull))</span><br><span class="line">print(<span class="string">"Deviance: "</span> + str(summary.deviance))</span><br><span class="line">print(<span class="string">"Residual Degree Of Freedom: "</span> + str(summary.residualDegreeOfFreedom))</span><br><span class="line">print(<span class="string">"AIC: "</span> + str(summary.aic))</span><br><span class="line">print(<span class="string">"Deviance Residuals: "</span>)</span><br><span class="line">summary.residuals().show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Coefficients: [<span class="number">0.0105418280813</span>,<span class="number">0.800325310056</span>,<span class="number">-0.784516554142</span>,<span class="number">2.36798871714</span>,<span class="number">0.501000208986</span>,<span class="number">1.12223511598</span>,<span class="number">-0.292682439862</span>,<span class="number">-0.498371743232</span>,<span class="number">-0.603579718068</span>,<span class="number">0.672555006719</span>]</span><br><span class="line">Intercept: <span class="number">0.14592176145232041</span></span><br><span class="line">Coefficient Standard Errors: [<span class="number">0.7950428434287478</span>, <span class="number">0.8049713176546897</span>, <span class="number">0.7975916824772489</span>, <span class="number">0.8312649247659919</span>, <span class="number">0.7945436200517938</span>, <span class="number">0.8118992572197593</span>, <span class="number">0.7919506385542777</span>, <span class="number">0.7973378214726764</span>, <span class="number">0.8300714999626418</span>, <span class="number">0.7771333489686802</span>, <span class="number">0.463930109648428</span>]</span><br><span class="line">T Values: [<span class="number">0.013259446542269243</span>, <span class="number">0.9942283563442594</span>, <span class="number">-0.9836067393599172</span>, <span class="number">2.848657084633759</span>, <span class="number">0.6305509179635714</span>, <span class="number">1.382234441029355</span>, <span class="number">-0.3695715687490668</span>, <span class="number">-0.6250446546128238</span>, <span class="number">-0.7271418403049983</span>, <span class="number">0.8654306337661122</span>, <span class="number">0.31453393176593286</span>]</span><br><span class="line">P Values: [<span class="number">0.989426199114056</span>, <span class="number">0.32060241580811044</span>, <span class="number">0.3257943227369877</span>, <span class="number">0.004575078538306521</span>, <span class="number">0.5286281628105467</span>, <span class="number">0.16752945248679119</span>, <span class="number">0.7118614002322872</span>, <span class="number">0.5322327097421431</span>, <span class="number">0.467486325282384</span>, <span class="number">0.3872259825794293</span>, <span class="number">0.753249430501097</span>]</span><br><span class="line">Dispersion: <span class="number">105.60988356821714</span></span><br><span class="line">Null Deviance: <span class="number">53229.3654338832</span></span><br><span class="line">Residual Degree Of Freedom Null: <span class="number">500</span></span><br><span class="line">Deviance: <span class="number">51748.8429484264</span></span><br><span class="line">Residual Degree Of Freedom: <span class="number">490</span></span><br><span class="line">AIC: <span class="number">3769.1895871765314</span></span><br><span class="line">Deviance Residuals: </span><br><span class="line">+-------------------+</span><br><span class="line">|  devianceResiduals|</span><br><span class="line">+-------------------+</span><br><span class="line">|<span class="number">-10.974359174246889</span>|</span><br><span class="line">| <span class="number">0.8872320138420559</span>|</span><br><span class="line">| <span class="number">-4.596541837478908</span>|</span><br><span class="line">|<span class="number">-20.411667435019638</span>|</span><br><span class="line">|<span class="number">-10.270419345342642</span>|</span><br><span class="line">|<span class="number">-6.0156058956799905</span>|</span><br><span class="line">|<span class="number">-10.663939415849267</span>|</span><br><span class="line">| <span class="number">2.1153960525024713</span>|</span><br><span class="line">| <span class="number">3.9807132379137675</span>|</span><br><span class="line">|<span class="number">-17.225218272069533</span>|</span><br><span class="line">| <span class="number">-4.611647633532147</span>|</span><br><span class="line">| <span class="number">6.4176669407698546</span>|</span><br><span class="line">| <span class="number">11.407137945300537</span>|</span><br><span class="line">| <span class="number">-20.70176540467664</span>|</span><br><span class="line">| <span class="number">-2.683748540510967</span>|</span><br><span class="line">|<span class="number">-16.755494794232536</span>|</span><br><span class="line">|  <span class="number">8.154668342638725</span>|</span><br><span class="line">|<span class="number">-1.4355057987358848</span>|</span><br><span class="line">|<span class="number">-0.6435058688185704</span>|</span><br><span class="line">|  <span class="number">-1.13802589316832</span>|</span><br><span class="line">+-------------------+</span><br><span class="line">only showing top <span class="number">20</span> rows</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/generalized_linear_regression_example.py” in the Spark repo.</p><h3 id="Decision-tree-regression"><a href="#Decision-tree-regression" class="headerlink" title="Decision tree regression"></a>Decision tree regression</h3><p>决策树以及其集成算法是机器学习分类和回归问题中非常流行的算法。因其易解释性、可处理类别特征、易扩展到多分类问题、不需特征缩放等性质被广泛使用。树集成算法如随机森林以及boosting算法几乎是解决分类和回归问题中表现最优的算法。</p><p>决策树是一个贪心算法递归地将特征空间划分为两个部分，在同一个叶子节点的数据最后会拥有同样的标签。每次划分通过贪心的以获得最大信息增益为目的，从可选择的分裂方式中选择最佳的分裂节点。节点不纯度有节点所含类别的同质性来衡量。工具提供为分类提供两种不纯度衡量（基尼不纯度和熵），为回归提供一种不纯度衡量（方差）。</p><p>spark.ml支持二分类、多分类以及回归的决策树算法，适用于连续特征以及类别特征。另外，对于分类问题，工具可以返回属于每种类别的概率（类别条件概率），对于回归问题工具可以返回预测在偏置样本上的方差。</p><ul><li>Examples</li></ul><p>以下示例以LibSVM格式加载数据集，将其分为训练集和测试集，在训练集训练，然后在测试集上进行评估。我们使用特征转换器为分类特征建立索引，并将元数据添加到DataFrame供决策树算法使用。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> RegressionEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"DecisionTreeRegressionExample"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Load the data stored in LIBSVM format as a DataFrame.</span></span><br><span class="line">data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Automatically identify categorical features, and index them.</span></span><br><span class="line"><span class="comment"># We specify maxCategories so features with &gt; 4 distinct values are treated as continuous.</span></span><br><span class="line">featureIndexer =\</span><br><span class="line">    VectorIndexer(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"indexedFeatures"</span>, maxCategories=<span class="number">4</span>).fit(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split the data into training and test sets (30% held out for testing)</span></span><br><span class="line">(trainingData, testData) = data.randomSplit([<span class="number">0.7</span>, <span class="number">0.3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train a DecisionTree model.</span></span><br><span class="line">dt = DecisionTreeRegressor(featuresCol=<span class="string">"indexedFeatures"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Chain indexer and tree in a Pipeline</span></span><br><span class="line">pipeline = Pipeline(stages=[featureIndexer, dt])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train model.  This also runs the indexer.</span></span><br><span class="line">model = pipeline.fit(trainingData)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make predictions.</span></span><br><span class="line">predictions = model.transform(testData)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select example rows to display.</span></span><br><span class="line">predictions.select(<span class="string">"prediction"</span>, <span class="string">"label"</span>, <span class="string">"features"</span>).show(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select (prediction, true label) and compute test error</span></span><br><span class="line">evaluator = RegressionEvaluator(</span><br><span class="line">    labelCol=<span class="string">"label"</span>, predictionCol=<span class="string">"prediction"</span>, metricName=<span class="string">"rmse"</span>)</span><br><span class="line">rmse = evaluator.evaluate(predictions)</span><br><span class="line">print(<span class="string">"Root Mean Squared Error (RMSE) on test data = %g"</span> % rmse)</span><br><span class="line"></span><br><span class="line">treeModel = model.stages[<span class="number">1</span>]</span><br><span class="line"><span class="comment"># summary only</span></span><br><span class="line">print(treeModel)</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+----------+-----+--------------------+</span><br><span class="line">|prediction|label|            features|</span><br><span class="line">+----------+-----+--------------------+</span><br><span class="line">|       <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">122</span>,<span class="number">123</span>,<span class="number">124.</span>..|</span><br><span class="line">|       <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">123</span>,<span class="number">124</span>,<span class="number">125.</span>..|</span><br><span class="line">|       <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">124</span>,<span class="number">125</span>,<span class="number">126.</span>..|</span><br><span class="line">|       <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">124</span>,<span class="number">125</span>,<span class="number">126.</span>..|</span><br><span class="line">|       <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">124</span>,<span class="number">125</span>,<span class="number">126.</span>..|</span><br><span class="line">+----------+-----+--------------------+</span><br><span class="line">only showing top <span class="number">5</span> rows</span><br><span class="line"></span><br><span class="line">Root Mean Squared Error (RMSE) on test data = <span class="number">0.164399</span></span><br><span class="line">DecisionTreeRegressionModel (uid=DecisionTreeRegressor_415194352f1feffc1231) of depth <span class="number">1</span> <span class="keyword">with</span> <span class="number">3</span> nodes</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/decision_tree_regression_example.py” in the Spark repo.</p><h3 id="Random-forest-regression"><a href="#Random-forest-regression" class="headerlink" title="Random forest regression"></a>Random forest regression</h3><p><code>随机森林</code>是决策树的集成算法。随机森林包含多个决策树来降低过拟合的风险。随机森林同样具有易解释性、可处理类别特征、易扩展到多分类问题、不需特征缩放等性质。</p><p>随机森林分别训练一系列的决策树，所以训练过程是并行的。因算法中加入随机过程，所以每个决策树又有少量区别。通过合并每个树的预测结果来减少预测的方差，提高在测试集上的性能表现。</p><p>随机性体现：<br>1.每次迭代时，对原始数据进行二次抽样来获得不同的训练数据。</p><p>2.对于每个树节点，考虑不同的随机特征子集来进行分裂。</p><p>除此之外，决策时的训练过程和单独决策树训练过程相同。</p><p>对新实例进行预测时，随机森林需要整合其各个决策树的预测结果。回归和分类问题的整合的方式略有不同。分类问题采取投票制，每个决策树投票给一个类别，获得最多投票的类别为最终结果。回归问题每个树得到的预测结果为实数，最终的预测结果为各个树预测结果的平均值。</p><p>spark.ml支持二分类、多分类以及回归的随机森林算法，适用于连续特征以及类别特征。</p><ul><li>Examples</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> RegressionEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"RandomForestRegressionExample"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Load and parse the data file, converting it to a DataFrame.</span></span><br><span class="line">data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Automatically identify categorical features, and index them.</span></span><br><span class="line"><span class="comment"># Set maxCategories so features with &gt; 4 distinct values are treated as continuous.</span></span><br><span class="line">featureIndexer =\</span><br><span class="line">    VectorIndexer(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"indexedFeatures"</span>, maxCategories=<span class="number">4</span>).fit(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split the data into training and test sets (30% held out for testing)</span></span><br><span class="line">(trainingData, testData) = data.randomSplit([<span class="number">0.7</span>, <span class="number">0.3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train a RandomForest model.</span></span><br><span class="line">rf = RandomForestRegressor(featuresCol=<span class="string">"indexedFeatures"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Chain indexer and forest in a Pipeline</span></span><br><span class="line">pipeline = Pipeline(stages=[featureIndexer, rf])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train model.  This also runs the indexer.</span></span><br><span class="line">model = pipeline.fit(trainingData)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make predictions.</span></span><br><span class="line">predictions = model.transform(testData)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select example rows to display.</span></span><br><span class="line">predictions.select(<span class="string">"prediction"</span>, <span class="string">"label"</span>, <span class="string">"features"</span>).show(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select (prediction, true label) and compute test error</span></span><br><span class="line">evaluator = RegressionEvaluator(</span><br><span class="line">    labelCol=<span class="string">"label"</span>, predictionCol=<span class="string">"prediction"</span>, metricName=<span class="string">"rmse"</span>)</span><br><span class="line">rmse = evaluator.evaluate(predictions)</span><br><span class="line">print(<span class="string">"Root Mean Squared Error (RMSE) on test data = %g"</span> % rmse)</span><br><span class="line"></span><br><span class="line">rfModel = model.stages[<span class="number">1</span>]</span><br><span class="line">print(rfModel)  <span class="comment"># summary only</span></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+----------+-----+--------------------+</span><br><span class="line">|prediction|label|            features|</span><br><span class="line">+----------+-----+--------------------+</span><br><span class="line">|       <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">95</span>,<span class="number">96</span>,<span class="number">97</span>,<span class="number">12.</span>..|</span><br><span class="line">|       <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">124</span>,<span class="number">125</span>,<span class="number">126.</span>..|</span><br><span class="line">|       <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">126</span>,<span class="number">127</span>,<span class="number">128.</span>..|</span><br><span class="line">|       <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">126</span>,<span class="number">127</span>,<span class="number">128.</span>..|</span><br><span class="line">|       <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">126</span>,<span class="number">127</span>,<span class="number">128.</span>..|</span><br><span class="line">+----------+-----+--------------------+</span><br><span class="line">only showing top <span class="number">5</span> rows</span><br><span class="line"></span><br><span class="line">Root Mean Squared Error (RMSE) on test data = <span class="number">0.193434</span></span><br><span class="line">RandomForestRegressionModel (uid=RandomForestRegressor_4bfa98dd14412263de8e) <span class="keyword">with</span> <span class="number">20</span> trees</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/random_forest_regressor_example.py” in the Spark repo.</p><h3 id="Gradient-boosted-tree-regression"><a href="#Gradient-boosted-tree-regression" class="headerlink" title="Gradient-boosted tree regression"></a>Gradient-boosted tree regression</h3><p><code>Gradient-boosted tree(GBTs)</code>梯度提升树是一种决策树的集成算法。它通过反复迭代训练决策树来最小化损失函数。与决策树类似，梯度提升树具有可处理类别特征、易扩展到多分类问题、不需特征缩放等性质。Spark.ml通过使用现有decision tree工具来实现。</p><p>梯度提升树依次迭代训练一系列的决策树。在一次迭代中，算法使用现有的集成来对每个训练实例的类别进行预测，然后将预测结果与真实的标签值进行比较。通过重新标记，来赋予预测结果不好的实例更高的权重。所以，在下次迭代中，决策树会对先前的错误进行修正。</p><p>对实例标签进行重新标记的机制由损失函数来指定。每次迭代过程中，梯度迭代树在训练数据上进一步减少损失函数的值。spark.ml为分类问题提供一种损失函数（Log Loss），为回归问题提供两种损失函数（平方误差与绝对误差）。</p><p>Spark.ml支持二分类以及回归的随机森林算法，适用于连续特征以及类别特征。</p><p>注意：梯度提升树目前不支持多分类问题。</p><ul><li>Examples</li></ul><p>注意：对于这个示例数据集，GBTRegressor实际上只需要1次迭代，但通常情况并非如此。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> GBTRegressor</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.evaluation <span class="keyword">import</span> RegressionEvaluator</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"GBTRegressionExample"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Load and parse the data file, converting it to a DataFrame.</span></span><br><span class="line">data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Automatically identify categorical features, and index them.</span></span><br><span class="line"><span class="comment"># Set maxCategories so features with &gt; 4 distinct values are treated as continuous.</span></span><br><span class="line">featureIndexer =\</span><br><span class="line">    VectorIndexer(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"indexedFeatures"</span>, maxCategories=<span class="number">4</span>).fit(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split the data into training and test sets (30% held out for testing)</span></span><br><span class="line">(trainingData, testData) = data.randomSplit([<span class="number">0.7</span>, <span class="number">0.3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train a GBT model.</span></span><br><span class="line">gbt = GBTRegressor(featuresCol=<span class="string">"indexedFeatures"</span>, maxIter=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Chain indexer and GBT in a Pipeline</span></span><br><span class="line">pipeline = Pipeline(stages=[featureIndexer, gbt])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train model.  This also runs the indexer.</span></span><br><span class="line">model = pipeline.fit(trainingData)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make predictions.</span></span><br><span class="line">predictions = model.transform(testData)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select example rows to display.</span></span><br><span class="line">predictions.select(<span class="string">"prediction"</span>, <span class="string">"label"</span>, <span class="string">"features"</span>).show(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Select (prediction, true label) and compute test error</span></span><br><span class="line">evaluator = RegressionEvaluator(</span><br><span class="line">    labelCol=<span class="string">"label"</span>, predictionCol=<span class="string">"prediction"</span>, metricName=<span class="string">"rmse"</span>)</span><br><span class="line">rmse = evaluator.evaluate(predictions)</span><br><span class="line">print(<span class="string">"Root Mean Squared Error (RMSE) on test data = %g"</span> % rmse)</span><br><span class="line"></span><br><span class="line">gbtModel = model.stages[<span class="number">1</span>]</span><br><span class="line">print(gbtModel)  <span class="comment"># summary only</span></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+----------+-----+--------------------+</span><br><span class="line">|prediction|label|            features|</span><br><span class="line">+----------+-----+--------------------+</span><br><span class="line">|       <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">100</span>,<span class="number">101</span>,<span class="number">102.</span>..|</span><br><span class="line">|       <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">121</span>,<span class="number">122</span>,<span class="number">123.</span>..|</span><br><span class="line">|       <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">122</span>,<span class="number">123</span>,<span class="number">124.</span>..|</span><br><span class="line">|       <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">123</span>,<span class="number">124</span>,<span class="number">125.</span>..|</span><br><span class="line">|       <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">124</span>,<span class="number">125</span>,<span class="number">126.</span>..|</span><br><span class="line">+----------+-----+--------------------+</span><br><span class="line">only showing top <span class="number">5</span> rows</span><br><span class="line"></span><br><span class="line">Root Mean Squared Error (RMSE) on test data = <span class="number">0.288675</span></span><br><span class="line">GBTRegressionModel (uid=GBTRegressor_4e5384caecb49745ae29) <span class="keyword">with</span> <span class="number">10</span> trees</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py” in the Spark repo.</p><h3 id="Survival-regression"><a href="#Survival-regression" class="headerlink" title="Survival regression"></a>Survival regression</h3><p>在spark.ml中，我们实施<a href="https://en.wikipedia.org/wiki/Accelerated_failure_time_model" target="_blank" rel="noopener">Acceleratedfailure time</a>(加速失效时间模型)，对于截尾数据它是一个参数化生存回归的模型。它描述了一个有对数生存时间的模型，所以它也常被称为生存分析的对数线性模型。与比例危险模型不同，因AFT模型中每个实例对目标函数的贡献是独立的，其更容易并行化。</p><p>给定协变量的值x，对于可能的右截尾的随机生存时间，AFT模型下的似然函数如下：<br><img src="https://github.com/cgDeepLearn/LearnSpark/blob/master/pics/GLM.png?raw=true" alt="AFT"></p><p>可以证明AFT模型是一个凸优化问题，即是说找到凸函数ι(β,σ)的最小值取决于系数向量β以及尺度参数σ的对数.其中实现的优化算法为L-BFGS，该实现与R的生存函数survreg的结果相匹配。</p><ul><li><p>当使用无拦截的连续非零列训练AFTSurvivalRegressionModel时，Spark MLlib为连续非零列输出零系数。这种处理与R中的生存函数survreg不同。</p></li><li><p>Examples</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> AFTSurvivalRegression</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"SurvivalRegressionExample"</span>).getOrCreate()</span><br><span class="line">training = spark.createDataFrame([</span><br><span class="line">    (<span class="number">1.218</span>, <span class="number">1.0</span>, Vectors.dense(<span class="number">1.560</span>, <span class="number">-0.605</span>)),</span><br><span class="line">    (<span class="number">2.949</span>, <span class="number">0.0</span>, Vectors.dense(<span class="number">0.346</span>, <span class="number">2.158</span>)),</span><br><span class="line">    (<span class="number">3.627</span>, <span class="number">0.0</span>, Vectors.dense(<span class="number">1.380</span>, <span class="number">0.231</span>)),</span><br><span class="line">    (<span class="number">0.273</span>, <span class="number">1.0</span>, Vectors.dense(<span class="number">0.520</span>, <span class="number">1.151</span>)),</span><br><span class="line">    (<span class="number">4.199</span>, <span class="number">0.0</span>, Vectors.dense(<span class="number">0.795</span>, <span class="number">-0.226</span>))], [<span class="string">"label"</span>, <span class="string">"censor"</span>, <span class="string">"features"</span>])</span><br><span class="line">quantileProbabilities = [<span class="number">0.3</span>, <span class="number">0.6</span>]</span><br><span class="line">aft = AFTSurvivalRegression(quantileProbabilities=quantileProbabilities,</span><br><span class="line">                            quantilesCol=<span class="string">"quantiles"</span>)</span><br><span class="line"></span><br><span class="line">model = aft.fit(training)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print the coefficients, intercept and scale parameter for AFT survival regression</span></span><br><span class="line">print(<span class="string">"Coefficients: "</span> + str(model.coefficients))</span><br><span class="line">print(<span class="string">"Intercept: "</span> + str(model.intercept))</span><br><span class="line">print(<span class="string">"Scale: "</span> + str(model.scale))</span><br><span class="line">model.transform(training).show(truncate=<span class="keyword">False</span>)</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></li></ul><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Coefficients: [<span class="number">-0.496304411053</span>,<span class="number">0.198452172529</span>]</span><br><span class="line">Intercept: <span class="number">2.638089896305637</span></span><br><span class="line">Scale: <span class="number">1.5472363533632303</span></span><br><span class="line">+-----+------+--------------+------------------+---------------------------------------+</span><br><span class="line">|label|censor|features      |prediction        |quantiles                              |</span><br><span class="line">+-----+------+--------------+------------------+---------------------------------------+</span><br><span class="line">|<span class="number">1.218</span>|<span class="number">1.0</span>   |[<span class="number">1.56</span>,<span class="number">-0.605</span>] |<span class="number">5.718985621018948</span> |[<span class="number">1.160322990805951</span>,<span class="number">4.99546058340675</span>]   |</span><br><span class="line">|<span class="number">2.949</span>|<span class="number">0.0</span>   |[<span class="number">0.346</span>,<span class="number">2.158</span>] |<span class="number">18.07678210850554</span> |[<span class="number">3.6675919944963185</span>,<span class="number">15.789837303662035</span>]|</span><br><span class="line">|<span class="number">3.627</span>|<span class="number">0.0</span>   |[<span class="number">1.38</span>,<span class="number">0.231</span>]  |<span class="number">7.381908879359957</span> |[<span class="number">1.4977129086101564</span>,<span class="number">6.448002719505488</span>] |</span><br><span class="line">|<span class="number">0.273</span>|<span class="number">1.0</span>   |[<span class="number">0.52</span>,<span class="number">1.151</span>]  |<span class="number">13.577717814884515</span>|[<span class="number">2.754778414791514</span>,<span class="number">11.859962351993207</span>] |</span><br><span class="line">|<span class="number">4.199</span>|<span class="number">0.0</span>   |[<span class="number">0.795</span>,<span class="number">-0.226</span>]|<span class="number">9.013087597344821</span> |[<span class="number">1.82866218773319</span>,<span class="number">7.8728164067854935</span>]  |</span><br><span class="line">+-----+------+--------------+------------------+---------------------------------------+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/aft_survival_regression.py” in the Spark repo.</p><h3 id="Isotonic-regression"><a href="#Isotonic-regression" class="headerlink" title="Isotonic regression"></a>Isotonic regression</h3><p><code>保序回归</code>是回归算法的一种。保序回归给定一个有限的实数集合(Y=y1,y2,…,yn)代表观察到的响应,以及(X=x1,x2,…,xn)代表未知的响应值，训练一个模型来最小化下列方程：<br><code>f(x) = ∑ωi(yi-xi)²</code>,其中wi为权重是正值，其结果方程称为保序回归，而且其解是唯一的。它可以被视为有顺序约束下的最小二乘法问题。实际上保序回归在拟合原始数据点时是一个单调函数。我们实现池旁者算法，它使用并行保序回归。训练数据是DataFrame格式，包含标签、特征值以及权重三列。另外保序算法还有一个参数名为isotonic，其默认值为真，它指定保序回归为保序（单调递增）或者反序（单调递减）。 </p><p>训练返回一个保序回归模型，可以被用于来预测已知或者未知特征值的标签。保序回归的结果是分段线性函数，预测规则如下：</p><ol><li><p>如果预测输入与训练中的特征值完全匹配，则返回相应标签。如果一个特征值对应多个预测标签值，则返回其中一个，具体是哪一个未指定。</p></li><li><p>如果预测输入比训练中的特征值都高（或者都低），则相应返回最高特征值或者最低特征值对应标签。如果一个特征值对应多个预测标签值，则相应返回最高值或者最低值。</p></li><li><p>如果预测输入落入两个特征值之间，则预测将会是一个分段线性函数，其值由两个最近的特征值的预测值计算得到。如果一个特征值对应多个预测标签值，则使用上述两种情况中的处理方式解决。</p></li></ol><ul><li>Examples</li></ul><p>有关API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.regression.IsotonicRegression" target="_blank" rel="noopener">IsotonicRegressionPython文档</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.regression <span class="keyword">import</span> IsotonicRegression</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"IsotonicRegressionExample"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Loads data.</span></span><br><span class="line">dataset = spark.read.format(<span class="string">"libsvm"</span>)\</span><br><span class="line">    .load(<span class="string">"data/mllib/sample_isotonic_regression_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Trains an isotonic regression model.</span></span><br><span class="line">model = IsotonicRegression().fit(dataset)</span><br><span class="line">print(<span class="string">"Boundaries in increasing order: %s\n"</span> % str(model.boundaries))</span><br><span class="line">print(<span class="string">"Predictions associated with the boundaries: %s\n"</span> % str(model.predictions))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Makes predictions.</span></span><br><span class="line">model.transform(dataset).show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Boundaries <span class="keyword">in</span> increasing order: [<span class="number">0.01</span>,<span class="number">0.17</span>,<span class="number">0.18</span>,<span class="number">0.27</span>,<span class="number">0.28</span>,<span class="number">0.29</span>,<span class="number">0.3</span>,<span class="number">0.31</span>,<span class="number">0.34</span>,<span class="number">0.35</span>,<span class="number">0.36</span>,<span class="number">0.41</span>,<span class="number">0.42</span>,<span class="number">0.71</span>,<span class="number">0.72</span>,<span class="number">0.74</span>,<span class="number">0.75</span>,<span class="number">0.76</span>,<span class="number">0.77</span>,<span class="number">0.78</span>,<span class="number">0.79</span>,<span class="number">0.8</span>,<span class="number">0.81</span>,<span class="number">0.82</span>,<span class="number">0.83</span>,<span class="number">0.84</span>,<span class="number">0.85</span>,<span class="number">0.86</span>,<span class="number">0.87</span>,<span class="number">0.88</span>,<span class="number">0.89</span>,<span class="number">1.0</span>]</span><br><span class="line"></span><br><span class="line">Predictions associated <span class="keyword">with</span> the boundaries: [<span class="number">0.157152712941</span>,<span class="number">0.157152712941</span>,<span class="number">0.189138196</span>,<span class="number">0.189138196</span>,<span class="number">0.20040796</span>,<span class="number">0.29576747</span>,<span class="number">0.43396226</span>,<span class="number">0.5081591025</span>,<span class="number">0.5081591025</span>,<span class="number">0.54156043</span>,<span class="number">0.550484446667</span>,<span class="number">0.550484446667</span>,<span class="number">0.563929967</span>,<span class="number">0.563929967</span>,<span class="number">0.566037736667</span>,<span class="number">0.566037736667</span>,<span class="number">0.56603774</span>,<span class="number">0.57929628</span>,<span class="number">0.64762876</span>,<span class="number">0.66241713</span>,<span class="number">0.67210607</span>,<span class="number">0.67210607</span>,<span class="number">0.674655785</span>,<span class="number">0.674655785</span>,<span class="number">0.73890872</span>,<span class="number">0.73992861</span>,<span class="number">0.84242733</span>,<span class="number">0.89673636</span>,<span class="number">0.89673636</span>,<span class="number">0.90719021</span>,<span class="number">0.9272055075</span>,<span class="number">0.9272055075</span>]</span><br><span class="line"></span><br><span class="line">+----------+--------------+-------------------+</span><br><span class="line">|     label|      features|         prediction|</span><br><span class="line">+----------+--------------+-------------------+</span><br><span class="line">|<span class="number">0.24579296</span>|(<span class="number">1</span>,[<span class="number">0</span>],[<span class="number">0.01</span>])|<span class="number">0.15715271294117644</span>|</span><br><span class="line">|<span class="number">0.28505864</span>|(<span class="number">1</span>,[<span class="number">0</span>],[<span class="number">0.02</span>])|<span class="number">0.15715271294117644</span>|</span><br><span class="line">|<span class="number">0.31208567</span>|(<span class="number">1</span>,[<span class="number">0</span>],[<span class="number">0.03</span>])|<span class="number">0.15715271294117644</span>|</span><br><span class="line">|<span class="number">0.35900051</span>|(<span class="number">1</span>,[<span class="number">0</span>],[<span class="number">0.04</span>])|<span class="number">0.15715271294117644</span>|</span><br><span class="line">|<span class="number">0.35747068</span>|(<span class="number">1</span>,[<span class="number">0</span>],[<span class="number">0.05</span>])|<span class="number">0.15715271294117644</span>|</span><br><span class="line">|<span class="number">0.16675166</span>|(<span class="number">1</span>,[<span class="number">0</span>],[<span class="number">0.06</span>])|<span class="number">0.15715271294117644</span>|</span><br><span class="line">|<span class="number">0.17491076</span>|(<span class="number">1</span>,[<span class="number">0</span>],[<span class="number">0.07</span>])|<span class="number">0.15715271294117644</span>|</span><br><span class="line">| <span class="number">0.0418154</span>|(<span class="number">1</span>,[<span class="number">0</span>],[<span class="number">0.08</span>])|<span class="number">0.15715271294117644</span>|</span><br><span class="line">|<span class="number">0.04793473</span>|(<span class="number">1</span>,[<span class="number">0</span>],[<span class="number">0.09</span>])|<span class="number">0.15715271294117644</span>|</span><br><span class="line">|<span class="number">0.03926568</span>| (<span class="number">1</span>,[<span class="number">0</span>],[<span class="number">0.1</span>])|<span class="number">0.15715271294117644</span>|</span><br><span class="line">|<span class="number">0.12952575</span>|(<span class="number">1</span>,[<span class="number">0</span>],[<span class="number">0.11</span>])|<span class="number">0.15715271294117644</span>|</span><br><span class="line">|       <span class="number">0.0</span>|(<span class="number">1</span>,[<span class="number">0</span>],[<span class="number">0.12</span>])|<span class="number">0.15715271294117644</span>|</span><br><span class="line">|<span class="number">0.01376849</span>|(<span class="number">1</span>,[<span class="number">0</span>],[<span class="number">0.13</span>])|<span class="number">0.15715271294117644</span>|</span><br><span class="line">|<span class="number">0.13105558</span>|(<span class="number">1</span>,[<span class="number">0</span>],[<span class="number">0.14</span>])|<span class="number">0.15715271294117644</span>|</span><br><span class="line">|<span class="number">0.08873024</span>|(<span class="number">1</span>,[<span class="number">0</span>],[<span class="number">0.15</span>])|<span class="number">0.15715271294117644</span>|</span><br><span class="line">|<span class="number">0.12595614</span>|(<span class="number">1</span>,[<span class="number">0</span>],[<span class="number">0.16</span>])|<span class="number">0.15715271294117644</span>|</span><br><span class="line">|<span class="number">0.15247323</span>|(<span class="number">1</span>,[<span class="number">0</span>],[<span class="number">0.17</span>])|<span class="number">0.15715271294117644</span>|</span><br><span class="line">|<span class="number">0.25956145</span>|(<span class="number">1</span>,[<span class="number">0</span>],[<span class="number">0.18</span>])|        <span class="number">0.189138196</span>|</span><br><span class="line">|<span class="number">0.20040796</span>|(<span class="number">1</span>,[<span class="number">0</span>],[<span class="number">0.19</span>])|        <span class="number">0.189138196</span>|</span><br><span class="line">|<span class="number">0.19581846</span>| (<span class="number">1</span>,[<span class="number">0</span>],[<span class="number">0.2</span>])|        <span class="number">0.189138196</span>|</span><br><span class="line">+----------+--------------+-------------------+</span><br><span class="line">only showing top <span class="number">20</span> rows</span><br></pre></td></tr></table></figure><p>Find full example code at “examples/src/main/python/ml/isotonic_regression_example.py” in the Spark repo.</p><p><strong>更多请查阅<a href="https://spark.apache.org/docs/latest/ml-classification-regression.html" target="_blank" rel="noopener">spark.ml-classification-regression</a></strong></p><h2 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h2>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;本节涵盖分类和回归算法。它还包括讨论特定类别算法的部分，例如线性方法，树和集成方法。&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-19d700cb25582df73feeb3a8ac96d6fe_r.jpg&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Spark" scheme="https://blog.writeathink.cn/categories/Spark/"/>
    
      <category term="MLlib" scheme="https://blog.writeathink.cn/categories/Spark/MLlib/"/>
    
    
      <category term="逻辑回归" scheme="https://blog.writeathink.cn/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    
      <category term="决策树" scheme="https://blog.writeathink.cn/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"/>
    
      <category term="GBDT" scheme="https://blog.writeathink.cn/tags/GBDT/"/>
    
      <category term="Naive Bayes" scheme="https://blog.writeathink.cn/tags/Naive-Bayes/"/>
    
  </entry>
  
  <entry>
    <title>SparkMLlib-Working-with-Features</title>
    <link href="https://blog.writeathink.cn/2018/01/21/sparkmllib-working-with-features/"/>
    <id>https://blog.writeathink.cn/2018/01/21/sparkmllib-working-with-features/</id>
    <published>2018-01-21T09:17:09.000Z</published>
    <updated>2018-03-01T09:37:32.859Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p class="description">Extracting, Transforming and Selecting features(特征的提取、转换、选择)<br></p><p><img src="" alt="" style="width:100%"></p><p>本节介绍用于处理特征的算法，大致分为以下几组：</p><ul><li><strong>Extraction(提取)</strong>：从“原始”数据中提取特征</li><li><strong>Transformation(转换)</strong>：缩放，转换或修改特征</li><li><strong>Selection(选择)</strong>：从一大组特征集中选择一个子集</li><li><strong>Locality Sensitive Hashing局部敏感散列（LSH）</strong>：这类算法将特征变换的各个方面与其他算法相结合。</li></ul><a id="more"></a><h2 id="Feature-Extractors"><a href="#Feature-Extractors" class="headerlink" title="Feature Extractors"></a><strong>Feature Extractors</strong></h2><h3 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a><strong>TF-IDF</strong></h3><p><strong>词频-逆向文档频率（<code>TF-IDF</code>）</strong> 是一种在文本挖掘中广泛使用的特征矢量化方法，用于反映在预料中词语在文档中的重要性。<em>t</em>表示一个词，<em>d</em>表示文档和<em>D</em>表示语料。词频<em>TF(t,d)</em>是词语<em>t</em>在文档<em>d</em>中出现的次数，而文档频率<em>DF(t, D)</em>是语料中文档包含词语<em>t</em>的的数量。如果我们只用词频来衡量重要性，那么很容易过分强调出现频率很高但是却只承载文档极少的信息的词语，例如“a”，“the”和“of”。如果一个词语经常在整个语料库中出现，这意味着对于特定的文档它并没有承载特殊的信息。<strong>逆文档频率是一个词语提供多少信息的数字度量</strong>： </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">IDF(t,D) = log(|D|+1)/(DF(t, D)+1)</span><br></pre></td></tr></table></figure><p>其中|D|是语料的文档总数。由于使用对数，所以如果一个词语在所有文档中出现，则其IDF值为0.请注意，smoothing term用来避免除以零对于那些在语料外的词语。TF-IDF度量是TF和IDF的乘积：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TFIDF(t,d,D)=TF(t,d)⋅IDF(t,D)</span><br></pre></td></tr></table></figure><p>词频和文档频率的定义有几个变体。在MLlib中，我们将TF和IDF分开，使它们更灵活。</p><p><code>TF</code>：HashingTF与CountVectorizer都可用于生成词频向量。</p><p>HashingTF是一个Transformer，其选取词语的集合并将这些集合转换成固定长度的特征向量。在文本处理中，“set of term”可能是一堆文字。 HashingTF利用哈希技巧(<a href="http://en.wikipedia.org/wiki/Feature_hashing" target="_blank" rel="noopener">hashing trick</a>)。通过应用散列函数(hash function)将原始特征映射成一个索引（term）。这里使用的哈希函数是<a href="https://en.wikipedia.org/wiki/MurmurHash" target="_blank" rel="noopener">MurmurHash 3</a> 。然后根据映射后的索引计算词频。这种方法避免了计算全局term-to-index的映射，而这些计算对于大型语料库来说可能是耗费的，但是它具有潜在的散列冲突，其中不同的原始特征可能在散列之后变成相同的term。为了减少碰撞的几率，我们可以增加目标特征维数，即散列表的桶数(buckets)。<strong>由于使用简单的模来将散列函数转换为列索引，所以建议使用2的幂作为特征维度，否则特征将不会均匀地映射到列</strong>。默认的特征维度是2^18=262144。一个可选的二进制切换参数控制词频计数。当设置为真时，所有非零频率计数都被设置为1.这对于模拟二进制计数而不是整数计数的离散概率模型特别有用。</p><p>CountVectorizer将文本文档转换为词条计数的向量。有关更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/ml-features.html#countvectorizer" target="_blank" rel="noopener">CountVectorizer</a> 。</p><p><code>IDF</code>：IDF是一个Estimator,被应用于一个数据集并产生一个IDFModel。IDFModel选取特征向量（通常从HashingTF或CountVectorizer创建）并缩放每一列。直观地，它减少了频繁出现在语料库中的列的权重。</p><p>Note： spark.ml不提供用于文本分割的工具。我们推荐用户参考<a href="http://nlp.stanford.edu/" target="_blank" rel="noopener">Stanford NLP Grou</a> 和 <a href="https://github.com/scalanlp/chalk" target="_blank" rel="noopener">scalanlp/chalk</a>。</p><ul><li>Examples</li></ul><p>在下面的代码段中，我们从一组句子开始。我们使用Tokenizer每个句子分成单词。对于每个句子（词包），我们使用HashingTF把语句散列成一个特征向量。我们用IDF来重新调整特征向量; 使用文本作为特征时，这通常会提高性能。我们的特征向量可以传递给学习算法。</p><p>有关API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.HashingTF" target="_blank" rel="noopener">HashingTF Python文档</a>和<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.IDF" target="_blank" rel="noopener">IDF Python文档</a>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> HashingTF, IDF, Tokenizer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"TF_IDfExample"</span>).getOrCreate()</span><br><span class="line">sentenceData = spark.createDataFrame([</span><br><span class="line">    (<span class="number">0.0</span>, <span class="string">"Hi I heard about Spark"</span>),</span><br><span class="line">    (<span class="number">0.0</span>, <span class="string">"I wish Java could use case classes"</span>),</span><br><span class="line">    (<span class="number">1.0</span>, <span class="string">"Logistic regression models are neat"</span>)</span><br><span class="line">], [<span class="string">"label"</span>, <span class="string">"sentence"</span>])</span><br><span class="line"></span><br><span class="line">tokenizer = Tokenizer(inputCol=<span class="string">"sentence"</span>, outputCol=<span class="string">"words"</span>)</span><br><span class="line">wordsData = tokenizer.transform(sentenceData)</span><br><span class="line"></span><br><span class="line">hashingTF = HashingTF(inputCol=<span class="string">"words"</span>, outputCol=<span class="string">"rawFeatures"</span>, numFeatures=<span class="number">20</span>)</span><br><span class="line">featurizedData = hashingTF.transform(wordsData)</span><br><span class="line"><span class="comment"># alternatively, CountVectorizer can also be used to get term frequency vectors</span></span><br><span class="line"></span><br><span class="line">idf = IDF(inputCol=<span class="string">"rawFeatures"</span>, outputCol=<span class="string">"features"</span>)</span><br><span class="line">idfModel = idf.fit(featurizedData)</span><br><span class="line">rescaledData = idfModel.transform(featurizedData)</span><br><span class="line"></span><br><span class="line">rescaledData.select(<span class="string">"label"</span>, <span class="string">"features"</span>).show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">|label|            features|</span><br><span class="line">|-----|--------------------|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">20</span>,[<span class="number">0</span>,<span class="number">5</span>,<span class="number">9</span>,<span class="number">17</span>],[<span class="number">0.</span>..|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">20</span>,[<span class="number">2</span>,<span class="number">7</span>,<span class="number">9</span>,<span class="number">13</span>,<span class="number">15</span>]...|</span><br><span class="line">|  <span class="number">1.0</span>|(<span class="number">20</span>,[<span class="number">4</span>,<span class="number">6</span>,<span class="number">13</span>,<span class="number">15</span>,<span class="number">18.</span>..|</span><br></pre></td></tr></table></figure><p>Find full example code at “examples/src/main/python/ml/tf_idf_example.py” in the Spark repo.</p><h3 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a><strong>Word2Vec</strong></h3><p><code>Word2Vec</code>是一个<code>Estimator</code>,它选取表征文件的单词序列(句子)来训练一个Word2VecModel。模型将每个单词映射到一个唯一的固定大小的向量vector。Word2VecModel 用所有单词在文档中的平均值将每个文档转换为一个向量vector; 然后这个vector可以用作预测，文档相似度计算等功能。请参阅<a href="https://spark.apache.org/docs/latest/mllib-feature-extraction.html#word2vec" target="_blank" rel="noopener">Word2Vec MLlib用户指南</a>了解更多详细信息。</p><ul><li>Examples</li></ul><p>在下面的代码段中，我们从一组文档开始，每个文档都被表示为一个单词序列。对于每个文档，我们把它转换成一个特征向量。这个特征向量可以传递给一个学习算法。</p><p>有关API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.Word2Vec" target="_blank" rel="noopener">Word2Vec Python文档</a>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> Word2Vec</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"Word2VecExample"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Input data: Each row is a bag of words from a sentence or document.</span></span><br><span class="line">documentDF = spark.createDataFrame([</span><br><span class="line">    (<span class="string">"Hi I heard about Spark"</span>.split(<span class="string">" "</span>), ),</span><br><span class="line">    (<span class="string">"I wish Java could use case classes"</span>.split(<span class="string">" "</span>), ),</span><br><span class="line">    (<span class="string">"Logistic regression models are neat"</span>.split(<span class="string">" "</span>), )</span><br><span class="line">], [<span class="string">"text"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Learn a mapping from words to Vectors.</span></span><br><span class="line">word2Vec = Word2Vec(vectorSize=<span class="number">3</span>, minCount=<span class="number">0</span>, inputCol=<span class="string">"text"</span>, outputCol=<span class="string">"result"</span>)</span><br><span class="line">model = word2Vec.fit(documentDF)</span><br><span class="line"></span><br><span class="line">result = model.transform(documentDF)</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> result.collect():</span><br><span class="line">    text, vector = row</span><br><span class="line">    print(<span class="string">"Text: [%s] =&gt; \nVector: %s\n"</span> % (<span class="string">", "</span>.join(text), str(vector)))</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Text: [Hi, I, heard, about, Spark] =&gt; </span><br><span class="line">Vector: [<span class="number">0.0334007266909</span>,<span class="number">0.00213784053922</span>,<span class="number">-0.00239131785929</span>]</span><br><span class="line"></span><br><span class="line">Text: [I, wish, Java, could, use, case, classes] =&gt; </span><br><span class="line">Vector: [<span class="number">0.0464252099129</span>,<span class="number">0.0357359477452</span>,<span class="number">-0.000244158453175</span>]</span><br><span class="line"></span><br><span class="line">Text: [Logistic, regression, models, are, neat] =&gt; </span><br><span class="line">Vector: [<span class="number">-0.00983053222299</span>,<span class="number">0.0668786892667</span>,<span class="number">-0.0307074898912</span>]</span><br><span class="line">---</span><br></pre></td></tr></table></figure><p>Find full example code at “examples/src/main/python/ml/word2vec_example.py” in the Spark repo.</p><h3 id="CountVectorizer"><a href="#CountVectorizer" class="headerlink" title="CountVectorizer"></a><strong>CountVectorizer</strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">在拟合过程中，CountVectorizer将选择整个语料库中词频排在前面vocabSize个的词汇。一个可选参数minDF也会影响拟合过程，方法是指定词汇必须出现的文档的最小数量（或小于1.0）。另一个可选的二进制切换参数控制输出向量。如果设置为true，则所有非零计数都设置为1.这对于模拟二进制计数而不是整数计数的离散概率模型特别有用。</span><br><span class="line"></span><br><span class="line">- Examples</span><br><span class="line"></span><br><span class="line">假设我们有列如下数据帧，有id和texts列：</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"></span><br><span class="line"> id | texts</span><br><span class="line">----|----------</span><br><span class="line"> 0  | Array(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)</span><br><span class="line"> 1  | Array(&quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;a&quot;)</span><br></pre></td></tr></table></figure><p>texts列中的每一行都是一个Array [String]类型的文档。调用CountVectorizer产生CountVectorizerModel与词汇（a，b，c）。然后转换后的输出列“向量”包含：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"> id | texts                           | vector</span><br><span class="line">----|---------------------------------|---------------</span><br><span class="line"> <span class="number">0</span>  | Array(<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>)            | (<span class="number">3</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">1.0</span>])</span><br><span class="line"> <span class="number">1</span>  | Array(<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>, <span class="string">"a"</span>)  | (<span class="number">3</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">2.0</span>,<span class="number">2.0</span>,<span class="number">1.0</span>])</span><br></pre></td></tr></table></figure><p>每个向量表示文档在词汇表上的标记计数。</p><p>有关API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.CountVectorizer" target="_blank" rel="noopener">CountVectorizer Python文档</a> 和<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.CountVectorizerModel" target="_blank" rel="noopener">CountVectorizerModel Python文档</a>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> CountVectorizer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"CountVectorizerExample"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Input data: Each row is a bag of words with a ID.</span></span><br><span class="line">df = spark.createDataFrame([</span><br><span class="line">    (<span class="number">0</span>, <span class="string">"a b c"</span>.split(<span class="string">" "</span>)),</span><br><span class="line">    (<span class="number">1</span>, <span class="string">"a b b c a"</span>.split(<span class="string">" "</span>))</span><br><span class="line">], [<span class="string">"id"</span>, <span class="string">"words"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># fit a CountVectorizerModel from the corpus.</span></span><br><span class="line">cv = CountVectorizer(inputCol=<span class="string">"words"</span>, outputCol=<span class="string">"features"</span>, vocabSize=<span class="number">3</span>, minDF=<span class="number">2.0</span>)</span><br><span class="line"></span><br><span class="line">model = cv.fit(df)</span><br><span class="line"></span><br><span class="line">result = model.transform(df)</span><br><span class="line">result.show(truncate=<span class="keyword">False</span>)</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>output:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+---+---------------+-------------------------+</span><br><span class="line">|id |words          |features                 |</span><br><span class="line">+---+---------------+-------------------------+</span><br><span class="line">|<span class="number">0</span>  |[a, b, c]      |(<span class="number">3</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">1.0</span>])|</span><br><span class="line">|<span class="number">1</span>  |[a, b, b, c, a]|(<span class="number">3</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">2.0</span>,<span class="number">2.0</span>,<span class="number">1.0</span>])|</span><br><span class="line">+---+---------------+-------------------------+</span><br></pre></td></tr></table></figure><p>Find full example code at “examples/src/main/python/ml/count_vectorizer_example.py” in the Spark repo.</p><h2 id="Feature-Transformers"><a href="#Feature-Transformers" class="headerlink" title="Feature Transformers"></a><strong>Feature Transformers</strong></h2><h3 id="Tokenizer"><a href="#Tokenizer" class="headerlink" title="Tokenizer"></a><strong>Tokenizer</strong></h3><p><a href="http://en.wikipedia.org/wiki/Lexical_analysis#Tokenization" target="_blank" rel="noopener">Tokenization</a>(分词)是将文本（如句子）分解成单个词（通常是单词）的过程。一个简单的<a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.feature.Tokenizer" target="_blank" rel="noopener">Tokenizer</a>类提供了这个功能。下面的例子展示了如何将句子拆分成单词序列。</p><p><a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.feature.RegexTokenizer" target="_blank" rel="noopener">RegexTokenizer</a>允许更高级的基于正则表达式（正则表达式）匹配的分词。默认情况下，使用参数“pattern”（正则表达式，默认：”\s+”）作为分隔符来分割输入文本。或者，用户可以将参数“gaps”设置为false，指示正则表达式“pattern”而不是分割间隙来表示“tokens”，并查找所有匹配事件作为分词结果。</p><ul><li>Examples</li></ul><p>有关API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.Tokenizer" target="_blank" rel="noopener">Tokenizer Python文档</a>和<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.RegexTokenizer" target="_blank" rel="noopener">RegexTokenizer Python文档</a>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> Tokenizer, RegexTokenizer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> col, udf</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> IntegerType</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"TokenizerExample"</span>).getOrCreate()</span><br><span class="line">sentenceDataFrame = spark.createDataFrame([</span><br><span class="line">    (<span class="number">0</span>, <span class="string">"Hi I heard about Spark"</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="string">"I wish Java could use case classes"</span>),</span><br><span class="line">    (<span class="number">2</span>, <span class="string">"Logistic,regression,models,are,neat"</span>)</span><br><span class="line">], [<span class="string">"id"</span>, <span class="string">"sentence"</span>])</span><br><span class="line"></span><br><span class="line">tokenizer = Tokenizer(inputCol=<span class="string">"sentence"</span>, outputCol=<span class="string">"words"</span>)</span><br><span class="line"></span><br><span class="line">regexTokenizer = RegexTokenizer(inputCol=<span class="string">"sentence"</span>, outputCol=<span class="string">"words"</span>, pattern=<span class="string">"\\W"</span>)</span><br><span class="line"><span class="comment"># alternatively, pattern="\\w+", gaps(False)</span></span><br><span class="line"></span><br><span class="line">countTokens = udf(<span class="keyword">lambda</span> words: len(words), IntegerType())</span><br><span class="line"></span><br><span class="line">tokenized = tokenizer.transform(sentenceDataFrame)</span><br><span class="line">tokenized.select(<span class="string">"sentence"</span>, <span class="string">"words"</span>)\</span><br><span class="line">    .withColumn(<span class="string">"tokens"</span>, countTokens(col(<span class="string">"words"</span>))).show(truncate=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">regexTokenized = regexTokenizer.transform(sentenceDataFrame)</span><br><span class="line">regexTokenized.select(<span class="string">"sentence"</span>, <span class="string">"words"</span>) \</span><br><span class="line">    .withColumn(<span class="string">"tokens"</span>, countTokens(col(<span class="string">"words"</span>))).show(truncate=<span class="keyword">False</span>)</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+-----------------------------------+------------------------------------------+------+</span><br><span class="line">|sentence                           |words                                     |tokens|</span><br><span class="line">+-----------------------------------+------------------------------------------+------+</span><br><span class="line">|Hi I heard about Spark             |[hi, i, heard, about, spark]              |<span class="number">5</span>     |</span><br><span class="line">|I wish Java could use case classes |[i, wish, java, could, use, case, classes]|<span class="number">7</span>     |</span><br><span class="line">|Logistic,regression,models,are,neat|[logistic,regression,models,are,neat]     |<span class="number">1</span>     |</span><br><span class="line">+-----------------------------------+------------------------------------------+------+</span><br><span class="line"></span><br><span class="line">+-----------------------------------+------------------------------------------+------+</span><br><span class="line">|sentence                           |words                                     |tokens|</span><br><span class="line">+-----------------------------------+------------------------------------------+------+</span><br><span class="line">|Hi I heard about Spark             |[hi, i, heard, about, spark]              |<span class="number">5</span>     |</span><br><span class="line">|I wish Java could use case classes |[i, wish, java, could, use, case, classes]|<span class="number">7</span>     |</span><br><span class="line">|Logistic,regression,models,are,neat|[logistic, regression, models, are, neat] |<span class="number">5</span>     |</span><br><span class="line">+-----------------------------------+------------------------------------------+------+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/tokenizer_example.py” in the Spark repo.</p><h3 id="StopWordsRemover"><a href="#StopWordsRemover" class="headerlink" title="StopWordsRemover"></a><strong>StopWordsRemover</strong></h3><p><a href="https://en.wikipedia.org/wiki/Stop_words" target="_blank" rel="noopener">Stop words</a>(停止词)是应该从输入中排除的词，通常是因为这些词经常出现而又不具有如此多的含义。</p><p>StopWordsRemover将一串字符串（例如一个Tokenizer的输出）作为输入，并从输入序列中删除所有的停止词。停用词表由stopWords参数指定。某些语言的默认停用词可通过调用访问StopWordsRemover.loadDefaultStopWords(language)，可用的选项有“danish”, “dutch”, “english”, “finnish”, “french”, “german”, “hungarian”, “italian”, “norwegian”, “portuguese”, “russian”, “spanish”, “swedish” and “turkish”。布尔参数caseSensitive指示匹配是否区分大小写（默认为false）。</p><ul><li>Examples</li></ul><p>假设我们有列如下数据帧,拥有列id和raw：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"> id | raw</span><br><span class="line">----|----------</span><br><span class="line"> <span class="number">0</span>  | [I, saw, the, red, baloon]</span><br><span class="line"> <span class="number">1</span>  | [Mary, had, a, little, lamb]</span><br></pre></td></tr></table></figure></p><p>应用StopWordsRemover与raw作为输入列，filtered作为输出列，我们应该得到以下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"> id | raw                         | filtered</span><br><span class="line">----|-----------------------------|--------------------</span><br><span class="line"> <span class="number">0</span>  | [I, saw, the, red, baloon]  |  [saw, red, baloon]</span><br><span class="line"> <span class="number">1</span>  | [Mary, had, a, little, lamb]|[Mary, little, lamb]</span><br></pre></td></tr></table></figure></p><p>在这里filtered，“I”，“the”，“had”和“a”这些停用词语已被滤除。\<br>有关API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.StopWordsRemover" target="_blank" rel="noopener">StopWordsRemover Python文档</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StopWordsRemover</span><br><span class="line"></span><br><span class="line">sentenceData = spark.createDataFrame([</span><br><span class="line">    (<span class="number">0</span>, [<span class="string">"I"</span>, <span class="string">"saw"</span>, <span class="string">"the"</span>, <span class="string">"red"</span>, <span class="string">"balloon"</span>]),</span><br><span class="line">    (<span class="number">1</span>, [<span class="string">"Mary"</span>, <span class="string">"had"</span>, <span class="string">"a"</span>, <span class="string">"little"</span>, <span class="string">"lamb"</span>])</span><br><span class="line">], [<span class="string">"id"</span>, <span class="string">"raw"</span>])</span><br><span class="line"></span><br><span class="line">remover = StopWordsRemover(inputCol=<span class="string">"raw"</span>, outputCol=<span class="string">"filtered"</span>)</span><br><span class="line">remover.transform(sentenceData).show(truncate=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/stopwords_remover_example.py” in the Spark repo.</p><h3 id="n-gram"><a href="#n-gram" class="headerlink" title="n-gram"></a><strong>n-gram</strong></h3><p>一个<a href="https://en.wikipedia.org/wiki/N-gram" target="_blank" rel="noopener">n-gram</a>是一个包含整数n个tokens（通常是单词）的序列。NGram类可用于输入特征转变成n-grams。</p><p>NGram将一串字符串（例如一个Tokenizer的输出）作为输入。参数n用于确定每个n-gram中的terms的数量。输出将由n-grams的序列组成，每个n-gram由空格分隔的n个连续的words的字符串表示。如果输入序列少于n，则没有输出。</p><ul><li>Examples</li></ul><p>有关API的更多细节，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.NGram" target="_blank" rel="noopener">NGram Python文档</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> NGram</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"n_gramExample"</span>).getOrCreate()</span><br><span class="line">wordDataFrame = spark.createDataFrame([</span><br><span class="line">    (<span class="number">0</span>, [<span class="string">"Hi"</span>, <span class="string">"I"</span>, <span class="string">"heard"</span>, <span class="string">"about"</span>, <span class="string">"Spark"</span>]),</span><br><span class="line">    (<span class="number">1</span>, [<span class="string">"I"</span>, <span class="string">"wish"</span>, <span class="string">"Java"</span>, <span class="string">"could"</span>, <span class="string">"use"</span>, <span class="string">"case"</span>, <span class="string">"classes"</span>]),</span><br><span class="line">    (<span class="number">2</span>, [<span class="string">"Logistic"</span>, <span class="string">"regression"</span>, <span class="string">"models"</span>, <span class="string">"are"</span>, <span class="string">"neat"</span>])</span><br><span class="line">], [<span class="string">"id"</span>, <span class="string">"words"</span>])</span><br><span class="line"></span><br><span class="line">ngram = NGram(n=<span class="number">2</span>, inputCol=<span class="string">"words"</span>, outputCol=<span class="string">"ngrams"</span>)</span><br><span class="line"></span><br><span class="line">ngramDataFrame = ngram.transform(wordDataFrame)</span><br><span class="line">ngramDataFrame.select(<span class="string">"ngrams"</span>).show(truncate=<span class="keyword">False</span>)</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+------------------------------------------------------------------+</span><br><span class="line">|ngrams                                                            |</span><br><span class="line">+------------------------------------------------------------------+</span><br><span class="line">|[Hi I, I heard, heard about, about Spark]                         |</span><br><span class="line">|[I wish, wish Java, Java could, could use, use case, case classes]|</span><br><span class="line">|[Logistic regression, regression models, models are, are neat]    |</span><br><span class="line">+------------------------------------------------------------------+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/n_gram_example.py” in the Spark repo.</p><h3 id="Binarizer"><a href="#Binarizer" class="headerlink" title="Binarizer"></a><strong>Binarizer</strong></h3><p><code>Binarization</code>(二值化)是将数字特征阈值化为二进制（0/1）特征的过程。</p><p>Binarizer需传入参数inputCol和outputCol，以及所述threshold参数来进行二值化。大于阈值的特征值被二进制化为1.0; 等于或小于阈值的值被二值化为0.0。inputCol支持Vector和Double类型。</p><ul><li>Examples</li></ul><p>有关API的更多细节，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.Binarizer" target="_blank" rel="noopener">Binarizer Python文档</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> Binarizer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession  </span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"BinarizerExample"</span>).getOrCreate()</span><br><span class="line">continuousDataFrame = spark.createDataFrame([</span><br><span class="line">    (<span class="number">0</span>, <span class="number">0.1</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="number">0.8</span>),</span><br><span class="line">    (<span class="number">2</span>, <span class="number">0.2</span>)</span><br><span class="line">], [<span class="string">"id"</span>, <span class="string">"feature"</span>])</span><br><span class="line"></span><br><span class="line">binarizer = Binarizer(threshold=<span class="number">0.5</span>, inputCol=<span class="string">"feature"</span>, outputCol=<span class="string">"binarized_feature"</span>)</span><br><span class="line"></span><br><span class="line">binarizedDataFrame = binarizer.transform(continuousDataFrame)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Binarizer output with Threshold = %f"</span> % binarizer.getThreshold())</span><br><span class="line">binarizedDataFrame.show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Binarizer output <span class="keyword">with</span> Threshold = <span class="number">0.500000</span></span><br><span class="line">+---+-------+-----------------+</span><br><span class="line">| id|feature|binarized_feature|</span><br><span class="line">+---+-------+-----------------+</span><br><span class="line">|  <span class="number">0</span>|    <span class="number">0.1</span>|              <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">1</span>|    <span class="number">0.8</span>|              <span class="number">1.0</span>|</span><br><span class="line">|  <span class="number">2</span>|    <span class="number">0.2</span>|              <span class="number">0.0</span>|</span><br><span class="line">+---+-------+-----------------+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/binarizer_example.py” in the Spark repo.</p><h3 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a><strong>PCA</strong></h3><p><a href="http://en.wikipedia.org/wiki/Principal_component_analysis" target="_blank" rel="noopener">PCA</a>是一个统计过程，它使用正交变换将一组可能相关的变量的观察值转换成一组称为主成分的线性不相关变量的值。一个PCA类使用PCA将向量映射到低维空间来训练一个模型。下面的例子显示了如何将五维特征向量投影到三维主成分中。</p><ul><li>Examples</li></ul><p>有关API的更多细节，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.PCA" target="_blank" rel="noopener">PCA Python文档</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession  </span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"PCA_Example"</span>).getOrCreate()</span><br><span class="line">data = [(Vectors.sparse(<span class="number">5</span>, [(<span class="number">1</span>, <span class="number">1.0</span>), (<span class="number">3</span>, <span class="number">7.0</span>)]),),</span><br><span class="line">        (Vectors.dense([<span class="number">2.0</span>, <span class="number">0.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>]),),</span><br><span class="line">        (Vectors.dense([<span class="number">4.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">6.0</span>, <span class="number">7.0</span>]),)]</span><br><span class="line">df = spark.createDataFrame(data, [<span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line">pca = PCA(k=<span class="number">3</span>, inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"pcaFeatures"</span>)</span><br><span class="line">model = pca.fit(df)</span><br><span class="line"></span><br><span class="line">result = model.transform(df).select(<span class="string">"pcaFeatures"</span>)</span><br><span class="line">result.show(truncate=<span class="keyword">False</span>)</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+-----------------------------------------------------------+</span><br><span class="line">|pcaFeatures                                                |</span><br><span class="line">+-----------------------------------------------------------+</span><br><span class="line">|[<span class="number">1.6485728230883807</span>,<span class="number">-4.013282700516296</span>,<span class="number">-5.524543751369388</span>] |</span><br><span class="line">|[<span class="number">-4.645104331781534</span>,<span class="number">-1.1167972663619026</span>,<span class="number">-5.524543751369387</span>]|</span><br><span class="line">|[<span class="number">-6.428880535676489</span>,<span class="number">-5.337951427775355</span>,<span class="number">-5.524543751369389</span>] |</span><br><span class="line">+-----------------------------------------------------------+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/pca_example.py” in the Spark repo.</p><h3 id="PolynomialExpansion"><a href="#PolynomialExpansion" class="headerlink" title="PolynomialExpansion"></a><strong>PolynomialExpansion</strong></h3><p><a href="http://en.wikipedia.org/wiki/Polynomial_expansion" target="_blank" rel="noopener">Polynomial expansion</a>(多项式展开)是将特征扩展到一个多项式空间的过程，这个多项式空间是由原始维度的n-degree组合形成的。一个<a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.feature.PolynomialExpansion" target="_blank" rel="noopener">PolynomialExpansion</a>类提供此功能。下面的例子展示了如何将特征扩展到一个三次多项式空间。</p><ul><li>Examples</li></ul><p>有关API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.PolynomialExpansion" target="_blank" rel="noopener">PolynomialExpansion Python文档</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> PolynomialExpansion</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"PolynormialExpansionExample"</span>).getOrCreate()</span><br><span class="line">df = spark.createDataFrame([</span><br><span class="line">    (Vectors.dense([<span class="number">2.0</span>, <span class="number">1.0</span>]),),</span><br><span class="line">    (Vectors.dense([<span class="number">0.0</span>, <span class="number">0.0</span>]),),</span><br><span class="line">    (Vectors.dense([<span class="number">3.0</span>, <span class="number">-1.0</span>]),)</span><br><span class="line">], [<span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line">polyExpansion = PolynomialExpansion(degree=<span class="number">3</span>, inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"polyFeatures"</span>)</span><br><span class="line">polyDF = polyExpansion.transform(df)</span><br><span class="line"></span><br><span class="line">polyDF.show(truncate=<span class="keyword">False</span>)</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+----------+------------------------------------------+</span><br><span class="line">|features  |polyFeatures                              |</span><br><span class="line">+----------+------------------------------------------+</span><br><span class="line">|[<span class="number">2.0</span>,<span class="number">1.0</span>] |[<span class="number">2.0</span>,<span class="number">4.0</span>,<span class="number">8.0</span>,<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">4.0</span>,<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">1.0</span>]     |</span><br><span class="line">|[<span class="number">0.0</span>,<span class="number">0.0</span>] |[<span class="number">0.0</span>,<span class="number">0.0</span>,<span class="number">0.0</span>,<span class="number">0.0</span>,<span class="number">0.0</span>,<span class="number">0.0</span>,<span class="number">0.0</span>,<span class="number">0.0</span>,<span class="number">0.0</span>]     |</span><br><span class="line">|[<span class="number">3.0</span>,<span class="number">-1.0</span>]|[<span class="number">3.0</span>,<span class="number">9.0</span>,<span class="number">27.0</span>,<span class="number">-1.0</span>,<span class="number">-3.0</span>,<span class="number">-9.0</span>,<span class="number">1.0</span>,<span class="number">3.0</span>,<span class="number">-1.0</span>]|</span><br><span class="line">+----------+------------------------------------------+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/polynomial_expansion_example.py” in the Spark repo.</p><h3 id="Discrete-Cosine-Transform-DCT"><a href="#Discrete-Cosine-Transform-DCT" class="headerlink" title="Discrete Cosine Transform(DCT)"></a><strong>Discrete Cosine Transform(DCT)</strong></h3><p><a href="https://en.wikipedia.org/wiki/Discrete_cosine_transform" target="_blank" rel="noopener">Discrete Cosine Transform</a>离散余弦变换将时域中的长度为N的实数序列转换为另一个频域中长度为N的实数序列。一个<a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.feature.DCT" target="_blank" rel="noopener">DCT</a>类提供此功能，实现 <a href="https://en.wikipedia.org/wiki/Discrete_cosine_transform#DCT-II" target="_blank" rel="noopener">DCT-II</a> 和通过缩放结果1/sqrt(2)倍使得变换的表示矩阵是单一的。被应用于变换的序列是无偏移的（例如变换的序列的第0th个元素是 第0th 个DCT系数而不是N/2个）。</p><ul><li>Examples</li></ul><p>有关API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.DCT" target="_blank" rel="noopener">DCT Python文档</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> DCT</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"DCT_Example"</span>).getOrCreate()</span><br><span class="line">df = spark.createDataFrame([</span><br><span class="line">    (Vectors.dense([<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">-2.0</span>, <span class="number">3.0</span>]),),</span><br><span class="line">    (Vectors.dense([<span class="number">-1.0</span>, <span class="number">2.0</span>, <span class="number">4.0</span>, <span class="number">-7.0</span>]),),</span><br><span class="line">    (Vectors.dense([<span class="number">14.0</span>, <span class="number">-2.0</span>, <span class="number">-5.0</span>, <span class="number">1.0</span>]),)], [<span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line">dct = DCT(inverse=<span class="keyword">False</span>, inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"featuresDCT"</span>)</span><br><span class="line"></span><br><span class="line">dctDf = dct.transform(df)</span><br><span class="line"></span><br><span class="line">dctDf.select(<span class="string">"featuresDCT"</span>).show(truncate=<span class="keyword">False</span>)</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+----------------------------------------------------------------+</span><br><span class="line">|featuresDCT                                                     |</span><br><span class="line">+----------------------------------------------------------------+</span><br><span class="line">|[<span class="number">1.0</span>,<span class="number">-1.1480502970952693</span>,<span class="number">2.0000000000000004</span>,<span class="number">-2.7716385975338604</span>]|</span><br><span class="line">|[<span class="number">-1.0</span>,<span class="number">3.378492794482933</span>,<span class="number">-7.000000000000001</span>,<span class="number">2.9301512653149677</span>]  |</span><br><span class="line">|[<span class="number">4.0</span>,<span class="number">9.304453421915744</span>,<span class="number">11.000000000000002</span>,<span class="number">1.5579302036357163</span>]   |</span><br><span class="line">+----------------------------------------------------------------+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/dct_example.py” in the Spark repo.</p><h3 id="StringIndexer"><a href="#StringIndexer" class="headerlink" title="StringIndexer"></a><strong>StringIndexer</strong></h3><p><code>StringIndexer</code>将一串字符串标签编码为标签索引。这些索引范围为[0, numLabels)按照标签频率排序，因此最频繁的标签获得索引0。对于unseen的标签如果用户选择保留它们，它们将被放在索引numLabels处。如果输入列是数字，我们将其转换为字符串值并将其索引。当下游管道组件（例如Estimator或 Transformer）使用此字符串索引标签时，必须将组件的输入列设置为此字符串索引列名称。在许多情况下，您可以使用setInputCol设置输入列</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StringIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession  </span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"StringIndexerExample"</span>).getOrCreate()</span><br><span class="line">df = spark.createDataFrame(</span><br><span class="line">    [(<span class="number">0</span>, <span class="string">"a"</span>), (<span class="number">1</span>, <span class="string">"b"</span>), (<span class="number">2</span>, <span class="string">"c"</span>), (<span class="number">3</span>, <span class="string">"a"</span>), (<span class="number">4</span>, <span class="string">"a"</span>), (<span class="number">5</span>, <span class="string">"c"</span>)],</span><br><span class="line">    [<span class="string">"id"</span>, <span class="string">"category"</span>])</span><br><span class="line"></span><br><span class="line">indexer = StringIndexer(inputCol=<span class="string">"category"</span>, outputCol=<span class="string">"categoryIndex"</span>)</span><br><span class="line">indexed = indexer.fit(df).transform(df)</span><br><span class="line">indexed.show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+---+--------+-------------+</span><br><span class="line">| id|category|categoryIndex|</span><br><span class="line">+---+--------+-------------+</span><br><span class="line">|  <span class="number">0</span>|       a|          <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">1</span>|       b|          <span class="number">2.0</span>|</span><br><span class="line">|  <span class="number">2</span>|       c|          <span class="number">1.0</span>|</span><br><span class="line">|  <span class="number">3</span>|       a|          <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">4</span>|       a|          <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">5</span>|       c|          <span class="number">1.0</span>|</span><br><span class="line">+---+--------+-------------+</span><br></pre></td></tr></table></figure></p><p>此外，StringIndexer处理看不见的标签还有三个策略：</p><ol><li>抛出一个异常(默认的)</li><li>完全跳过unseen标签的行</li><li>把一个unseen的标签放在一个特殊的额外桶里，在索引numLabels处</li></ol><p>让我们回到之前的例子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"> id | category</span><br><span class="line">----|----------</span><br><span class="line"> <span class="number">0</span>  | a</span><br><span class="line"> <span class="number">1</span>  | b</span><br><span class="line"> <span class="number">2</span>  | c</span><br><span class="line"> <span class="number">3</span>  | d</span><br><span class="line"> <span class="number">4</span>  | e</span><br></pre></td></tr></table></figure></p><p>如果你没有设置如何StringIndexer处理看不见的标签或将其设置为“错误”，则会抛出异常。但是，如果您已经调用setHandleInvalid(“skip”)，则会生成以下数据集：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"> id | category | categoryIndex</span><br><span class="line">----|----------|---------------</span><br><span class="line"> <span class="number">0</span>  | a        | <span class="number">0.0</span></span><br><span class="line"> <span class="number">1</span>  | b        | <span class="number">2.0</span></span><br><span class="line"> <span class="number">2</span>  | c        | <span class="number">1.0</span></span><br></pre></td></tr></table></figure></p><p>请注意，包含“d”或“e”的行不显示。</p><p>如果你调用setHandleInvalid(“keep”)，将生成以下数据集：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"> id | category | categoryIndex</span><br><span class="line">----|----------|---------------</span><br><span class="line"> <span class="number">0</span>  | a        | <span class="number">0.0</span></span><br><span class="line"> <span class="number">1</span>  | b        | <span class="number">2.0</span></span><br><span class="line"> <span class="number">2</span>  | c        | <span class="number">1.0</span></span><br><span class="line"> <span class="number">3</span>  | d        | <span class="number">3.0</span></span><br><span class="line"> <span class="number">4</span>  | e        | <span class="number">3.0</span></span><br><span class="line"> <span class="comment"># d,e 所在的被映射到索引“3.0”</span></span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/string_indexer_example.py” in the Spark repo.</p><h3 id="IndexToString"><a href="#IndexToString" class="headerlink" title="IndexToString"></a><strong>IndexToString</strong></h3><p>对应于StringIndexer，IndexToString将一列标签索引映射回包含作为字符串的原始标签的列。一个常见的用例是从StringIndexer标签生成索引，用这些索引对模型进行训练，并从预测IndexToString索引列中检索原始标签。然而，你也可以提供自己的标签。</p><ul><li>Examples</li></ul><p>构造tringIndexer例子，假设我们有一个如下的数据帧，其有id和categoryIndex列：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"> id | categoryIndex</span><br><span class="line">----|---------------</span><br><span class="line"> <span class="number">0</span>  | <span class="number">0.0</span></span><br><span class="line"> <span class="number">1</span>  | <span class="number">2.0</span></span><br><span class="line"> <span class="number">2</span>  | <span class="number">1.0</span></span><br><span class="line"> <span class="number">3</span>  | <span class="number">0.0</span></span><br><span class="line"> <span class="number">4</span>  | <span class="number">0.0</span></span><br><span class="line"> <span class="number">5</span>  | <span class="number">1.0</span></span><br></pre></td></tr></table></figure></p><p>将categoryIndex作为输入列，应用IndexToString， originalCategory作为输出列，我们能够检索我们的原始标签（他们将从列的元数据推断）：</p><p>有关API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.IndexToString" target="_blank" rel="noopener">IndexToString Python文档</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> IndexToString, StringIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession  </span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"IndexToStringExample"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">df = spark.createDataFrame(</span><br><span class="line">    [(<span class="number">0</span>, <span class="string">"a"</span>), (<span class="number">1</span>, <span class="string">"b"</span>), (<span class="number">2</span>, <span class="string">"c"</span>), (<span class="number">3</span>, <span class="string">"a"</span>), (<span class="number">4</span>, <span class="string">"a"</span>), (<span class="number">5</span>, <span class="string">"c"</span>)],</span><br><span class="line">    [<span class="string">"id"</span>, <span class="string">"category"</span>])</span><br><span class="line"></span><br><span class="line">indexer = StringIndexer(inputCol=<span class="string">"category"</span>, outputCol=<span class="string">"categoryIndex"</span>)</span><br><span class="line">model = indexer.fit(df)</span><br><span class="line">indexed = model.transform(df)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Transformed string column '%s' to indexed column '%s'"</span></span><br><span class="line">      % (indexer.getInputCol(), indexer.getOutputCol()))</span><br><span class="line">indexed.show()</span><br><span class="line"></span><br><span class="line">print(<span class="string">"StringIndexer will store labels in output column metadata\n"</span>)</span><br><span class="line"></span><br><span class="line">converter = IndexToString(inputCol=<span class="string">"categoryIndex"</span>, outputCol=<span class="string">"originalCategory"</span>)</span><br><span class="line">converted = converter.transform(indexed)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Transformed indexed column '%s' back to original string column '%s' using "</span></span><br><span class="line">      <span class="string">"labels in metadata"</span> % (converter.getInputCol(), converter.getOutputCol()))</span><br><span class="line">converted.select(<span class="string">"id"</span>, <span class="string">"categoryIndex"</span>, <span class="string">"originalCategory"</span>).show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Transformed string column <span class="string">'category'</span> to indexed column <span class="string">'categoryIndex'</span></span><br><span class="line">+---+--------+-------------+</span><br><span class="line">| id|category|categoryIndex|</span><br><span class="line">+---+--------+-------------+</span><br><span class="line">|  <span class="number">0</span>|       a|          <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">1</span>|       b|          <span class="number">2.0</span>|</span><br><span class="line">|  <span class="number">2</span>|       c|          <span class="number">1.0</span>|</span><br><span class="line">|  <span class="number">3</span>|       a|          <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">4</span>|       a|          <span class="number">0.0</span>|</span><br><span class="line">|  <span class="number">5</span>|       c|          <span class="number">1.0</span>|</span><br><span class="line">+---+--------+-------------+</span><br><span class="line"></span><br><span class="line">StringIndexer will store labels <span class="keyword">in</span> output column metadata</span><br><span class="line"></span><br><span class="line">Transformed indexed column <span class="string">'categoryIndex'</span> back to original string column <span class="string">'originalCategory'</span> using labels <span class="keyword">in</span> metadata</span><br><span class="line">+---+-------------+----------------+</span><br><span class="line">| id|categoryIndex|originalCategory|</span><br><span class="line">+---+-------------+----------------+</span><br><span class="line">|  <span class="number">0</span>|          <span class="number">0.0</span>|               a|</span><br><span class="line">|  <span class="number">1</span>|          <span class="number">2.0</span>|               b|</span><br><span class="line">|  <span class="number">2</span>|          <span class="number">1.0</span>|               c|</span><br><span class="line">|  <span class="number">3</span>|          <span class="number">0.0</span>|               a|</span><br><span class="line">|  <span class="number">4</span>|          <span class="number">0.0</span>|               a|</span><br><span class="line">|  <span class="number">5</span>|          <span class="number">1.0</span>|               c|</span><br><span class="line">+---+-------------+----------------+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/index_to_string_example.py” in the Spark repo.</p><h3 id="OneHotEncoding"><a href="#OneHotEncoding" class="headerlink" title="OneHotEncoding"></a><strong>OneHotEncoding</strong></h3><p><a href="http://en.wikipedia.org/wiki/One-hot" target="_blank" rel="noopener">One-hot encoding</a>将一列标签索引映射到一列二进制向量，其中最多只有一个one-value。该编码允许那些期望使用连续特征的算法（例如Logistic回归）使用分类特征。</p><ul><li>Examples</li></ul><p>关于 API的更多细节请参考<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.OneHotEncoder" target="_blank" rel="noopener">OneHotEncoder Python文档</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> OneHotEncoder, StringIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession  </span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"OneHotEncoderExample"</span>).getOrCreate()</span><br><span class="line">df = spark.createDataFrame([</span><br><span class="line">    (<span class="number">0</span>, <span class="string">"a"</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="string">"b"</span>),</span><br><span class="line">    (<span class="number">2</span>, <span class="string">"c"</span>),</span><br><span class="line">    (<span class="number">3</span>, <span class="string">"a"</span>),</span><br><span class="line">    (<span class="number">4</span>, <span class="string">"a"</span>),</span><br><span class="line">    (<span class="number">5</span>, <span class="string">"c"</span>)</span><br><span class="line">], [<span class="string">"id"</span>, <span class="string">"category"</span>])</span><br><span class="line"></span><br><span class="line">stringIndexer = StringIndexer(inputCol=<span class="string">"category"</span>, outputCol=<span class="string">"categoryIndex"</span>)</span><br><span class="line">model = stringIndexer.fit(df)</span><br><span class="line">indexed = model.transform(df)</span><br><span class="line"></span><br><span class="line">encoder = OneHotEncoder(inputCol=<span class="string">"categoryIndex"</span>, outputCol=<span class="string">"categoryVec"</span>)</span><br><span class="line">encoded = encoder.transform(indexed)</span><br><span class="line">encoded.show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+---+--------+-------------+-------------+</span><br><span class="line">| id|category|categoryIndex|  categoryVec|</span><br><span class="line">+---+--------+-------------+-------------+</span><br><span class="line">|  <span class="number">0</span>|       a|          <span class="number">0.0</span>|(<span class="number">2</span>,[<span class="number">0</span>],[<span class="number">1.0</span>])|</span><br><span class="line">|  <span class="number">1</span>|       b|          <span class="number">2.0</span>|    (<span class="number">2</span>,[],[])|</span><br><span class="line">|  <span class="number">2</span>|       c|          <span class="number">1.0</span>|(<span class="number">2</span>,[<span class="number">1</span>],[<span class="number">1.0</span>])|</span><br><span class="line">|  <span class="number">3</span>|       a|          <span class="number">0.0</span>|(<span class="number">2</span>,[<span class="number">0</span>],[<span class="number">1.0</span>])|</span><br><span class="line">|  <span class="number">4</span>|       a|          <span class="number">0.0</span>|(<span class="number">2</span>,[<span class="number">0</span>],[<span class="number">1.0</span>])|</span><br><span class="line">|  <span class="number">5</span>|       c|          <span class="number">1.0</span>|(<span class="number">2</span>,[<span class="number">1</span>],[<span class="number">1.0</span>])|</span><br><span class="line">+---+--------+-------------+-------------+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/onehot_encoder_example.py” in the Spark repo.</p><h3 id="VectorIndexer"><a href="#VectorIndexer" class="headerlink" title="VectorIndexer"></a><strong>VectorIndexer</strong></h3><p>VectorIndexer有助于索引Vectors的数据集中的分类特征。它可以自动决定哪些特征是分类的，并将原始值转换为分类索引。具体来说，它做了以下几点：</p><ol><li>取一个<a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.linalg.Vector" target="_blank" rel="noopener">Vector</a>类型的输入列和一个参数maxCategories。</li><li>根据不同值的数量确定哪些特征应该分类，这些特征最多被分为maxCategories类。</li><li>计算每个分类特征的分类索引(0-based)。</li><li>索引分类特征并将原始特征值转换为索引。</li></ol><p>索引分类特征允许Decision Trees(决策树)和Tree Ensembles等算法适当地处理分类特征，提高性能。</p><ul><li>Examples<br>在下面的例子中，我们读入一个标记点​​的数据集，然后用VectorIndexer来决定哪些特征应该被视为分类特征。我们将分类特征值转换为它们的索引。这个转换的数据然后可以被传递给诸如DecisionTreeRegressor处理分类特征的算法。</li></ul><p>请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.VectorIndexer" target="_blank" rel="noopener">VectorIndexer Python文档</a> 以获取有关API的更多详细信息。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorIndexer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession  </span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"VectorIndexerExample"</span>).getOrCreate()</span><br><span class="line">data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"data/mllib/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">indexer = VectorIndexer(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"indexed"</span>, maxCategories=<span class="number">10</span>)</span><br><span class="line">indexerModel = indexer.fit(data)</span><br><span class="line"></span><br><span class="line">categoricalFeatures = indexerModel.categoryMaps</span><br><span class="line">print(<span class="string">"Chose %d categorical features: %s"</span> %</span><br><span class="line">      (len(categoricalFeatures), <span class="string">", "</span>.join(str(k) <span class="keyword">for</span> k <span class="keyword">in</span> categoricalFeatures.keys())))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create new column "indexed" with categorical values transformed to indices</span></span><br><span class="line">indexedData = indexerModel.transform(data)</span><br><span class="line">indexedData.show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Chose <span class="number">351</span> categorical features: <span class="number">645</span>, <span class="number">69</span>, <span class="number">365</span>, <span class="number">138</span>, <span class="number">101</span>, <span class="number">479</span>, <span class="number">333</span>, <span class="number">249</span>, <span class="number">0</span>, <span class="number">555</span>, <span class="number">666</span>, <span class="number">88</span>, <span class="number">170</span>, <span class="number">115</span>, <span class="number">276</span>, <span class="number">308</span>, <span class="number">5</span>, <span class="number">449</span>, <span class="number">120</span>, <span class="number">247</span>, <span class="number">614</span>, <span class="number">677</span>, <span class="number">202</span>, <span class="number">10</span>, <span class="number">56</span>, <span class="number">533</span>, <span class="number">142</span>, <span class="number">500</span>, <span class="number">340</span>, <span class="number">670</span>, <span class="number">174</span>, <span class="number">42</span>, <span class="number">417</span>, <span class="number">24</span>, <span class="number">37</span>, <span class="number">25</span>, <span class="number">257</span>, <span class="number">389</span>, <span class="number">52</span>, <span class="number">14</span>, <span class="number">504</span>, <span class="number">110</span>, <span class="number">587</span>, <span class="number">619</span>, <span class="number">196</span>, <span class="number">559</span>, <span class="number">638</span>, <span class="number">20</span>, <span class="number">421</span>, <span class="number">46</span>, <span class="number">93</span>, <span class="number">284</span>, <span class="number">228</span>, <span class="number">448</span>, <span class="number">57</span>, <span class="number">78</span>, <span class="number">29</span>, <span class="number">475</span>, <span class="number">164</span>, <span class="number">591</span>, <span class="number">646</span>, <span class="number">253</span>, <span class="number">106</span>, <span class="number">121</span>, <span class="number">84</span>, <span class="number">480</span>, <span class="number">147</span>, <span class="number">280</span>, <span class="number">61</span>, <span class="number">221</span>, <span class="number">396</span>, <span class="number">89</span>, <span class="number">133</span>, <span class="number">116</span>, <span class="number">1</span>, <span class="number">507</span>, <span class="number">312</span>, <span class="number">74</span>, <span class="number">307</span>, <span class="number">452</span>, <span class="number">6</span>, <span class="number">248</span>, <span class="number">60</span>, <span class="number">117</span>, <span class="number">678</span>, <span class="number">529</span>, <span class="number">85</span>, <span class="number">201</span>, <span class="number">220</span>, <span class="number">366</span>, <span class="number">534</span>, <span class="number">102</span>, <span class="number">334</span>, <span class="number">28</span>, <span class="number">38</span>, <span class="number">561</span>, <span class="number">392</span>, <span class="number">70</span>, <span class="number">424</span>, <span class="number">192</span>, <span class="number">21</span>, <span class="number">137</span>, <span class="number">165</span>, <span class="number">33</span>, <span class="number">92</span>, <span class="number">229</span>, <span class="number">252</span>, <span class="number">197</span>, <span class="number">361</span>, <span class="number">65</span>, <span class="number">97</span>, <span class="number">665</span>, <span class="number">583</span>, <span class="number">285</span>, <span class="number">224</span>, <span class="number">650</span>, <span class="number">615</span>, <span class="number">9</span>, <span class="number">53</span>, <span class="number">169</span>, <span class="number">593</span>, <span class="number">141</span>, <span class="number">610</span>, <span class="number">420</span>, <span class="number">109</span>, <span class="number">256</span>, <span class="number">225</span>, <span class="number">339</span>, <span class="number">77</span>, <span class="number">193</span>, <span class="number">669</span>, <span class="number">476</span>, <span class="number">642</span>, <span class="number">637</span>, <span class="number">590</span>, <span class="number">679</span>, <span class="number">96</span>, <span class="number">393</span>, <span class="number">647</span>, <span class="number">173</span>, <span class="number">13</span>, <span class="number">41</span>, <span class="number">503</span>, <span class="number">134</span>, <span class="number">73</span>, <span class="number">105</span>, <span class="number">2</span>, <span class="number">508</span>, <span class="number">311</span>, <span class="number">558</span>, <span class="number">674</span>, <span class="number">530</span>, <span class="number">586</span>, <span class="number">618</span>, <span class="number">166</span>, <span class="number">32</span>, <span class="number">34</span>, <span class="number">148</span>, <span class="number">45</span>, <span class="number">161</span>, <span class="number">279</span>, <span class="number">64</span>, <span class="number">689</span>, <span class="number">17</span>, <span class="number">149</span>, <span class="number">584</span>, <span class="number">562</span>, <span class="number">176</span>, <span class="number">423</span>, <span class="number">191</span>, <span class="number">22</span>, <span class="number">44</span>, <span class="number">59</span>, <span class="number">118</span>, <span class="number">281</span>, <span class="number">27</span>, <span class="number">641</span>, <span class="number">71</span>, <span class="number">391</span>, <span class="number">12</span>, <span class="number">445</span>, <span class="number">54</span>, <span class="number">313</span>, <span class="number">611</span>, <span class="number">144</span>, <span class="number">49</span>, <span class="number">335</span>, <span class="number">86</span>, <span class="number">672</span>, <span class="number">172</span>, <span class="number">113</span>, <span class="number">681</span>, <span class="number">219</span>, <span class="number">419</span>, <span class="number">81</span>, <span class="number">230</span>, <span class="number">362</span>, <span class="number">451</span>, <span class="number">76</span>, <span class="number">7</span>, <span class="number">39</span>, <span class="number">649</span>, <span class="number">98</span>, <span class="number">616</span>, <span class="number">477</span>, <span class="number">367</span>, <span class="number">535</span>, <span class="number">103</span>, <span class="number">140</span>, <span class="number">621</span>, <span class="number">91</span>, <span class="number">66</span>, <span class="number">251</span>, <span class="number">668</span>, <span class="number">198</span>, <span class="number">108</span>, <span class="number">278</span>, <span class="number">223</span>, <span class="number">394</span>, <span class="number">306</span>, <span class="number">135</span>, <span class="number">563</span>, <span class="number">226</span>, <span class="number">3</span>, <span class="number">505</span>, <span class="number">80</span>, <span class="number">167</span>, <span class="number">35</span>, <span class="number">473</span>, <span class="number">675</span>, <span class="number">589</span>, <span class="number">162</span>, <span class="number">531</span>, <span class="number">680</span>, <span class="number">255</span>, <span class="number">648</span>, <span class="number">112</span>, <span class="number">617</span>, <span class="number">194</span>, <span class="number">145</span>, <span class="number">48</span>, <span class="number">557</span>, <span class="number">690</span>, <span class="number">63</span>, <span class="number">640</span>, <span class="number">18</span>, <span class="number">282</span>, <span class="number">95</span>, <span class="number">310</span>, <span class="number">50</span>, <span class="number">67</span>, <span class="number">199</span>, <span class="number">673</span>, <span class="number">16</span>, <span class="number">585</span>, <span class="number">502</span>, <span class="number">338</span>, <span class="number">643</span>, <span class="number">31</span>, <span class="number">336</span>, <span class="number">613</span>, <span class="number">11</span>, <span class="number">72</span>, <span class="number">175</span>, <span class="number">446</span>, <span class="number">612</span>, <span class="number">143</span>, <span class="number">43</span>, <span class="number">250</span>, <span class="number">231</span>, <span class="number">450</span>, <span class="number">99</span>, <span class="number">363</span>, <span class="number">556</span>, <span class="number">87</span>, <span class="number">203</span>, <span class="number">671</span>, <span class="number">688</span>, <span class="number">104</span>, <span class="number">368</span>, <span class="number">588</span>, <span class="number">40</span>, <span class="number">304</span>, <span class="number">26</span>, <span class="number">258</span>, <span class="number">390</span>, <span class="number">55</span>, <span class="number">114</span>, <span class="number">171</span>, <span class="number">139</span>, <span class="number">418</span>, <span class="number">23</span>, <span class="number">8</span>, <span class="number">75</span>, <span class="number">119</span>, <span class="number">58</span>, <span class="number">667</span>, <span class="number">478</span>, <span class="number">536</span>, <span class="number">82</span>, <span class="number">620</span>, <span class="number">447</span>, <span class="number">36</span>, <span class="number">168</span>, <span class="number">146</span>, <span class="number">30</span>, <span class="number">51</span>, <span class="number">190</span>, <span class="number">19</span>, <span class="number">422</span>, <span class="number">564</span>, <span class="number">305</span>, <span class="number">107</span>, <span class="number">4</span>, <span class="number">136</span>, <span class="number">506</span>, <span class="number">79</span>, <span class="number">195</span>, <span class="number">474</span>, <span class="number">664</span>, <span class="number">532</span>, <span class="number">94</span>, <span class="number">283</span>, <span class="number">395</span>, <span class="number">332</span>, <span class="number">528</span>, <span class="number">644</span>, <span class="number">47</span>, <span class="number">15</span>, <span class="number">163</span>, <span class="number">200</span>, <span class="number">68</span>, <span class="number">62</span>, <span class="number">277</span>, <span class="number">691</span>, <span class="number">501</span>, <span class="number">90</span>, <span class="number">111</span>, <span class="number">254</span>, <span class="number">227</span>, <span class="number">337</span>, <span class="number">122</span>, <span class="number">83</span>, <span class="number">309</span>, <span class="number">560</span>, <span class="number">639</span>, <span class="number">676</span>, <span class="number">222</span>, <span class="number">592</span>, <span class="number">364</span>, <span class="number">100</span></span><br><span class="line">+-----+--------------------+--------------------+</span><br><span class="line">|label|            features|             indexed|</span><br><span class="line">+-----+--------------------+--------------------+</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">127</span>,<span class="number">128</span>,<span class="number">129.</span>..|(<span class="number">692</span>,[<span class="number">127</span>,<span class="number">128</span>,<span class="number">129.</span>..|</span><br><span class="line">|  <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">158</span>,<span class="number">159</span>,<span class="number">160.</span>..|(<span class="number">692</span>,[<span class="number">158</span>,<span class="number">159</span>,<span class="number">160.</span>..|</span><br><span class="line">|  <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">124</span>,<span class="number">125</span>,<span class="number">126.</span>..|(<span class="number">692</span>,[<span class="number">124</span>,<span class="number">125</span>,<span class="number">126.</span>..|</span><br><span class="line">|  <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">152</span>,<span class="number">153</span>,<span class="number">154.</span>..|(<span class="number">692</span>,[<span class="number">152</span>,<span class="number">153</span>,<span class="number">154.</span>..|</span><br><span class="line">|  <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">151</span>,<span class="number">152</span>,<span class="number">153.</span>..|(<span class="number">692</span>,[<span class="number">151</span>,<span class="number">152</span>,<span class="number">153.</span>..|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">129</span>,<span class="number">130</span>,<span class="number">131.</span>..|(<span class="number">692</span>,[<span class="number">129</span>,<span class="number">130</span>,<span class="number">131.</span>..|</span><br><span class="line">|  <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">158</span>,<span class="number">159</span>,<span class="number">160.</span>..|(<span class="number">692</span>,[<span class="number">158</span>,<span class="number">159</span>,<span class="number">160.</span>..|</span><br><span class="line">|  <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">99</span>,<span class="number">100</span>,<span class="number">101</span>,...|(<span class="number">692</span>,[<span class="number">99</span>,<span class="number">100</span>,<span class="number">101</span>,...|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">154</span>,<span class="number">155</span>,<span class="number">156.</span>..|(<span class="number">692</span>,[<span class="number">154</span>,<span class="number">155</span>,<span class="number">156.</span>..|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">127</span>,<span class="number">128</span>,<span class="number">129.</span>..|(<span class="number">692</span>,[<span class="number">127</span>,<span class="number">128</span>,<span class="number">129.</span>..|</span><br><span class="line">|  <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">154</span>,<span class="number">155</span>,<span class="number">156.</span>..|(<span class="number">692</span>,[<span class="number">154</span>,<span class="number">155</span>,<span class="number">156.</span>..|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">153</span>,<span class="number">154</span>,<span class="number">155.</span>..|(<span class="number">692</span>,[<span class="number">153</span>,<span class="number">154</span>,<span class="number">155.</span>..|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">151</span>,<span class="number">152</span>,<span class="number">153.</span>..|(<span class="number">692</span>,[<span class="number">151</span>,<span class="number">152</span>,<span class="number">153.</span>..|</span><br><span class="line">|  <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">129</span>,<span class="number">130</span>,<span class="number">131.</span>..|(<span class="number">692</span>,[<span class="number">129</span>,<span class="number">130</span>,<span class="number">131.</span>..|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">154</span>,<span class="number">155</span>,<span class="number">156.</span>..|(<span class="number">692</span>,[<span class="number">154</span>,<span class="number">155</span>,<span class="number">156.</span>..|</span><br><span class="line">|  <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">150</span>,<span class="number">151</span>,<span class="number">152.</span>..|(<span class="number">692</span>,[<span class="number">150</span>,<span class="number">151</span>,<span class="number">152.</span>..|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">124</span>,<span class="number">125</span>,<span class="number">126.</span>..|(<span class="number">692</span>,[<span class="number">124</span>,<span class="number">125</span>,<span class="number">126.</span>..|</span><br><span class="line">|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">152</span>,<span class="number">153</span>,<span class="number">154.</span>..|(<span class="number">692</span>,[<span class="number">152</span>,<span class="number">153</span>,<span class="number">154.</span>..|</span><br><span class="line">|  <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">97</span>,<span class="number">98</span>,<span class="number">99</span>,<span class="number">12.</span>..|(<span class="number">692</span>,[<span class="number">97</span>,<span class="number">98</span>,<span class="number">99</span>,<span class="number">12.</span>..|</span><br><span class="line">|  <span class="number">1.0</span>|(<span class="number">692</span>,[<span class="number">124</span>,<span class="number">125</span>,<span class="number">126.</span>..|(<span class="number">692</span>,[<span class="number">124</span>,<span class="number">125</span>,<span class="number">126.</span>..|</span><br><span class="line">+-----+--------------------+--------------------+</span><br><span class="line">only showing top <span class="number">20</span> rows</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/vector_indexer_example.py” in the Spark repo.</p><h3 id="Interaction"><a href="#Interaction" class="headerlink" title="Interaction"></a><strong>Interaction</strong></h3><p><code>Interaction</code>是一个Transformer,采用向量或双值列的方法生成一个单一的向量列，其中包含每个输入列的一个值的所有组合的乘积。</p><p>例如，如果您有两个向量类型列，每个列都有三个维度作为输入列，那么您将获得一个9维向量作为输出列。</p><ul><li>Examples</li></ul><p>假设我们有以下DataFrame,有列“id1”，“vec1”和“vec2”：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">id1|vec1          |vec2</span><br><span class="line">---|--------------|--------------</span><br><span class="line"><span class="number">1</span>  |[<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>] |[<span class="number">8.0</span>,<span class="number">4.0</span>,<span class="number">5.0</span>]</span><br><span class="line"><span class="number">2</span>  |[<span class="number">4.0</span>,<span class="number">3.0</span>,<span class="number">8.0</span>] |[<span class="number">7.0</span>,<span class="number">9.0</span>,<span class="number">8.0</span>]</span><br><span class="line"><span class="number">3</span>  |[<span class="number">6.0</span>,<span class="number">1.0</span>,<span class="number">9.0</span>] |[<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">6.0</span>]</span><br><span class="line"><span class="number">4</span>  |[<span class="number">10.0</span>,<span class="number">8.0</span>,<span class="number">6.0</span>]|[<span class="number">9.0</span>,<span class="number">4.0</span>,<span class="number">5.0</span>]</span><br><span class="line"><span class="number">5</span>  |[<span class="number">9.0</span>,<span class="number">2.0</span>,<span class="number">7.0</span>] |[<span class="number">10.0</span>,<span class="number">7.0</span>,<span class="number">3.0</span>]</span><br><span class="line"><span class="number">6</span>  |[<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">4.0</span>] |[<span class="number">2.0</span>,<span class="number">8.0</span>,<span class="number">4.0</span>]</span><br></pre></td></tr></table></figure></p><p>应用Interaction作用于这些输入列，然后interactedCol输出列包含：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">id1|vec1          |vec2          |interactedCol</span><br><span class="line">---|--------------|--------------|------------------------------------------------------</span><br><span class="line"><span class="number">1</span>  |[<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>] |[<span class="number">8.0</span>,<span class="number">4.0</span>,<span class="number">5.0</span>] |[<span class="number">8.0</span>,<span class="number">4.0</span>,<span class="number">5.0</span>,<span class="number">16.0</span>,<span class="number">8.0</span>,<span class="number">10.0</span>,<span class="number">24.0</span>,<span class="number">12.0</span>,<span class="number">15.0</span>]</span><br><span class="line"><span class="number">2</span>  |[<span class="number">4.0</span>,<span class="number">3.0</span>,<span class="number">8.0</span>] |[<span class="number">7.0</span>,<span class="number">9.0</span>,<span class="number">8.0</span>] |[<span class="number">56.0</span>,<span class="number">72.0</span>,<span class="number">64.0</span>,<span class="number">42.0</span>,<span class="number">54.0</span>,<span class="number">48.0</span>,<span class="number">112.0</span>,<span class="number">144.0</span>,<span class="number">128.0</span>]</span><br><span class="line"><span class="number">3</span>  |[<span class="number">6.0</span>,<span class="number">1.0</span>,<span class="number">9.0</span>] |[<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">6.0</span>] |[<span class="number">36.0</span>,<span class="number">54.0</span>,<span class="number">108.0</span>,<span class="number">6.0</span>,<span class="number">9.0</span>,<span class="number">18.0</span>,<span class="number">54.0</span>,<span class="number">81.0</span>,<span class="number">162.0</span>]</span><br><span class="line"><span class="number">4</span>  |[<span class="number">10.0</span>,<span class="number">8.0</span>,<span class="number">6.0</span>]|[<span class="number">9.0</span>,<span class="number">4.0</span>,<span class="number">5.0</span>] |[<span class="number">360.0</span>,<span class="number">160.0</span>,<span class="number">200.0</span>,<span class="number">288.0</span>,<span class="number">128.0</span>,<span class="number">160.0</span>,<span class="number">216.0</span>,<span class="number">96.0</span>,<span class="number">120.0</span>]</span><br><span class="line"><span class="number">5</span>  |[<span class="number">9.0</span>,<span class="number">2.0</span>,<span class="number">7.0</span>] |[<span class="number">10.0</span>,<span class="number">7.0</span>,<span class="number">3.0</span>]|[<span class="number">450.0</span>,<span class="number">315.0</span>,<span class="number">135.0</span>,<span class="number">100.0</span>,<span class="number">70.0</span>,<span class="number">30.0</span>,<span class="number">350.0</span>,<span class="number">245.0</span>,<span class="number">105.0</span>]</span><br><span class="line"><span class="number">6</span>  |[<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">4.0</span>] |[<span class="number">2.0</span>,<span class="number">8.0</span>,<span class="number">4.0</span>] |[<span class="number">12.0</span>,<span class="number">48.0</span>,<span class="number">24.0</span>,<span class="number">12.0</span>,<span class="number">48.0</span>,<span class="number">24.0</span>,<span class="number">48.0</span>,<span class="number">192.0</span>,<span class="number">96.0</span>]</span><br></pre></td></tr></table></figure></p><p>注：该方法暂时并没有python的实现，有scala和Java的</p><h3 id="Normalizer"><a href="#Normalizer" class="headerlink" title="Normalizer"></a><strong>Normalizer</strong></h3><p><code>Normalizer</code>是一个Transformer，它转换数据集的Vector行，规范化每个Vector为unit norm。它采用参数p来规范化，它指定用于规范化的p范数。（默认p = 2 ）。这种规范化可以帮助标准化您的输入数据，并改善学习算法的行为。</p><ul><li>Examples</li></ul><p>以下示例演示如何以libsvm格式加载数据集，然后将每行标准化为unit L^1 norm1和unitL^∞ norm。</p><p>有关API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.Normalizer" target="_blank" rel="noopener">Normalizer Python文档</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> Normalizer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession  </span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"NormalizerExample"</span>).getOrCreate()</span><br><span class="line">dataFrame = spark.createDataFrame([</span><br><span class="line">    (<span class="number">0</span>, Vectors.dense([<span class="number">1.0</span>, <span class="number">0.5</span>, <span class="number">-1.0</span>]),),</span><br><span class="line">    (<span class="number">1</span>, Vectors.dense([<span class="number">2.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>]),),</span><br><span class="line">    (<span class="number">2</span>, Vectors.dense([<span class="number">4.0</span>, <span class="number">10.0</span>, <span class="number">2.0</span>]),)</span><br><span class="line">], [<span class="string">"id"</span>, <span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Normalize each Vector using $L^1$ norm.</span></span><br><span class="line">normalizer = Normalizer(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"normFeatures"</span>, p=<span class="number">1.0</span>)</span><br><span class="line">l1NormData = normalizer.transform(dataFrame)</span><br><span class="line">print(<span class="string">"Normalized using L^1 norm"</span>)</span><br><span class="line">l1NormData.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Normalize each Vector using $L^\infty$ norm.</span></span><br><span class="line">lInfNormData = normalizer.transform(dataFrame, &#123;normalizer.p: float(<span class="string">"inf"</span>)&#125;)</span><br><span class="line">print(<span class="string">"Normalized using L^inf norm"</span>)</span><br><span class="line">lInfNormData.show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Normalized using L^<span class="number">1</span> norm</span><br><span class="line">+---+--------------+------------------+</span><br><span class="line">| id|      features|      normFeatures|</span><br><span class="line">+---+--------------+------------------+</span><br><span class="line">|  <span class="number">0</span>|[<span class="number">1.0</span>,<span class="number">0.5</span>,<span class="number">-1.0</span>]|    [<span class="number">0.4</span>,<span class="number">0.2</span>,<span class="number">-0.4</span>]|</span><br><span class="line">|  <span class="number">1</span>| [<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">1.0</span>]|   [<span class="number">0.5</span>,<span class="number">0.25</span>,<span class="number">0.25</span>]|</span><br><span class="line">|  <span class="number">2</span>|[<span class="number">4.0</span>,<span class="number">10.0</span>,<span class="number">2.0</span>]|[<span class="number">0.25</span>,<span class="number">0.625</span>,<span class="number">0.125</span>]|</span><br><span class="line">+---+--------------+------------------+</span><br><span class="line"></span><br><span class="line">Normalized using L^inf norm</span><br><span class="line">+---+--------------+--------------+</span><br><span class="line">| id|      features|  normFeatures|</span><br><span class="line">+---+--------------+--------------+</span><br><span class="line">|  <span class="number">0</span>|[<span class="number">1.0</span>,<span class="number">0.5</span>,<span class="number">-1.0</span>]|[<span class="number">1.0</span>,<span class="number">0.5</span>,<span class="number">-1.0</span>]|</span><br><span class="line">|  <span class="number">1</span>| [<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">1.0</span>]| [<span class="number">1.0</span>,<span class="number">0.5</span>,<span class="number">0.5</span>]|</span><br><span class="line">|  <span class="number">2</span>|[<span class="number">4.0</span>,<span class="number">10.0</span>,<span class="number">2.0</span>]| [<span class="number">0.4</span>,<span class="number">1.0</span>,<span class="number">0.2</span>]|</span><br><span class="line">+---+--------------+--------------+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/normalizer_example.py” in the Spark repo.</p><h3 id="StandardScaler"><a href="#StandardScaler" class="headerlink" title="StandardScaler"></a><strong>StandardScaler</strong></h3><p><code>StandardScaler</code>转换Vector行的数据集，将每个特征归一化为具有单位标准偏差和/或零均值。它需要参数：</p><ul><li>withStd：默认为true。将数据缩放到单位标准偏差。</li><li>withMean：默认为False。在缩放之前将数据集中在平均值上。它会建立一个密集的输出，所以在应用于稀疏输入时要小心。</li></ul><p>StandardScaler是一个Estimator，可以fit在一个数据集上产生一个StandardScalerModel; 这相当于计算汇总统计。然后该模型可以转换Vector数据集中的列以具有单位标准偏差和/或零均值特征。</p><p>请注意，如果某个要素的标准偏差为零，则会在该特征的Vector中返回默认值0.0。</p><ul><li>Example</li></ul><p>以下示例演示如何加载数据集，然后将每个特征标准化为单位标准偏差。</p><p>有关API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.StandardScaler" target="_blank" rel="noopener">StandardScaler Python文档</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"StandardScalerExample"</span>).getOrCreate()</span><br><span class="line">dataFrame = spark.createDataFrame([</span><br><span class="line">    (<span class="number">0</span>, Vectors.dense([<span class="number">1.0</span>, <span class="number">0.5</span>, <span class="number">-1.0</span>]),),</span><br><span class="line">    (<span class="number">1</span>, Vectors.dense([<span class="number">2.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>]),),</span><br><span class="line">    (<span class="number">2</span>, Vectors.dense([<span class="number">4.0</span>, <span class="number">10.0</span>, <span class="number">2.0</span>]),)</span><br><span class="line">], [<span class="string">"id"</span>, <span class="string">"features"</span>])</span><br><span class="line">scaler = StandardScaler(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"scaledFeatures"</span>,</span><br><span class="line">                        withStd=<span class="keyword">True</span>, withMean=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute summary statistics by fitting the StandardScaler</span></span><br><span class="line">scalerModel = scaler.fit(dataFrame)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Normalize each feature to have unit standard deviation.</span></span><br><span class="line">scaledData = scalerModel.transform(dataFrame)</span><br><span class="line">scaledData.show(truncate=<span class="keyword">False</span>)</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+---+--------------+------------------------------------------------------------+</span><br><span class="line">|id |features      |scaledFeatures                                              |</span><br><span class="line">+---+--------------+------------------------------------------------------------+</span><br><span class="line">|<span class="number">0</span>  |[<span class="number">1.0</span>,<span class="number">0.5</span>,<span class="number">-1.0</span>]|[<span class="number">0.6546536707079772</span>,<span class="number">0.09352195295828244</span>,<span class="number">-0.6546536707079771</span>]|</span><br><span class="line">|<span class="number">1</span>  |[<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">1.0</span>] |[<span class="number">1.3093073414159544</span>,<span class="number">0.1870439059165649</span>,<span class="number">0.6546536707079771</span>]  |</span><br><span class="line">|<span class="number">2</span>  |[<span class="number">4.0</span>,<span class="number">10.0</span>,<span class="number">2.0</span>]|[<span class="number">2.618614682831909</span>,<span class="number">1.870439059165649</span>,<span class="number">1.3093073414159542</span>]    |</span><br><span class="line">+---+--------------+------------------------------------------------------------+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/standard_scaler_example.py” in the Spark repo.</p><h3 id="MinMaxScaler"><a href="#MinMaxScaler" class="headerlink" title="MinMaxScaler"></a><strong>MinMaxScaler</strong></h3><p><code>MinMaxScaler</code>转换Vector行数据集，将每个特征重新缩放到特定范围（通常为[0，1]）。它需要参数：</p><p>min：默认为0.0。转换后的下界，被所有特征共享。<br>max：默认为1.0。变换后的上界，被所有的特征共享。<br>MinMaxScaler计算数据集的汇总统计并生成一个MinMaxScalerModel。然后模型可以单独转换每个特征，使其在给定的范围内。</p><p>特征E的重新缩放的值被计算为，<br>Rescaled(ei) = (ei − Emin) / (Emax − Emin) ∗ (max − min) + min<br>对于Emax==Emin的情况Rescaled(ei)=0.5∗(max+min)</p><p>请注意，由于零值可能会被转换为非零值，所以transofromer的输出将会是DenseVector，即使输入是稀疏输入。</p><ul><li>Examples</li></ul><p>有关API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.MinMaxScaler" target="_blank" rel="noopener">MinMaxScaler Python文档</a> 和<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.MinMaxScalerModel" target="_blank" rel="noopener">MinMaxScalerModel Python文档</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession  </span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"MinMaxScalerExample"</span>).getOrCreate()</span><br><span class="line">dataFrame = spark.createDataFrame([</span><br><span class="line">    (<span class="number">0</span>, Vectors.dense([<span class="number">1.0</span>, <span class="number">0.1</span>, <span class="number">-1.0</span>]),),</span><br><span class="line">    (<span class="number">1</span>, Vectors.dense([<span class="number">2.0</span>, <span class="number">1.1</span>, <span class="number">1.0</span>]),),</span><br><span class="line">    (<span class="number">2</span>, Vectors.dense([<span class="number">3.0</span>, <span class="number">10.1</span>, <span class="number">3.0</span>]),)</span><br><span class="line">], [<span class="string">"id"</span>, <span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line">scaler = MinMaxScaler(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"scaledFeatures"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute summary statistics and generate MinMaxScalerModel</span></span><br><span class="line">scalerModel = scaler.fit(dataFrame)</span><br><span class="line"></span><br><span class="line"><span class="comment"># rescale each feature to range [min, max].</span></span><br><span class="line">scaledData = scalerModel.transform(dataFrame)</span><br><span class="line">print(<span class="string">"Features scaled to range: [%f, %f]"</span> % (scaler.getMin(), scaler.getMax()))</span><br><span class="line">scaledData.select(<span class="string">"features"</span>, <span class="string">"scaledFeatures"</span>).show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Features scaled to range: [<span class="number">0.000000</span>, <span class="number">1.000000</span>]</span><br><span class="line">+--------------+--------------+</span><br><span class="line">|      features|scaledFeatures|</span><br><span class="line">+--------------+--------------+</span><br><span class="line">|[<span class="number">1.0</span>,<span class="number">0.1</span>,<span class="number">-1.0</span>]| [<span class="number">0.0</span>,<span class="number">0.0</span>,<span class="number">0.0</span>]|</span><br><span class="line">| [<span class="number">2.0</span>,<span class="number">1.1</span>,<span class="number">1.0</span>]| [<span class="number">0.5</span>,<span class="number">0.1</span>,<span class="number">0.5</span>]|</span><br><span class="line">|[<span class="number">3.0</span>,<span class="number">10.1</span>,<span class="number">3.0</span>]| [<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">1.0</span>]|</span><br><span class="line">+--------------+--------------+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/min_max_scaler_example.py” in the Spark repo.</p><h3 id="MaxAbsScaler"><a href="#MaxAbsScaler" class="headerlink" title="MaxAbsScaler"></a><strong>MaxAbsScaler</strong></h3><p><code>MaxAbsScaler</code>转换Vector行的数据集，通过分割每个特征的最大绝对值来重新缩放每个特征到范围[-1,1]。它不会移动/居中数据，因此不会破坏任何稀疏性。</p><p>MaxAbsScaler计算数据集的汇总统计并生成一个MaxAbsScalerModel。该模型可以将每个特征分别转换为范围[-1,1]。</p><ul><li>Examples</li></ul><p>有关API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.MaxAbsScaler" target="_blank" rel="noopener">MaxAbsScaler Python文档</a> 和<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.MaxAbsScalerModel" target="_blank" rel="noopener">MaxAbsScalerModel Python文档</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> MaxAbsScaler</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"MaxAbsScalerExample"</span>).getOrCreate()</span><br><span class="line">dataFrame = spark.createDataFrame([</span><br><span class="line">    (<span class="number">0</span>, Vectors.dense([<span class="number">1.0</span>, <span class="number">0.1</span>, <span class="number">-8.0</span>]),),</span><br><span class="line">    (<span class="number">1</span>, Vectors.dense([<span class="number">2.0</span>, <span class="number">1.0</span>, <span class="number">-4.0</span>]),),</span><br><span class="line">    (<span class="number">2</span>, Vectors.dense([<span class="number">4.0</span>, <span class="number">10.0</span>, <span class="number">8.0</span>]),)</span><br><span class="line">], [<span class="string">"id"</span>, <span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line">scaler = MaxAbsScaler(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"scaledFeatures"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute summary statistics and generate MaxAbsScalerModel</span></span><br><span class="line">scalerModel = scaler.fit(dataFrame)</span><br><span class="line"></span><br><span class="line"><span class="comment"># rescale each feature to range [-1, 1].</span></span><br><span class="line">scaledData = scalerModel.transform(dataFrame)</span><br><span class="line"></span><br><span class="line">scaledData.select(<span class="string">"features"</span>, <span class="string">"scaledFeatures"</span>).show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+--------------+----------------+</span><br><span class="line">|      features|  scaledFeatures|</span><br><span class="line">+--------------+----------------+</span><br><span class="line">|[<span class="number">1.0</span>,<span class="number">0.1</span>,<span class="number">-8.0</span>]|[<span class="number">0.25</span>,<span class="number">0.01</span>,<span class="number">-1.0</span>]|</span><br><span class="line">|[<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">-4.0</span>]|  [<span class="number">0.5</span>,<span class="number">0.1</span>,<span class="number">-0.5</span>]|</span><br><span class="line">|[<span class="number">4.0</span>,<span class="number">10.0</span>,<span class="number">8.0</span>]|   [<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">1.0</span>]|</span><br><span class="line">+--------------+----------------+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/max_abs_scaler_example.py” in the Spark repo.</p><h3 id="Bucketizer"><a href="#Bucketizer" class="headerlink" title="Bucketizer"></a><strong>Bucketizer</strong></h3><p><code>Bucketizer</code>将一列连续的特征转换成特征桶列，其中桶由用户指定。它需要一个参数：</p><ul><li>splits：用于将连续特征映射到存储桶的参数。n个buckets有n+1个splits。由分割x，y定义的bucket值范围为[x,y)不包含y,而只有最后一个bucket包含y。splits应是严格增加的。必须明确提供inf的值以涵盖所有Double值; 否则，指定splits之外的值将被视为错误。两个splits的例子是Array(Double.NegativeInfinity, 0.0, 1.0, Double.PositiveInfinity)和Array(0.0, 1.0, 2.0)。</li></ul><p>请注意，如果您不知道目标列的上限和下限，则应该添加Double.NegativeInfinity并Double.PositiveInfinity作为分割的界限，以防止出现Bucketizer界限异常。</p><p>还要注意，你提供的splits必须严格按照递增顺序，即s0 &lt; s1 &lt; s2 &lt; … &lt; sn。</p><p>更多细节可以在<a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.feature.Bucketizer" target="_blank" rel="noopener">Bucketizer</a>的API文档中找到。</p><ul><li>Examples</li></ul><p>以下示例演示了如何将一列Doubles转换为另一个索引表列<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> Bucketizer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"BucketizerExample"</span>).getOrCreate()</span><br><span class="line">splits = [-float(<span class="string">"inf"</span>), <span class="number">-0.5</span>, <span class="number">0.0</span>, <span class="number">0.5</span>, float(<span class="string">"inf"</span>)]</span><br><span class="line"></span><br><span class="line">data = [(<span class="number">-999.9</span>,), (<span class="number">-0.5</span>,), (<span class="number">-0.3</span>,), (<span class="number">0.0</span>,), (<span class="number">0.2</span>,), (<span class="number">999.9</span>,)]</span><br><span class="line">dataFrame = spark.createDataFrame(data, [<span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line">bucketizer = Bucketizer(splits=splits, inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"bucketedFeatures"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Transform original data into its bucket index.</span></span><br><span class="line">bucketedData = bucketizer.transform(dataFrame)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Bucketizer output with %d buckets"</span> % (len(bucketizer.getSplits())<span class="number">-1</span>))</span><br><span class="line">bucketedData.show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Bucketizer output <span class="keyword">with</span> <span class="number">4</span> buckets</span><br><span class="line">+--------+----------------+</span><br><span class="line">|features|bucketedFeatures|</span><br><span class="line">+--------+----------------+</span><br><span class="line">|  <span class="number">-999.9</span>|             <span class="number">0.0</span>|</span><br><span class="line">|    <span class="number">-0.5</span>|             <span class="number">1.0</span>|</span><br><span class="line">|    <span class="number">-0.3</span>|             <span class="number">1.0</span>|</span><br><span class="line">|     <span class="number">0.0</span>|             <span class="number">2.0</span>|</span><br><span class="line">|     <span class="number">0.2</span>|             <span class="number">2.0</span>|</span><br><span class="line">|   <span class="number">999.9</span>|             <span class="number">3.0</span>|</span><br><span class="line">+--------+----------------+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/bucketizer_example.py” in the Spark repo.</p><h3 id="ElementwiseProduct"><a href="#ElementwiseProduct" class="headerlink" title="ElementwiseProduct"></a><strong>ElementwiseProduct</strong></h3><p><code>ElementwiseProduct</code>将每个输入矢量使用元素乘法乘以一个提供的“权重”矢量。换句话说，它通过标量乘数来缩放数据集的每一列。这表示输入向量v和变换向量w之间的<a href="https://en.wikipedia.org/wiki/Hadamard_product_%28matrices%29" target="_blank" rel="noopener">Hadamard product</a>(哈达玛积)，得到结果向量。<br>(v1…vN).T 。(w1…WN).T = (v1w1…vNwN).T</p><ul><li>Examples</li></ul><p>下面的这个例子演示了如何使用变换向量值来变换向量。有关API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.ElementwiseProduct" target="_blank" rel="noopener">ElementwiseProduct Python文档</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> ElementwiseProduct</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"ElementwiseProductExample"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Create some vector data; also works for sparse vectors</span></span><br><span class="line">data = [(Vectors.dense([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>]),), (Vectors.dense([<span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>]),)]</span><br><span class="line">df = spark.createDataFrame(data, [<span class="string">"vector"</span>])</span><br><span class="line">transformer = ElementwiseProduct(scalingVec=Vectors.dense([<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">2.0</span>]),</span><br><span class="line">                                 inputCol=<span class="string">"vector"</span>, outputCol=<span class="string">"transformedVector"</span>)</span><br><span class="line"><span class="comment"># Batch transform the vectors to create new column:</span></span><br><span class="line">transformer.transform(df).show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+-------------+-----------------+</span><br><span class="line">|       vector|transformedVector|</span><br><span class="line">+-------------+-----------------+</span><br><span class="line">|[<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>]|    [<span class="number">0.0</span>,<span class="number">2.0</span>,<span class="number">6.0</span>]|</span><br><span class="line">|[<span class="number">4.0</span>,<span class="number">5.0</span>,<span class="number">6.0</span>]|   [<span class="number">0.0</span>,<span class="number">5.0</span>,<span class="number">12.0</span>]|</span><br><span class="line">+-------------+-----------------+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/elementwise_product_example.py” in the Spark repo.</p><h3 id="SQLTransformer"><a href="#SQLTransformer" class="headerlink" title="SQLTransformer"></a><strong>SQLTransformer</strong></h3><p><code>SQLTransformer</code>实现由SQL语句定义的转换。目前我们只支持一下SQL语法：”SELECT … FROM <strong>THIS</strong> …” where， “<strong>THIS</strong>“代表输入数据集的基础表。select子句指定要在输出中显示的字段，常量和表达式，并且可以是Spark SQL支持的任何select子句。用户还可以使用Spark SQL内置函数和UDF对这些选定的列进行操作。例如，SQLTransformer支持像这样的语句：</p><ul><li>SELECT a, a + b AS a_b FROM <strong>THIS</strong></li><li>SELECT a, SQRT(b) AS b_sqrt FROM <strong>THIS</strong> where a &gt; 5</li><li><p>SELECT a, b, SUM(c) AS c_sum FROM <strong>THIS</strong> GROUP BY a, b</p></li><li><p>Examples</p></li></ul><p>有关该API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.SQLTransformer" target="_blank" rel="noopener">SQLTransformer Python文档</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> SQLTransformer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"SQLTransformerExample"</span>).getOrCreate()</span><br><span class="line">df = spark.createDataFrame([</span><br><span class="line">    (<span class="number">0</span>, <span class="number">1.0</span>, <span class="number">3.0</span>),</span><br><span class="line">    (<span class="number">2</span>, <span class="number">2.0</span>, <span class="number">5.0</span>)</span><br><span class="line">], [<span class="string">"id"</span>, <span class="string">"v1"</span>, <span class="string">"v2"</span>])</span><br><span class="line">sqlTrans = SQLTransformer(</span><br><span class="line">    statement=<span class="string">"SELECT *, (v1 + v2) AS v3, (v1 * v2) AS v4 FROM __THIS__"</span>)</span><br><span class="line">sqlTrans.transform(df).show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+---+---+---+---+----+</span><br><span class="line">| id| v1| v2| v3|  v4|</span><br><span class="line">+---+---+---+---+----+</span><br><span class="line">|  <span class="number">0</span>|<span class="number">1.0</span>|<span class="number">3.0</span>|<span class="number">4.0</span>| <span class="number">3.0</span>|</span><br><span class="line">|  <span class="number">2</span>|<span class="number">2.0</span>|<span class="number">5.0</span>|<span class="number">7.0</span>|<span class="number">10.0</span>|</span><br><span class="line">+---+---+---+---+----+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/sql_transformer.py” in the Spark repo.</p><h3 id="VectorAssembler"><a href="#VectorAssembler" class="headerlink" title="VectorAssembler"></a><strong>VectorAssembler</strong></h3><p><code>VectorAssembler</code>是一个将给定的列列表组合成单个向量列的transoformer。对于将原始特征和由不同特征变换器生成的特征组合成一个特征向量，以便训练诸如逻辑回归和决策树等ML模型是有用的。 VectorAssembler接受以下输入列类型：所有数字类型，布尔类型和向量类型。在每一行中，输入列的值将按照指定的顺序连接成一个向量。</p><ul><li>Examples</li></ul><p>请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.VectorAssembler" target="_blank" rel="noopener">VectorAssembler Python文档</a> 以获取有关API的更多详细信息。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorAssembler</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"VectorAssemblerExample"</span>).getOrCreate()</span><br><span class="line">dataset = spark.createDataFrame(</span><br><span class="line">    [(<span class="number">0</span>, <span class="number">18</span>, <span class="number">1.0</span>, Vectors.dense([<span class="number">0.0</span>, <span class="number">10.0</span>, <span class="number">0.5</span>]), <span class="number">1.0</span>)],</span><br><span class="line">    [<span class="string">"id"</span>, <span class="string">"hour"</span>, <span class="string">"mobile"</span>, <span class="string">"userFeatures"</span>, <span class="string">"clicked"</span>])</span><br><span class="line"></span><br><span class="line">assembler = VectorAssembler(</span><br><span class="line">    inputCols=[<span class="string">"hour"</span>, <span class="string">"mobile"</span>, <span class="string">"userFeatures"</span>],</span><br><span class="line">    outputCol=<span class="string">"features"</span>)</span><br><span class="line"></span><br><span class="line">output = assembler.transform(dataset)</span><br><span class="line">print(<span class="string">"Assembled columns 'hour', 'mobile', 'userFeatures' to vector column 'features'"</span>)</span><br><span class="line">output.select(<span class="string">"features"</span>, <span class="string">"clicked"</span>).show(truncate=<span class="keyword">False</span>)</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Assembled columns <span class="string">'hour'</span>, <span class="string">'mobile'</span>, <span class="string">'userFeatures'</span> to vector column <span class="string">'features'</span></span><br><span class="line">+-----------------------+-------+</span><br><span class="line">|features               |clicked|</span><br><span class="line">+-----------------------+-------+</span><br><span class="line">|[<span class="number">18.0</span>,<span class="number">1.0</span>,<span class="number">0.0</span>,<span class="number">10.0</span>,<span class="number">0.5</span>]|<span class="number">1.0</span>    |</span><br><span class="line">+-----------------------+-------+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/vector_assembler_example.py” in the Spark repo.</p><h3 id="QuantileDiscretizer"><a href="#QuantileDiscretizer" class="headerlink" title="QuantileDiscretizer"></a><strong>QuantileDiscretizer</strong></h3><p>QuantileDiscretizer将带有连续特征的列转换成具有分类分类特征的列。bins的数量通过numBuckets参数设置。如果输入的独特值不足以创建足够多的分位数，则所用桶的数量可能会小于此值。</p><p>NaN values：NaN值将在QuantileDiscretizer拟合过程中从列中移除。这将产生一个Bucketizer预测模型。在转换期间，当在数据集中发现NaN值时Bucketizer会引发错误，但是用户也可以通过设置handleInvalid来选择保留或删除数据集中的NaN值。如果用户选择保留NaN值，他们将被专门处理，并放入他们自己的bucket中，例如，如果使用4个bucket，那么非NaN数据将被放入bucket[0-3]，但是NaN将是算在一个特殊的bucket[4]里。</p><p>Algorithm：使用近似算法（有关详细说明，请参阅<a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrameStatFunctions" target="_blank" rel="noopener">approxQuantile</a>文档 ）来选择bin的范围。近似的精度可以用relativeError参数来控制 。设置为零时，计算确切的分位数（注意：精确计算分位数是一个耗费的操作）。下部和上部bin边界会是-Infinity和+Infinity以来涵盖所有实数值。</p><ul><li>Examples</li></ul><p>请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.QuantileDiscretizer" target="_blank" rel="noopener">QuantileDiscretizer Python文档</a> 以获取有关API的更多详细信息。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> QuantileDiscretizer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"QuantileDiscretizerExample"</span>).getOrCreate()</span><br><span class="line">data = [(<span class="number">0</span>, <span class="number">18.0</span>), (<span class="number">1</span>, <span class="number">19.0</span>), (<span class="number">2</span>, <span class="number">8.0</span>), (<span class="number">3</span>, <span class="number">5.0</span>), (<span class="number">4</span>, <span class="number">2.2</span>)]</span><br><span class="line">df = spark.createDataFrame(data, [<span class="string">"id"</span>, <span class="string">"hour"</span>])</span><br><span class="line"></span><br><span class="line">discretizer = QuantileDiscretizer(numBuckets=<span class="number">3</span>, inputCol=<span class="string">"hour"</span>, outputCol=<span class="string">"result"</span>)</span><br><span class="line"></span><br><span class="line">result = discretizer.fit(df).transform(df)</span><br><span class="line">result.show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+---+----+------+</span><br><span class="line">| id|hour|result|</span><br><span class="line">+---+----+------+</span><br><span class="line">|  <span class="number">0</span>|<span class="number">18.0</span>|   <span class="number">2.0</span>|</span><br><span class="line">|  <span class="number">1</span>|<span class="number">19.0</span>|   <span class="number">2.0</span>|</span><br><span class="line">|  <span class="number">2</span>| <span class="number">8.0</span>|   <span class="number">1.0</span>|</span><br><span class="line">|  <span class="number">3</span>| <span class="number">5.0</span>|   <span class="number">1.0</span>|</span><br><span class="line">|  <span class="number">4</span>| <span class="number">2.2</span>|   <span class="number">0.0</span>|</span><br><span class="line">+---+----+------+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/quantile_discretizer_example.py” in the Spark repo.</p><h3 id="Imputer"><a href="#Imputer" class="headerlink" title="Imputer"></a><strong>Imputer</strong></h3><p><code>Imputer</code> transformer使用平均值或位于列的中位数填充数据集中缺少的值。输入列应该是 DoubleType或FloatType。目前Imputer不支持分类特征，并可能为包含分类特征的列创建不正确的值。</p><p>注意：输入列中的所有null值都被视为缺失，所以也被归类。</p><ul><li>Examples</li></ul><p>有关API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.Imputer" target="_blank" rel="noopener">Imputer Python文档</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> Imputer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"ImputerExample"</span>).getOrCreate()</span><br><span class="line">df = spark.createDataFrame([</span><br><span class="line">    (<span class="number">1.0</span>, float(<span class="string">"nan"</span>)),</span><br><span class="line">    (<span class="number">2.0</span>, float(<span class="string">"nan"</span>)),</span><br><span class="line">    (float(<span class="string">"nan"</span>), <span class="number">3.0</span>),</span><br><span class="line">    (<span class="number">4.0</span>, <span class="number">4.0</span>),</span><br><span class="line">    (<span class="number">5.0</span>, <span class="number">5.0</span>)</span><br><span class="line">], [<span class="string">"a"</span>, <span class="string">"b"</span>])</span><br><span class="line"></span><br><span class="line">imputer = Imputer(inputCols=[<span class="string">"a"</span>, <span class="string">"b"</span>], outputCols=[<span class="string">"out_a"</span>, <span class="string">"out_b"</span>])</span><br><span class="line">model = imputer.fit(df)</span><br><span class="line"></span><br><span class="line">model.transform(df).show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+---+---+-----+-----+</span><br><span class="line">|  a|  b|out_a|out_b|</span><br><span class="line">+---+---+-----+-----+</span><br><span class="line">|<span class="number">1.0</span>|NaN|  <span class="number">1.0</span>|  <span class="number">4.0</span>|</span><br><span class="line">|<span class="number">2.0</span>|NaN|  <span class="number">2.0</span>|  <span class="number">4.0</span>|</span><br><span class="line">|NaN|<span class="number">3.0</span>|  <span class="number">3.0</span>|  <span class="number">3.0</span>|</span><br><span class="line">|<span class="number">4.0</span>|<span class="number">4.0</span>|  <span class="number">4.0</span>|  <span class="number">4.0</span>|</span><br><span class="line">|<span class="number">5.0</span>|<span class="number">5.0</span>|  <span class="number">5.0</span>|  <span class="number">5.0</span>|</span><br><span class="line">+---+---+-----+-----+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/imputer_example.py” in the Spark repo.</p><h2 id="Feature-Selectors"><a href="#Feature-Selectors" class="headerlink" title="Feature Selectors"></a><strong>Feature Selectors</strong></h2><h3 id="VectorSlicer"><a href="#VectorSlicer" class="headerlink" title="VectorSlicer"></a><strong>VectorSlicer</strong></h3><p><code>VectorSlicer</code>是一个transformer，它将一个特征向量转换成一个新的具有原始特征的sub-array的特征向量。这对从向量列中提取特征很有用。</p><p>VectorSlicer接受一个具有指定索引的向量列，然后输出一个新的向量列，其值通过这些索引来选择。有两种类型的索引：</p><ol><li><p>setIndices()：代表向量中索引的整数索引。</p></li><li><p>setNames()：代表向量中特征名称的字符串索引。 这需要vector列有一个AttributeGroup，因为实现得匹配Attribute名称字段。</p></li></ol><p>整数和字符串的规范都是可以接受的。而且，您可以同时使用整数索引和字符串名称。必须至少选择一个特征，不允许重复的特征，所以选择的索引和名称之间就没有重叠。请注意，如果选择了特征的名称，遇到空的输入属性时将会抛出异常。</p><p>输出向量将首先按照选定的索引（按给定的顺序）排序，然后是选定的名称（按给定的顺序）。</p><ul><li>Examples</li></ul><p>有关API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.VectorSlicer" target="_blank" rel="noopener">VectorSlicer Python文档</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> VectorSlicer</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> Row</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"VectorSlicerExample"</span>).getOrCreate()</span><br><span class="line">df = spark.createDataFrame([</span><br><span class="line">    Row(userFeatures=Vectors.sparse(<span class="number">3</span>, &#123;<span class="number">0</span>: <span class="number">-2.0</span>, <span class="number">1</span>: <span class="number">2.3</span>&#125;)),</span><br><span class="line">    Row(userFeatures=Vectors.dense([<span class="number">-2.0</span>, <span class="number">2.3</span>, <span class="number">0.0</span>]))])</span><br><span class="line"></span><br><span class="line">slicer = VectorSlicer(inputCol=<span class="string">"userFeatures"</span>, outputCol=<span class="string">"features"</span>, indices=[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">output = slicer.transform(df)</span><br><span class="line"></span><br><span class="line">output.select(<span class="string">"userFeatures"</span>, <span class="string">"features"</span>).show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+--------------------+-------------+</span><br><span class="line">|        userFeatures|     features|</span><br><span class="line">+--------------------+-------------+</span><br><span class="line">|(<span class="number">3</span>,[<span class="number">0</span>,<span class="number">1</span>],[<span class="number">-2.0</span>,<span class="number">2.3</span>])|(<span class="number">1</span>,[<span class="number">0</span>],[<span class="number">2.3</span>])|</span><br><span class="line">|      [<span class="number">-2.0</span>,<span class="number">2.3</span>,<span class="number">0.0</span>]|        [<span class="number">2.3</span>]|</span><br><span class="line">+--------------------+-------------+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/vector_slicer_example.py” in the Spark repo.</p><h3 id="RFormula"><a href="#RFormula" class="headerlink" title="RFormula"></a><strong>RFormula</strong></h3><p><code>RFormula</code>选择由<a href="https://stat.ethz.ch/R-manual/R-devel/library/stats/html/formula.html" target="_blank" rel="noopener">Rmodel formula</a>指定的列。目前我们支持R操作符的有限子集，包括’〜’，’。’，’：’，’+’和’ - ‘。其基本的操作符是：</p><ul><li>‘~’: 分开 target和terms</li><li>‘+’: 连接terms，“+ 0”表示删除intercept</li><li>‘-‘: 删除一个term，“ - 1”表示删除intercept</li><li>‘:’: interaction（数值相乘或二元化分类值）</li><li>‘.’: 除target以外的所有列</li></ul><p>假设a和都是b是double类型的列，我们使用以下简单的例子来说明RFormula的作用：</p><p>y ~ a + b意味着模型y ~ w0 + w1 <em> a + w2 </em> b，其中w0是截距intercept，w1, w2是系数coefficients。\<br>y ~ a + b + a:b - 1装置模型y ~ w1 <em> a + w2 </em> b + w3 <em> a </em> b，其中w1, w2, w3为系数。\<br>RFormula产生特征的一个向量列的和一个double类型列或标签的字符串类型列。就像在R中使用公式进行线性回归时一样，字符串输入列将被进行one-hot编码，而数字列将被转换为doule类型。如果标签列是字符串类型的，它将首先被转换为StringIndexer的double类型。如果DataFrame中不存在标签列，则将使用公式中指定的结果变量创建输出标签列。</p><ul><li>Examples</li></ul><p>有关API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.RFormula" target="_blank" rel="noopener">RFormula Python文档</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> RFormula</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"RFormulaExample"</span>).getOrCreate()</span><br><span class="line">dataset = spark.createDataFrame(</span><br><span class="line">    [(<span class="number">7</span>, <span class="string">"US"</span>, <span class="number">18</span>, <span class="number">1.0</span>),</span><br><span class="line">     (<span class="number">8</span>, <span class="string">"CA"</span>, <span class="number">12</span>, <span class="number">0.0</span>),</span><br><span class="line">     (<span class="number">9</span>, <span class="string">"NZ"</span>, <span class="number">15</span>, <span class="number">0.0</span>)],</span><br><span class="line">    [<span class="string">"id"</span>, <span class="string">"country"</span>, <span class="string">"hour"</span>, <span class="string">"clicked"</span>])</span><br><span class="line"></span><br><span class="line">formula = RFormula(</span><br><span class="line">    formula=<span class="string">"clicked ~ country + hour"</span>,</span><br><span class="line">    featuresCol=<span class="string">"features"</span>,</span><br><span class="line">    labelCol=<span class="string">"label"</span>)</span><br><span class="line"></span><br><span class="line">output = formula.fit(dataset).transform(dataset)</span><br><span class="line">output.select(<span class="string">"features"</span>, <span class="string">"label"</span>).show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">+--------------+-----+</span><br><span class="line">|      features|label|</span><br><span class="line">+--------------+-----+</span><br><span class="line">|[<span class="number">0.0</span>,<span class="number">0.0</span>,<span class="number">18.0</span>]|  <span class="number">1.0</span>|</span><br><span class="line">|[<span class="number">1.0</span>,<span class="number">0.0</span>,<span class="number">12.0</span>]|  <span class="number">0.0</span>|</span><br><span class="line">|[<span class="number">0.0</span>,<span class="number">1.0</span>,<span class="number">15.0</span>]|  <span class="number">0.0</span>|</span><br><span class="line">+--------------+-----+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/rformula_example.py” in the Spark repo.</p><h3 id="ChiSqSelector"><a href="#ChiSqSelector" class="headerlink" title="ChiSqSelector"></a><strong>ChiSqSelector</strong></h3><p><code>ChiSqSelector</code>代表Chi-Squared特征选择。它作用于具有分类特征的已标记数据。ChiSqSelector使用<a href="https://en.wikipedia.org/wiki/Chi-squared_test" target="_blank" rel="noopener">Chi-Squared test of independence</a>来决定选择哪些特征。它支持五种选择方法：numTopFeatures，percentile，fpr，fdr，fwe：<em> numTopFeatures选择一个根据卡方检验得到的固定的数目前几个特征，这类似于产生具有最大预测能力的特征。</em> percentile类似于numTopFeatures，但只选择所有特征的一部分，而不是固定的数目。<em> fpr选择p值低于阈值的所有特征，从而控制选择的误报率。</em> fdr使用<a href="https://en.wikipedia.org/wiki/False_discovery_rate#Benjamini.E2.80.93Hochberg_procedure" target="_blank" rel="noopener">Benjamini-Hochbergprocedure</a>选择false discovery rate低于阈值的所有特征。* fwe选择p值低于阈值的所有特征,阈值由1 / numFeatures缩放，从而控制选择的family-wise error rate。默认选择方法是numTopFeatures，top特征的默认数量设置为50.用户可以使用setSelectorType选择方法。</p><ul><li>Examples</li></ul><p>有关API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.ChiSqSelector" target="_blank" rel="noopener">ChiSqSelector Python文档</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> ChiSqSelector</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"ChiSqSelectorExample"</span>).getOrCreate()</span><br><span class="line">df = spark.createDataFrame([</span><br><span class="line">    (<span class="number">7</span>, Vectors.dense([<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">18.0</span>, <span class="number">1.0</span>]), <span class="number">1.0</span>,),</span><br><span class="line">    (<span class="number">8</span>, Vectors.dense([<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">12.0</span>, <span class="number">0.0</span>]), <span class="number">0.0</span>,),</span><br><span class="line">    (<span class="number">9</span>, Vectors.dense([<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">15.0</span>, <span class="number">0.1</span>]), <span class="number">0.0</span>,)], [<span class="string">"id"</span>, <span class="string">"features"</span>, <span class="string">"clicked"</span>])</span><br><span class="line"></span><br><span class="line">selector = ChiSqSelector(numTopFeatures=<span class="number">1</span>, featuresCol=<span class="string">"features"</span>,</span><br><span class="line">                         outputCol=<span class="string">"selectedFeatures"</span>, labelCol=<span class="string">"clicked"</span>)</span><br><span class="line"></span><br><span class="line">result = selector.fit(df).transform(df)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"ChiSqSelector output with top %d features selected"</span> % selector.getNumTopFeatures())</span><br><span class="line">result.show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">ChiSqSelector output <span class="keyword">with</span> top <span class="number">1</span> features selected</span><br><span class="line">+---+------------------+-------+----------------+</span><br><span class="line">| id|          features|clicked|selectedFeatures|</span><br><span class="line">+---+------------------+-------+----------------+</span><br><span class="line">|  <span class="number">7</span>|[<span class="number">0.0</span>,<span class="number">0.0</span>,<span class="number">18.0</span>,<span class="number">1.0</span>]|    <span class="number">1.0</span>|          [<span class="number">18.0</span>]|</span><br><span class="line">|  <span class="number">8</span>|[<span class="number">0.0</span>,<span class="number">1.0</span>,<span class="number">12.0</span>,<span class="number">0.0</span>]|    <span class="number">0.0</span>|          [<span class="number">12.0</span>]|</span><br><span class="line">|  <span class="number">9</span>|[<span class="number">1.0</span>,<span class="number">0.0</span>,<span class="number">15.0</span>,<span class="number">0.1</span>]|    <span class="number">0.0</span>|          [<span class="number">15.0</span>]|</span><br><span class="line">+---+------------------+-------+----------------+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/chisq_selector_example.py” in the Spark repo.</p><h2 id="Locality-Sensitive-Hashing"><a href="#Locality-Sensitive-Hashing" class="headerlink" title="Locality Sensitive Hashing"></a><strong>Locality Sensitive Hashing</strong></h2><p><a href="https://en.wikipedia.org/wiki/Locality-sensitive_hashing" target="_blank" rel="noopener">Locality Sensitive Hashing (LSH)</a>是一类重要的散列技术，常用于聚类，近似最近邻搜索和大数据集异常值检测。</p><p>LSH的总体思路是使用一系列函数（“LSH families”）将数据点散列到桶中，使得彼此靠近的数据点高概率地出现在同一个桶中，而彼此相距很远的数据点很有可能在不同的桶里。LSH family正式定义如下。</p><p>在一个度量空间中(M, d)中，M一个集合，d是一个基于M的距离函数，LSH族是满足下列性质的函数族h：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">存在p,q属于M，</span><br><span class="line">d(p,q) &lt;= r1 =&gt; Pr(h(p)) = h(q) &gt;= p1</span><br><span class="line">d(p,1) &gt;= r2 =&gt; Pr(h(p)) = h(q) &lt;= p2 </span><br><span class="line">则这个LSH族被称为 (r1, r2, p1, p2)-敏感的。</span><br></pre></td></tr></table></figure></p><p>在Spark中，不同的LSH families在不同的类中实现（例如MinHash），并且在每个类中提供用于feature transformation(特征变换)，approximate simility join(最近似连接)和approximate nearest neighbor最近邻的APIs。</p><p>在LSH中，我们将false positive定义为一对散列到同一个桶中远距输入特征(with d(p,q)≥r2)，并且将一个false negative定义为一对被散列到不同的桶中近距特征(with d(p,q)≤r1)</p><h3 id="LSH-Operations"><a href="#LSH-Operations" class="headerlink" title="LSH Operations"></a><strong>LSH Operations</strong></h3><p>我们描述了LSH可以应用的主要操作类型。一个拟合的LSH模型具有下列每个操作的方法。</p><h4 id="Feature-Transformation"><a href="#Feature-Transformation" class="headerlink" title="Feature Transformation"></a>Feature Transformation</h4><p>Feature Transformation是添加哈希值作为新列的基本功能。这对降维有用。用户可以通过设置inputCol和outputCol来指定输入和输出列名。</p><p>LSH还支持多个LSH哈希表。用户可以通过设置numHashTables来指定哈希表的数量。这也用于在approximate similarity join和approximate nearest neighbo的<a href="approximate similarity join and approximate nearest neighbo">OR-amplification</a>。增加哈希表的数量会提高精度，但同时也会增加通信成本和运行时间。</p><p>outputCol的类型是Seq[Vector]，其中数组的维度等于numHashTables，vectors的维度当前设置为1。在未来的版本中，我们将实现AND-amplification，使得用户可以指定这些vectors的维度。</p><h4 id="Approximate-Similarity-Join"><a href="#Approximate-Similarity-Join" class="headerlink" title="Approximate Similarity Join"></a>Approximate Similarity Join</h4><p>Approximate Similarity Join输入两个数据集，近似地返回数据集中那些距离小于用户定义的阈值的数行对。Approximate similarity join支持连接两个不同的数据集和self-joining(自连接)。自加入会产生一些重复的对。</p><p>Approximate similarity join接受转换和未转换的数据集作为输入。如果使用未转换的数据集，则会自动进行转换。在这种情况下，hash signture(哈希签名)将被创建为outputCol。</p><p>在连接的数据集中，可以在datasetA和datasetB中查询原始数据集。距离列将被添加到输出数据集，以显示返回的每对行之间的真实距离。</p><h4 id="Approximate-Nearest-Neighbor-Search"><a href="#Approximate-Nearest-Neighbor-Search" class="headerlink" title="Approximate Nearest Neighbor Search"></a>Approximate Nearest Neighbor Search</h4><p>Approximate nearest neighbor search需要（拥有特征向量s的）数据集和一个关键字（单个特征向量），并且它近似地返回数据集中最接近这个向量的指定数量的行。</p><p>Approximate nearest neighbor search接受转换和未转换的数据集作为输入。如果使用未转换的数据集，则会自动进行转换。在这种情况下，哈希签名将被创建为outputCol。</p><p>距离列将被添加到输出数据集，以显示每个输出行和搜索键之间的真实距离。</p><p>注意：当散列桶中没有足够的候选项时，Approximate nearest neighbor search将返回少于l行。</p><h3 id="LSH-Algorithms"><a href="#LSH-Algorithms" class="headerlink" title="LSH Algorithms"></a><strong>LSH Algorithms</strong></h3><h4 id="Bucketed-Random-Projection-for-Euclidean-Distance"><a href="#Bucketed-Random-Projection-for-Euclidean-Distance" class="headerlink" title="Bucketed Random Projection for Euclidean Distance"></a>Bucketed Random Projection for Euclidean Distance</h4><p><a href="https://en.wikipedia.org/wiki/Locality-sensitive_hashing#Stable_distributions" target="_blank" rel="noopener">Bucketed Random Projection</a>是一个基于欧氏距离的LSH family。欧几里德距离定义如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">d(x,y) = sqrt(sum((xi - yi)**2))</span><br></pre></td></tr></table></figure></p><p> 其LSH族将特征向量投影到随机单位向量上，并将投影结果分成哈希桶：<br> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">h(x) = [x·v/r]</span><br></pre></td></tr></table></figure></p><p>其中r是用户定义的桶长度。桶长度可以用来控制散列桶的平均大小（从而控制桶的数量）。较大的桶长度（即，较少的桶）增加了特征被散列到相同桶的可能性（增加了true and false positives）。</p><p>Bucketed Random Projection接受任意向量作为输入特征，同时支持稀疏和密集向量。\<br>有关API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.BucketedRandomProjectionLSH" target="_blank" rel="noopener">BucketedRandomProjectionLSH Python文档</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> BucketedRandomProjectionLSH</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> col</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"BucketedRandomProjectionLshExample"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">dataA = [(<span class="number">0</span>, Vectors.dense([<span class="number">1.0</span>, <span class="number">1.0</span>]),),</span><br><span class="line">         (<span class="number">1</span>, Vectors.dense([<span class="number">1.0</span>, <span class="number">-1.0</span>]),),</span><br><span class="line">         (<span class="number">2</span>, Vectors.dense([<span class="number">-1.0</span>, <span class="number">-1.0</span>]),),</span><br><span class="line">         (<span class="number">3</span>, Vectors.dense([<span class="number">-1.0</span>, <span class="number">1.0</span>]),)]</span><br><span class="line">dfA = spark.createDataFrame(dataA, [<span class="string">"id"</span>, <span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line">dataB = [(<span class="number">4</span>, Vectors.dense([<span class="number">1.0</span>, <span class="number">0.0</span>]),),</span><br><span class="line">         (<span class="number">5</span>, Vectors.dense([<span class="number">-1.0</span>, <span class="number">0.0</span>]),),</span><br><span class="line">         (<span class="number">6</span>, Vectors.dense([<span class="number">0.0</span>, <span class="number">1.0</span>]),),</span><br><span class="line">         (<span class="number">7</span>, Vectors.dense([<span class="number">0.0</span>, <span class="number">-1.0</span>]),)]</span><br><span class="line">dfB = spark.createDataFrame(dataB, [<span class="string">"id"</span>, <span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line">key = Vectors.dense([<span class="number">1.0</span>, <span class="number">0.0</span>])</span><br><span class="line"></span><br><span class="line">brp = BucketedRandomProjectionLSH(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"hashes"</span>, bucketLength=<span class="number">2.0</span>,</span><br><span class="line">                                  numHashTables=<span class="number">3</span>)</span><br><span class="line">model = brp.fit(dfA)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Feature Transformation</span></span><br><span class="line">print(<span class="string">"The hashed dataset where hashed values are stored in the column 'hashes':"</span>)</span><br><span class="line">model.transform(dfA).show(truncate=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the locality sensitive hashes for the input rows, then perform approximate</span></span><br><span class="line"><span class="comment"># similarity join.</span></span><br><span class="line"><span class="comment"># We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span></span><br><span class="line"><span class="comment"># `model.approxSimilarityJoin(transformedA, transformedB, 1.5)`</span></span><br><span class="line">print(<span class="string">"Approximately joining dfA and dfB on Euclidean distance smaller than 1.5:"</span>)</span><br><span class="line">model.approxSimilarityJoin(dfA, dfB, <span class="number">1.5</span>, distCol=<span class="string">"EuclideanDistance"</span>)\</span><br><span class="line">    .select(col(<span class="string">"datasetA.id"</span>).alias(<span class="string">"idA"</span>),</span><br><span class="line">            col(<span class="string">"datasetB.id"</span>).alias(<span class="string">"idB"</span>),</span><br><span class="line">            col(<span class="string">"EuclideanDistance"</span>)).show(truncate=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the locality sensitive hashes for the input rows, then perform approximate nearest</span></span><br><span class="line"><span class="comment"># neighbor search.</span></span><br><span class="line"><span class="comment"># We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span></span><br><span class="line"><span class="comment"># `model.approxNearestNeighbors(transformedA, key, 2)`</span></span><br><span class="line">print(<span class="string">"Approximately searching dfA for 2 nearest neighbors of the key:"</span>)</span><br><span class="line">model.approxNearestNeighbors(dfA, key, <span class="number">2</span>).show(truncate=<span class="keyword">False</span>)</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">The hashed dataset where hashed values are stored <span class="keyword">in</span> the column <span class="string">'hashes'</span>:</span><br><span class="line">+---+-----------+-----------------------+</span><br><span class="line">|id |features   |hashes                 |</span><br><span class="line">+---+-----------+-----------------------+</span><br><span class="line">|<span class="number">0</span>  |[<span class="number">1.0</span>,<span class="number">1.0</span>]  |[[<span class="number">-1.0</span>], [<span class="number">0.0</span>], [<span class="number">0.0</span>]] |</span><br><span class="line">|<span class="number">1</span>  |[<span class="number">1.0</span>,<span class="number">-1.0</span>] |[[<span class="number">0.0</span>], [<span class="number">-1.0</span>], [<span class="number">0.0</span>]] |</span><br><span class="line">|<span class="number">2</span>  |[<span class="number">-1.0</span>,<span class="number">-1.0</span>]|[[<span class="number">0.0</span>], [<span class="number">-1.0</span>], [<span class="number">-1.0</span>]]|</span><br><span class="line">|<span class="number">3</span>  |[<span class="number">-1.0</span>,<span class="number">1.0</span>] |[[<span class="number">-1.0</span>], [<span class="number">0.0</span>], [<span class="number">-1.0</span>]]|</span><br><span class="line">+---+-----------+-----------------------+</span><br><span class="line"></span><br><span class="line">Approximately joining dfA <span class="keyword">and</span> dfB on Euclidean distance smaller than <span class="number">1.5</span>:</span><br><span class="line">+---+---+-----------------+</span><br><span class="line">|idA|idB|EuclideanDistance|</span><br><span class="line">+---+---+-----------------+</span><br><span class="line">|<span class="number">0</span>  |<span class="number">4</span>  |<span class="number">1.0</span>              |</span><br><span class="line">|<span class="number">2</span>  |<span class="number">7</span>  |<span class="number">1.0</span>              |</span><br><span class="line">|<span class="number">1</span>  |<span class="number">4</span>  |<span class="number">1.0</span>              |</span><br><span class="line">|<span class="number">0</span>  |<span class="number">6</span>  |<span class="number">1.0</span>              |</span><br><span class="line">|<span class="number">3</span>  |<span class="number">6</span>  |<span class="number">1.0</span>              |</span><br><span class="line">|<span class="number">3</span>  |<span class="number">5</span>  |<span class="number">1.0</span>              |</span><br><span class="line">|<span class="number">1</span>  |<span class="number">7</span>  |<span class="number">1.0</span>              |</span><br><span class="line">|<span class="number">2</span>  |<span class="number">5</span>  |<span class="number">1.0</span>              |</span><br><span class="line">+---+---+-----------------+</span><br><span class="line"></span><br><span class="line">Approximately searching dfA <span class="keyword">for</span> <span class="number">2</span> nearest neighbors of the key:</span><br><span class="line">+---+----------+----------------------+-------+</span><br><span class="line">|id |features  |hashes                |distCol|</span><br><span class="line">+---+----------+----------------------+-------+</span><br><span class="line">|<span class="number">0</span>  |[<span class="number">1.0</span>,<span class="number">1.0</span>] |[[<span class="number">-1.0</span>], [<span class="number">0.0</span>], [<span class="number">0.0</span>]]|<span class="number">1.0</span>    |</span><br><span class="line">|<span class="number">1</span>  |[<span class="number">1.0</span>,<span class="number">-1.0</span>]|[[<span class="number">0.0</span>], [<span class="number">-1.0</span>], [<span class="number">0.0</span>]]|<span class="number">1.0</span>    |</span><br><span class="line">+---+----------+----------------------+-------+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/bucketed_random_projection_lsh_example.py” in the Spark repo.</p><h4 id="MinHash-for-Jaccard-Distance"><a href="#MinHash-for-Jaccard-Distance" class="headerlink" title="MinHash for Jaccard Distance"></a>MinHash for Jaccard Distance</h4><p><a href="https://en.wikipedia.org/wiki/MinHash" target="_blank" rel="noopener">MinHash</a>是用于计算Jaccard距离的LSH族，其中输入特征是自然数集合。两个集合的Jaccard距离由它们的交集和并集决定：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">d(A,B) = 1 -|A ∩ B| / |A ∪ B|</span><br></pre></td></tr></table></figure></p><p>MinHash 对集合中的每个元素应用随机哈希函数g，并取所有哈希值的最小值：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">h(A) = min(g(a))  ,a∈A</span><br></pre></td></tr></table></figure></p><p>MinHash的输入集表示为二元向量，其中向量索引表示元素本身，向量中的非零值表示集合中元素的存在。虽然支持密集和稀疏向量，但通常建议使用稀疏向量来提高效率。例如，Vectors.sparse(10, Array[(2, 1.0), (3, 1.0), (5, 1.0)])意味着空间中有10个元素。该集合包含元素2，元素3和元素5.所有非零值都被视为二进制“1”值。</p><p>注意：空集不能被MinHash转换，这意味着任何输入向量必须至少有一个非零的entry。</p><p>有关API的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.MinHashLSH" target="_blank" rel="noopener">MinHashLSH Python文档</a>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> MinHashLSH</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.functions <span class="keyword">import</span> col</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"MinHashLSHExample"</span>).getOrCreate()</span><br><span class="line">dataA = [(<span class="number">0</span>, Vectors.sparse(<span class="number">6</span>, [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>]),),</span><br><span class="line">         (<span class="number">1</span>, Vectors.sparse(<span class="number">6</span>, [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>]),),</span><br><span class="line">         (<span class="number">2</span>, Vectors.sparse(<span class="number">6</span>, [<span class="number">0</span>, <span class="number">2</span>, <span class="number">4</span>], [<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>]),)]</span><br><span class="line">dfA = spark.createDataFrame(dataA, [<span class="string">"id"</span>, <span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line">dataB = [(<span class="number">3</span>, Vectors.sparse(<span class="number">6</span>, [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>], [<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>]),),</span><br><span class="line">         (<span class="number">4</span>, Vectors.sparse(<span class="number">6</span>, [<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>], [<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>]),),</span><br><span class="line">         (<span class="number">5</span>, Vectors.sparse(<span class="number">6</span>, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>], [<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>]),)]</span><br><span class="line">dfB = spark.createDataFrame(dataB, [<span class="string">"id"</span>, <span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line">key = Vectors.sparse(<span class="number">6</span>, [<span class="number">1</span>, <span class="number">3</span>], [<span class="number">1.0</span>, <span class="number">1.0</span>])</span><br><span class="line"></span><br><span class="line">mh = MinHashLSH(inputCol=<span class="string">"features"</span>, outputCol=<span class="string">"hashes"</span>, numHashTables=<span class="number">5</span>)</span><br><span class="line">model = mh.fit(dfA)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Feature Transformation</span></span><br><span class="line">print(<span class="string">"The hashed dataset where hashed values are stored in the column 'hashes':"</span>)</span><br><span class="line">model.transform(dfA).show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the locality sensitive hashes for the input rows, then perform approximate</span></span><br><span class="line"><span class="comment"># similarity join.</span></span><br><span class="line"><span class="comment"># We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span></span><br><span class="line"><span class="comment"># `model.approxSimilarityJoin(transformedA, transformedB, 0.6)`</span></span><br><span class="line">print(<span class="string">"Approximately joining dfA and dfB on distance smaller than 0.6:"</span>)</span><br><span class="line">model.approxSimilarityJoin(dfA, dfB, <span class="number">0.6</span>, distCol=<span class="string">"JaccardDistance"</span>)\</span><br><span class="line">    .select(col(<span class="string">"datasetA.id"</span>).alias(<span class="string">"idA"</span>),</span><br><span class="line">            col(<span class="string">"datasetB.id"</span>).alias(<span class="string">"idB"</span>),</span><br><span class="line">            col(<span class="string">"JaccardDistance"</span>)).show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compute the locality sensitive hashes for the input rows, then perform approximate nearest</span></span><br><span class="line"><span class="comment"># neighbor search.</span></span><br><span class="line"><span class="comment"># We could avoid computing hashes by passing in the already-transformed dataset, e.g.</span></span><br><span class="line"><span class="comment"># `model.approxNearestNeighbors(transformedA, key, 2)`</span></span><br><span class="line"><span class="comment"># It may return less than 2 rows when not enough approximate near-neighbor candidates are</span></span><br><span class="line"><span class="comment"># found.</span></span><br><span class="line">print(<span class="string">"Approximately searching dfA for 2 nearest neighbors of the key:"</span>)</span><br><span class="line">model.approxNearestNeighbors(dfA, key, <span class="number">2</span>).show()</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure></p><p>output:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">The hashed dataset where hashed values are stored <span class="keyword">in</span> the column <span class="string">'hashes'</span>:</span><br><span class="line">+---+--------------------+--------------------+</span><br><span class="line">| id|            features|              hashes|</span><br><span class="line">+---+--------------------+--------------------+</span><br><span class="line">|  <span class="number">0</span>|(<span class="number">6</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">1.0</span>,<span class="number">1.</span>..|[[<span class="number">-8.91727E8</span>], [-...|</span><br><span class="line">|  <span class="number">1</span>|(<span class="number">6</span>,[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">1.0</span>,<span class="number">1.</span>..|[[<span class="number">-1.81795643E9</span>],...|</span><br><span class="line">|  <span class="number">2</span>|(<span class="number">6</span>,[<span class="number">0</span>,<span class="number">2</span>,<span class="number">4</span>],[<span class="number">1.0</span>,<span class="number">1.</span>..|[[<span class="number">-1.33587497E8</span>],...|</span><br><span class="line">+---+--------------------+--------------------+</span><br><span class="line"></span><br><span class="line">Approximately joining dfA <span class="keyword">and</span> dfB on distance smaller than <span class="number">0.6</span>:</span><br><span class="line">+---+---+---------------+</span><br><span class="line">|idA|idB|JaccardDistance|</span><br><span class="line">+---+---+---------------+</span><br><span class="line">|  <span class="number">1</span>|  <span class="number">4</span>|            <span class="number">0.5</span>|</span><br><span class="line">|  <span class="number">1</span>|  <span class="number">5</span>|            <span class="number">0.5</span>|</span><br><span class="line">|  <span class="number">2</span>|  <span class="number">5</span>|            <span class="number">0.5</span>|</span><br><span class="line">|  <span class="number">0</span>|  <span class="number">5</span>|            <span class="number">0.5</span>|</span><br><span class="line">+---+---+---------------+</span><br><span class="line"></span><br><span class="line">Approximately searching dfA <span class="keyword">for</span> <span class="number">2</span> nearest neighbors of the key:</span><br><span class="line">+---+--------------------+--------------------+-------+</span><br><span class="line">| id|            features|              hashes|distCol|</span><br><span class="line">+---+--------------------+--------------------+-------+</span><br><span class="line">|  <span class="number">0</span>|(<span class="number">6</span>,[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">1.0</span>,<span class="number">1.</span>..|[[<span class="number">-8.91727E8</span>], [-...|   <span class="number">0.75</span>|</span><br><span class="line">|  <span class="number">1</span>|(<span class="number">6</span>,[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],[<span class="number">1.0</span>,<span class="number">1.</span>..|[[<span class="number">-1.81795643E9</span>],...|   <span class="number">0.75</span>|</span><br><span class="line">+---+--------------------+--------------------+-------+</span><br></pre></td></tr></table></figure></p><p>Find full example code at “examples/src/main/python/ml/min_hash_lsh_example.py” in the Spark repo.</p><h2 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h2>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;Extracting, Transforming and Selecting features(特征的提取、转换、选择)&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
&lt;p&gt;本节介绍用于处理特征的算法，大致分为以下几组：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Extraction(提取)&lt;/strong&gt;：从“原始”数据中提取特征&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transformation(转换)&lt;/strong&gt;：缩放，转换或修改特征&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Selection(选择)&lt;/strong&gt;：从一大组特征集中选择一个子集&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Locality Sensitive Hashing局部敏感散列（LSH）&lt;/strong&gt;：这类算法将特征变换的各个方面与其他算法相结合。&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Spark" scheme="https://blog.writeathink.cn/categories/Spark/"/>
    
      <category term="MLlib" scheme="https://blog.writeathink.cn/categories/Spark/MLlib/"/>
    
    
      <category term="TF-IDF" scheme="https://blog.writeathink.cn/tags/TF-IDF/"/>
    
      <category term="Word2Vec" scheme="https://blog.writeathink.cn/tags/Word2Vec/"/>
    
      <category term="OneHotEncoding" scheme="https://blog.writeathink.cn/tags/OneHotEncoding/"/>
    
  </entry>
  
  <entry>
    <title>SparkMLlib-Pipeline</title>
    <link href="https://blog.writeathink.cn/2018/01/19/sparkmllib-pipeline/"/>
    <id>https://blog.writeathink.cn/2018/01/19/sparkmllib-pipeline/</id>
    <published>2018-01-19T09:03:04.000Z</published>
    <updated>2018-03-01T09:37:17.598Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p class="description">Spark中的管道pipeline<br></p><p><img src="" alt="" style="width:100%"><br>ML Pipelines</p><h2 id="管道中的主要概念"><a href="#管道中的主要概念" class="headerlink" title="管道中的主要概念"></a><strong>管道中的主要概念</strong></h2><p>MLlib对机器学习算法的API进行了标准化，使得将多种算法合并成一个流水线或工作流变得更加容易。本部分涵盖了Pipelines API引入的关键概念，其中流水线概念主要受scikit-learn项目的启发。</p><ul><li><p><strong>DataFrame</strong>：这个ML API使用Spark SQL中的DataFrame作为一个ML数据集，它可以容纳各种数据类型。例如，一个DataFrame可以具有存储文本，特征向量，真实标签和预测的不同列。</p></li><li><p><strong>Transformer</strong>：一个Transformer是可以将一个DataFrame变换成成另一个DataFrame的算法。例如，一个ML模型是一个Transformer将一个DataFrame特征转化为一个DataFrame预测的模型。</p></li><li><p><strong>Estimator</strong>：一个 Estimator是一个可以被应用在DataFrame上来产生一个Transformer的算法。例如，一个学习算法是一种Estimator，它可以在DataFrame上训练并生成模型。</p></li><li><p><strong>Pipeline</strong>：Pipeline将多个Transformers和Estimators连接起来以指定ML工作流程。</p></li><li><p><strong>Parameter</strong>：所有Transformers和Estimators现在对于指定参数共享通用API。</p></li></ul><a id="more"></a><h3 id="DataFrame-数据帧"><a href="#DataFrame-数据帧" class="headerlink" title="DataFrame(数据帧)"></a><strong>DataFrame(数据帧)</strong></h3><p>机器学习可以应用于各种数据类型，如向量，文本，图像和结构化数据。这个API采用DataFrameSpark SQL来支持各种数据类型。</p><p>DataFrame支持许多基本和结构化的类型; 请参阅Spark SQL数据类型参考以获取受支持类型的列表。除了Spark SQL指南中列出的类型以外，DataFrame还可以使用ML Vector类型。</p><p>A DataFrame可以隐式地或显式地从常规创建RDD。有关示例，请参阅下面的代码示例和Spark SQL编程指南。</p><p>a DataFrame中的列被命名。下面的代码示例使用“text”，“feature”和“label”等名称。</p><h3 id="Pipeline-components-管道组件"><a href="#Pipeline-components-管道组件" class="headerlink" title="Pipeline components(管道组件)"></a><strong>Pipeline components(管道组件)</strong></h3><h4 id="Transformers"><a href="#Transformers" class="headerlink" title="Transformers"></a>Transformers</h4><p>A Transformer是包含特征变换器和学习模型的抽象。从技术上来说，a Transformer实现了一种方法(<em>transform()</em>),将一个DataFrame转换为另一个的方法，通常通过附加一列或多列。例如：</p><ul><li>特征转换器选取一个DataFrame，读取列（例如文本），将其映射到新的列（例如特征向量），并且输出具有附加映射列的新DataFrame</li><li>学习模型可以选取一个DataFrame，读取包含特征向量的列，预测每个特征向量的标签，并输出带有预测标签的新列的DataFrame。</li></ul><h4 id="Estimators"><a href="#Estimators" class="headerlink" title="Estimators"></a>Estimators</h4><p>一个Estimator是在数据集上训练的学习算法的抽象概念。从技术上讲，一个Estimator实现了一个方法 <em>fit()</em>，它接受DataFrame并生成一个 Model，这是一个Transformer。例如，一个学习算法，如LogisticRegression(它是一个Estimator)，调用 <em>fit()</em> 函数来训练一个LogisticRegressionModel模型，它是一个Model也是一个Transformer。</p><h4 id="Properties-o-pipeline-components"><a href="#Properties-o-pipeline-components" class="headerlink" title="Properties o pipeline components"></a>Properties o pipeline components</h4><p>Transformer.transform()s和Estimator.fit()s都是无状态的。将来，有状态算法可以通过替代概念来支持。<br>每个Transformer或者Estimator的实例具有唯一的ID，这在指定参数（在下面讨论）中是有用的。</p><h3 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h3><p>在机器学习中，通常运行一系列算法来处理和学习数据。例如，简单的文本文档处理工作流程可能包括几个阶段：</p><ul><li>将每个文档的文本分词。</li><li>将每个文档的单词转换为数字特征向量。</li><li>使用特征向量和标签来学习预测模型。</li></ul><p>MLlib表示这样一个工作流程Pipeline，它由一系列 PipelineStages（Transformers和Estimators）组成，并以特定顺序运行。我们将使用这个简单的工作流程作为本节中的一个运行示例。</p><h4 id="How-it-works"><a href="#How-it-works" class="headerlink" title="How it works"></a>How it works</h4><p>A Pipeline是一个阶段序列，每个阶段是一个Transformer或一个Estimator。这些阶段是按顺序运行的，输入的DataFrame在每个阶段都经过转换。对于Transformer阶段，<em>transform()</em> 方法被调用作用于DataFrame上。对于Estimator阶段，<em>fit()</em>方法被调用，以产生Transformer（它成为PipelineModel或合适的Pipeline的一部分），以及Transformer的transform()方法也被调用作用于DataFrame。</p><p>我们用简单的文本文档工作流来说明这一点。下图是a 。训练时间的使用情况Pipeline。<br><img src="https://github.com/cgDeepLearn/LearnSpark/blob/master/pics/ml-Pipeline.png?raw=true" alt="Pipeline"></p><p>在上面，最上面一行代表一个Pipeline有三个阶段。前两个（Tokenizer和HashingTF）是Transformers（蓝色），第三个（LogisticRegression）是Estimator（红色）。最下面一行代表流经管道的数据，其中圆柱表示DataFrames。这个Pipeline.fit()方法在原始DataFrame文档和标签上被调用。Tokenizer.transform()方法将原始文本文档分词，分词后的words作为一个新列添加到DataFrame中。HashingTF.transform()方法将单词列转换为特征向量，并向这些向量作为一个新列添加到DataFrame中。现在，既然LogisticRegression是一个Estimator，Pipeline首先调用LogisticRegression.fit()方法就生成一个LogisticRegressionModel。如果Pipeline有更多Estimators，它就会在DataFrame传送到下个阶段之前调用LogisticRegressionModel的transform() 方法。</p><p>一个Pipeline是一个Estimator。因此，在Pipeline的fit()方法运行后，它产生一个PipelineModel，这是一个 Transformer。这PipelineModel是在测试时使用 ; 下图说明了这种用法。</p><p><img src="https://github.com/cgDeepLearn/LearnSpark/blob/master/pics/ml-PipelineModel.png?raw=true" alt="PiplineModel"></p><p>在上面的图中，PipelineModel具有和原始的Pipeline相同数量的阶段，但所有EstimatorS在原始Pipeline中已变成TransformerS。当PipelineModel的transform()方法在测试数据集被调用，数据在管道上按序传递。每个阶段的transform()方法都会更新数据集并将其传递到下一个阶段。</p><p>Pipelines和PipelineModels有助于确保训练和测试数据经过相同的特征处理步骤。</p><h4 id="Details"><a href="#Details" class="headerlink" title="Details"></a><strong>Details</strong></h4><p><em>DAG Pipelines</em>：A Pipeline的阶段被指定为一个有序数组。这里给出的例子都是线性Pipeline的，即Pipeline每个阶段使用前一阶段产生的数据。Pipeline只要数据流图形成有向无环图（DAG），就可以创建非线性的PipelineS。该图当前是基于每个阶段的输入和输出列名（通常指定为参数）隐含指定的。如果Pipeline形式为DAG，那么阶段必须按拓扑顺序指定。</p><p><em>Runtime checking</em>：由于Pipelines可以在不同类型的DataFrames上运行，所以不能使用compile-time类型检查。 Pipelines和PipelineModels，而是在实际运行Pipeline之前进行runtime checking检查。这种类型的检查是通过使用DataFrame <em>schema</em>来完成的，schema是对DataFrame的列的数据类型的描述。</p><p><em>Unique Pipeline stages</em>：A Pipeline的阶段应该是独一无二的实例。例如，同一个实例 myHashingTF不应该插入Pipeline两次，因为Pipeline阶段必须有唯一的ID。然而，不同的实例myHashingTF1和myHashingTF2（两个类型HashingTF）可以放在一起，Pipeline因为创建不同的实例使用不同的ID。</p><h3 id="Parameters"><a href="#Parameters" class="headerlink" title="Parameters"></a><strong>Parameters</strong></h3><p>MLlib Estimators和Transformers使用统一的API来指定参数。</p><p>A Param是一个带有自包含文档的命名参数。A ParamMap是一组（参数，值）对。</p><p>将参数传递给算法有两种主要方法：</p><ol><li>为实例设置参数。例如，如果lr是的一个实例LogisticRegression，它可以调用lr.setMaxIter(10)让lr.fit()至多10次迭代使用。这个API类似于spark.mllib包中使用的API 。</li><li>传递ParamMap给fit()或transform()。任何在ParamMap中额参数将覆盖以前通过setter方法指定的参数。</li></ol><p>参数属于Estimators和Transformers的特定实例。例如，如果我们有两个LogisticRegression实例lr1和lr2，然后我们可以建立一个ParamMap与两个maxIter指定的参数：ParamMap(lr1.maxIter -&gt; 10, lr2.maxIter -&gt; 20)。如果一个Pipeline里有两个包含maxIter参数的算法，那么这很有用。</p><h3 id="Saving-and-LoadingPipelines"><a href="#Saving-and-LoadingPipelines" class="headerlink" title="Saving and LoadingPipelines"></a><strong>Saving and LoadingPipelines</strong></h3><p>通常情况下，会将模型或管道保存到磁盘供以后使用。在Spark 1.6中，模型导入/导出功能被添加到管道API中。大多数基本的Transformers都和一些更加基本的ML模型一样被支持。请参阅算法的API文档以查看是否支持保存和加载。</p><h2 id="Code-examples"><a href="#Code-examples" class="headerlink" title="Code examples"></a>Code examples</h2><p>本节给出了说明上述功能的代码示例。有关更多信息，请参阅API文档（Scala， Java和Python）。</p><h3 id="Example-Estimator-Transformer-and-Param"><a href="#Example-Estimator-Transformer-and-Param" class="headerlink" title="Example: Estimator, Transformer, and Param"></a><strong>Example: Estimator, Transformer, and Param</strong></h3><p>这个例子涉及的概念Estimator，Transformer和Param。<br>请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.Estimator" target="_blank" rel="noopener">EstimatorPython文档</a>，<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.Transformer" target="_blank" rel="noopener">TransformerPython文档</a>和<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.param.Params" target="_blank" rel="noopener">ParamsPython文档</a>以获取有关API的更多详细信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession </span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"ParamsExample"</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Prepare training data from a list of (label, features) tuples.</span></span><br><span class="line">training = spark.createDataFrame([</span><br><span class="line">    (<span class="number">1.0</span>, Vectors.dense([<span class="number">0.0</span>, <span class="number">1.1</span>, <span class="number">0.1</span>])),</span><br><span class="line">    (<span class="number">0.0</span>, Vectors.dense([<span class="number">2.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>])),</span><br><span class="line">    (<span class="number">0.0</span>, Vectors.dense([<span class="number">2.0</span>, <span class="number">1.3</span>, <span class="number">1.0</span>])),</span><br><span class="line">    (<span class="number">1.0</span>, Vectors.dense([<span class="number">0.0</span>, <span class="number">1.2</span>, <span class="number">-0.5</span>]))], [<span class="string">"label"</span>, <span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a LogisticRegression instance. This instance is an Estimator.</span></span><br><span class="line">lr = LogisticRegression(maxIter=<span class="number">10</span>, regParam=<span class="number">0.01</span>)</span><br><span class="line"><span class="comment"># Print out the parameters, documentation, and any default values.</span></span><br><span class="line">print(<span class="string">"LogisticRegression parameters:\n"</span> + lr.explainParams() + <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Learn a LogisticRegression model. This uses the parameters stored in lr.</span></span><br><span class="line">model1 = lr.fit(training)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Since model1 is a Model (i.e., a transformer produced by an Estimator),</span></span><br><span class="line"><span class="comment"># we can view the parameters it used during fit().</span></span><br><span class="line"><span class="comment"># This prints the parameter (name: value) pairs, where names are unique IDs for this</span></span><br><span class="line"><span class="comment"># LogisticRegression instance.</span></span><br><span class="line">print(<span class="string">"Model 1 was fit using parameters: "</span>)</span><br><span class="line">print(model1.extractParamMap())</span><br><span class="line"></span><br><span class="line"><span class="comment"># We may alternatively specify parameters using a Python dictionary as a paramMap</span></span><br><span class="line">paramMap = &#123;lr.maxIter: <span class="number">20</span>&#125;</span><br><span class="line">paramMap[lr.maxIter] = <span class="number">30</span>  <span class="comment"># Specify 1 Param, overwriting the original maxIter.</span></span><br><span class="line">paramMap.update(&#123;lr.regParam: <span class="number">0.1</span>, lr.threshold: <span class="number">0.55</span>&#125;)  <span class="comment"># Specify multiple Params.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># You can combine paramMaps, which are python dictionaries.</span></span><br><span class="line">paramMap2 = &#123;lr.probabilityCol: <span class="string">"myProbability"</span>&#125;  <span class="comment"># Change output column name</span></span><br><span class="line">paramMapCombined = paramMap.copy()</span><br><span class="line">paramMapCombined.update(paramMap2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now learn a new model using the paramMapCombined parameters.</span></span><br><span class="line"><span class="comment"># paramMapCombined overrides all parameters set earlier via lr.set* methods.</span></span><br><span class="line">model2 = lr.fit(training, paramMapCombined)</span><br><span class="line">print(<span class="string">"Model 2 was fit using parameters: "</span>)</span><br><span class="line">print(model2.extractParamMap())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare test data</span></span><br><span class="line">test = spark.createDataFrame([</span><br><span class="line">    (<span class="number">1.0</span>, Vectors.dense([<span class="number">-1.0</span>, <span class="number">1.5</span>, <span class="number">1.3</span>])),</span><br><span class="line">    (<span class="number">0.0</span>, Vectors.dense([<span class="number">3.0</span>, <span class="number">2.0</span>, <span class="number">-0.1</span>])),</span><br><span class="line">    (<span class="number">1.0</span>, Vectors.dense([<span class="number">0.0</span>, <span class="number">2.2</span>, <span class="number">-1.5</span>]))], [<span class="string">"label"</span>, <span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make predictions on test data using the Transformer.transform() method.</span></span><br><span class="line"><span class="comment"># LogisticRegression.transform will only use the 'features' column.</span></span><br><span class="line"><span class="comment"># Note that model2.transform() outputs a "myProbability" column instead of the usual</span></span><br><span class="line"><span class="comment"># 'probability' column since we renamed the lr.probabilityCol parameter previously.</span></span><br><span class="line">prediction = model2.transform(test)</span><br><span class="line">result = prediction.select(<span class="string">"features"</span>, <span class="string">"label"</span>, <span class="string">"myProbability"</span>, <span class="string">"prediction"</span>) \</span><br><span class="line">    .collect()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> result:</span><br><span class="line">    print(<span class="string">"features=%s, label=%s -&gt; prob=%s, prediction=%s"</span></span><br><span class="line">          % (row.features, row.label, row.myProbability, row.prediction))</span><br><span class="line"></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>Find full example code at “examples/src/main/python/ml/estimator_transformer_param_example.py” in the Spark repo.</p><h3 id="Example-Pipeline"><a href="#Example-Pipeline" class="headerlink" title="Example: Pipeline"></a><strong>Example: Pipeline</strong></h3><p>本示例遵循Pipeline上图中所示的简单文本文档。<br>有关APi的更多详细信息，请参阅<a href="https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.Pipeline" target="_blank" rel="noopener">PipelinePython文档</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.classification <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> HashingTF, Tokenizer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession  </span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">""</span>PipeLineExample<span class="string">""</span>).getOrCreate()</span><br><span class="line"><span class="comment"># Prepare training documents from a list of (id, text, label) tuples.</span></span><br><span class="line">training = spark.createDataFrame([</span><br><span class="line">    (<span class="number">0</span>, <span class="string">"a b c d e spark"</span>, <span class="number">1.0</span>),</span><br><span class="line">    (<span class="number">1</span>, <span class="string">"b d"</span>, <span class="number">0.0</span>),</span><br><span class="line">    (<span class="number">2</span>, <span class="string">"spark f g h"</span>, <span class="number">1.0</span>),</span><br><span class="line">    (<span class="number">3</span>, <span class="string">"hadoop mapreduce"</span>, <span class="number">0.0</span>)</span><br><span class="line">], [<span class="string">"id"</span>, <span class="string">"text"</span>, <span class="string">"label"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Configure an ML pipeline, which consists of three stages: tokenizer, hashingTF, and lr.</span></span><br><span class="line">tokenizer = Tokenizer(inputCol=<span class="string">"text"</span>, outputCol=<span class="string">"words"</span>)</span><br><span class="line">hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=<span class="string">"features"</span>)</span><br><span class="line">lr = LogisticRegression(maxIter=<span class="number">10</span>, regParam=<span class="number">0.001</span>)</span><br><span class="line">pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit the pipeline to training documents.</span></span><br><span class="line">model = pipeline.fit(training)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare test documents, which are unlabeled (id, text) tuples.</span></span><br><span class="line">test = spark.createDataFrame([</span><br><span class="line">    (<span class="number">4</span>, <span class="string">"spark i j k"</span>),</span><br><span class="line">    (<span class="number">5</span>, <span class="string">"l m n"</span>),</span><br><span class="line">    (<span class="number">6</span>, <span class="string">"spark hadoop spark"</span>),</span><br><span class="line">    (<span class="number">7</span>, <span class="string">"apache hadoop"</span>)</span><br><span class="line">], [<span class="string">"id"</span>, <span class="string">"text"</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make predictions on test documents and print columns of interest.</span></span><br><span class="line">prediction = model.transform(test)</span><br><span class="line">selected = prediction.select(<span class="string">"id"</span>, <span class="string">"text"</span>, <span class="string">"probability"</span>, <span class="string">"prediction"</span>)</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> selected.collect():</span><br><span class="line">    rid, text, prob, prediction = row</span><br><span class="line">    print(<span class="string">"(%d, %s) --&gt; prob=%s, prediction=%f"</span> % (rid, text, str(prob), prediction))</span><br><span class="line"></span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p>Find full example code at “examples/src/main/python/ml/pipeline_example.py” in the Spark repo.</p><h3 id="Model-selection-hyperparameter-tuning-模型选择-超参数调整"><a href="#Model-selection-hyperparameter-tuning-模型选择-超参数调整" class="headerlink" title="Model selection (hyperparameter tuning)- 模型选择(超参数调整)"></a><strong>Model selection (hyperparameter tuning)- 模型选择(超参数调整)</strong></h3><p>使用ML管道的一大好处是超参数优化。有关自动模型选择的更多信息，请参阅<a href="https://spark.apache.org/docs/latest/ml-tuning.html" target="_blank" rel="noopener">ML调整指南</a>。</p><h2 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h2>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;Spark中的管道pipeline&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;br&gt;ML Pipelines&lt;/p&gt;
&lt;h2 id=&quot;管道中的主要概念&quot;&gt;&lt;a href=&quot;#管道中的主要概念&quot; class=&quot;headerlink&quot; title=&quot;管道中的主要概念&quot;&gt;&lt;/a&gt;&lt;strong&gt;管道中的主要概念&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;MLlib对机器学习算法的API进行了标准化，使得将多种算法合并成一个流水线或工作流变得更加容易。本部分涵盖了Pipelines API引入的关键概念，其中流水线概念主要受scikit-learn项目的启发。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;DataFrame&lt;/strong&gt;：这个ML API使用Spark SQL中的DataFrame作为一个ML数据集，它可以容纳各种数据类型。例如，一个DataFrame可以具有存储文本，特征向量，真实标签和预测的不同列。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Transformer&lt;/strong&gt;：一个Transformer是可以将一个DataFrame变换成成另一个DataFrame的算法。例如，一个ML模型是一个Transformer将一个DataFrame特征转化为一个DataFrame预测的模型。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Estimator&lt;/strong&gt;：一个 Estimator是一个可以被应用在DataFrame上来产生一个Transformer的算法。例如，一个学习算法是一种Estimator，它可以在DataFrame上训练并生成模型。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Pipeline&lt;/strong&gt;：Pipeline将多个Transformers和Estimators连接起来以指定ML工作流程。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Parameter&lt;/strong&gt;：所有Transformers和Estimators现在对于指定参数共享通用API。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Spark" scheme="https://blog.writeathink.cn/categories/Spark/"/>
    
      <category term="MLlib" scheme="https://blog.writeathink.cn/categories/Spark/MLlib/"/>
    
    
      <category term="pipeline" scheme="https://blog.writeathink.cn/tags/pipeline/"/>
    
  </entry>
  
  <entry>
    <title>SparkMLlib-Basic</title>
    <link href="https://blog.writeathink.cn/2018/01/19/sparkmllib-basic/"/>
    <id>https://blog.writeathink.cn/2018/01/19/sparkmllib-basic/</id>
    <published>2018-01-19T08:49:21.000Z</published>
    <updated>2018-03-01T09:36:02.041Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p class="description">机器学习裤(MLlib)指南</p><p><img src="" alt="" style="width:100%"></p><p>MLlib是Spark的机器学习库，可让实际的机器学习容易和可扩展，它提供了如下工具：</p><ul><li><p><strong>ML算法</strong>：通用学习算法，如分类，回归，聚类和协同过滤</p></li><li><p><strong>特征提取</strong>，特征提取，转换，降维和选择</p></li><li><p><strong>管道</strong>：用于构建，评估和调整ML管道的工具</p></li><li><p><strong>持久性</strong>：保存和加载算法，模型和管道</p></li><li><p><strong>实用程序</strong>：线性代数，统计，数据处理等</p></li></ul><a id="more"></a><h2 id="公告：基于DataFrame的API是主要的API"><a href="#公告：基于DataFrame的API是主要的API" class="headerlink" title="公告：基于DataFrame的API是主要的API"></a>公告：基于DataFrame的API是主要的API</h2><p>MLlib基于RDD的API现在处于维护模式。</p><p>从Spark 2.0开始，包中的基于RDD的API spark.mllib已进入维护模式。Spark的主要机器学习API现在是包中的基于DataFrame的API spark.ml。</p><p>有什么影响？</p><ul><li>MLlib将仍然支持基于RDD的API spark.mllib并修复错误。</li><li>MLlib不会将新功能添加到基于RDD的API。</li><li>在Spark 2.x版本中，MLlib将为基于DataFrame的API添加功能，以便与基于RDD的API达成功能奇偶校验。</li></ul><p>达到功能奇偶校验（大致估计为Spark 2.3）后，基于RDD的API将被弃用。</p><ul><li>基于RDD的API预计将在Spark 3.0中被删除。</li></ul><p>为什么MLlib切换到基于DataFrame的API？</p><ul><li>DataFrames提供比RDD更友好的API。DataFrame的许多优点包括Spark数据源，SQL / DataFrame查询，Tungsten和Catalyst优化以及跨语言的统一API。</li><li>MLlib的基于DataFrame的API提供跨ML算法和跨多种语言的统一API。</li><li>数据框便于实际的ML管线，特别是功能转换。有关详细信息，请参阅管道指南。</li></ul><p>什么是“Spark ML”？</p><ul><li>“Spark ML”不是一个正式的名字，偶尔用于指代基于MLlib DataFrame的API。这主要是由于org.apache.spark.ml基于DataFrame的API所使用的Scala包名以及我们最初用来强调管道概念的“Spark ML Pipelines”术语。</li></ul><p>MLlib是否被弃用？</p><ul><li>编号MLlib包括基于RDD的API和基于DataFrame的API。基于RDD的API现在处于维护模式。但是这两个API都没过时，MLlib也是。</li></ul><h2 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h2><p>MLlib使用线性代数包Breeze，它依赖于 netlib-java进行优化的数值处理。如果本机库1在运行时不可用，您将看到一条警告消息，而将使用纯JVM实现。</p><p>由于运行时专有二进制文件的授权问题，netlib-java默认情况下，我们不包含本地代理。要配置netlib-java/ Breeze以使用系统优化的二进制文件，请包括 com.github.fommil.netlib:all:1.1.2（或者构建Spark -Pnetlib-lgpl）作为项目的依赖项，并阅读netlib-java文档以获取平台的其他安装说明。</p><p>要在Python中使用MLlib，您将需要NumPy 1.4或更高版本。</p><h2 id="2-2中的亮点"><a href="#2-2中的亮点" class="headerlink" title="2.2中的亮点"></a>2.2中的亮点</h2><p>下面的列表突出了在2.2 Spark发行版中添加到MLlib中的一些新功能和增强功能：</p><ul><li>ALS为所有用户或项目提供top-k建议的方法，与mllib （SPARK-19535）中的功能相匹配。性能也得到了改善两者ml和mllib （SPARK-11968和 SPARK-20587）</li><li>Correlation和 ChiSquareTest统计功能DataFrames （SPARK-19636和 SPARK-19635）</li><li>FPGrowth频繁模式挖掘算法（SPARK-14503）</li><li>GLM现在支持Tweedie全家（SPARK-18929）</li><li>Imputer特征变换器来估算数据集中的缺失值（SPARK-13​​568）</li><li>LinearSVC 对于线性支持向量机分类（SPARK-14709）</li><li>逻辑回归现在支持训练期间系数的限制（SPARK-20047）</li></ul><h2 id="迁移指南"><a href="#迁移指南" class="headerlink" title="迁移指南"></a>迁移指南</h2><p>MLlib正在积极开发中。未来发行版中标记为Experimental/ 的API DeveloperApi可能会更改，下面的迁移指南将解释发行版之间的所有更改。</p><h2 id="Basic-Statistics"><a href="#Basic-Statistics" class="headerlink" title="Basic Statistics"></a>Basic Statistics</h2><h3 id="Correllation-相关性"><a href="#Correllation-相关性" class="headerlink" title="Correllation(相关性)"></a>Correllation(相关性)</h3><p>计算两组数据之间的相关性是统计学中的一个常见操作。在spark.ml 我们提供的灵活性来计算多个系列之间的成对相关性。支持的相关方法目前是<strong>皮尔逊</strong>和<strong>斯皮尔曼</strong>相关性。</p><p>Correlation 使用指定的方法计算输入矢量数据集的相关矩阵。输出将是一个DataFrame，它包含向量列的相关矩阵。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.stat <span class="keyword">import</span> Correlation</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"CorrelationExample"</span>).getOrCreate()</span><br><span class="line">data = [(Vectors.sparse(<span class="number">4</span>, [(<span class="number">0</span>, <span class="number">1.0</span>), (<span class="number">3</span>, <span class="number">-2.0</span>)]),),</span><br><span class="line">        (Vectors.dense([<span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">0.0</span>, <span class="number">3.0</span>]),),</span><br><span class="line">        (Vectors.dense([<span class="number">6.0</span>, <span class="number">7.0</span>, <span class="number">0.0</span>, <span class="number">8.0</span>]),),</span><br><span class="line">        (Vectors.sparse(<span class="number">4</span>, [(<span class="number">0</span>, <span class="number">9.0</span>), (<span class="number">3</span>, <span class="number">1.0</span>)]),)]</span><br><span class="line">df = spark.createDataFrame(data, [<span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line">r1 = Correlation.corr(df, <span class="string">"features"</span>).head()</span><br><span class="line">print(<span class="string">"Pearson correlation matrix:\n"</span> + str(r1[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">r2 = Correlation.corr(df, <span class="string">"features"</span>, <span class="string">"spearman"</span>).head()</span><br><span class="line">print(<span class="string">"Spearman correlation matrix:\n"</span> + str(r2[<span class="number">0</span>]))</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p><em>Find full example code at “examples/src/main/python/ml/correlation_example.py” in the Spark repo.</em></p><h3 id="Hypothesis-testing-假设检验"><a href="#Hypothesis-testing-假设检验" class="headerlink" title="Hypothesis testing(假设检验)"></a>Hypothesis testing(假设检验)</h3><p>假设检验是统计学中一个强大的工具，用来确定一个结果是否具有统计显著性，这个结果是否偶然发生。spark.ml目前支持皮尔逊的卡方（χ2χ2）测试独立性。</p><p>ChiSquareTest针对标签的每个特征进行皮尔森独立测试。对于每个特征，（特征，标签）对被转换为计算卡方统计量的可能性矩阵。所有标签和特征值必须是分类的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.ml.linalg <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.stat <span class="keyword">import</span> ChiSquareTest</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line">spark = SparkSession.builder.appName(<span class="string">"HypothesisTestExample"</span>).getOrCreate()</span><br><span class="line">data = [(<span class="number">0.0</span>, Vectors.dense(<span class="number">0.5</span>, <span class="number">10.0</span>)),</span><br><span class="line">        (<span class="number">0.0</span>, Vectors.dense(<span class="number">1.5</span>, <span class="number">20.0</span>)),</span><br><span class="line">        (<span class="number">1.0</span>, Vectors.dense(<span class="number">1.5</span>, <span class="number">30.0</span>)),</span><br><span class="line">        (<span class="number">0.0</span>, Vectors.dense(<span class="number">3.5</span>, <span class="number">30.0</span>)),</span><br><span class="line">        (<span class="number">0.0</span>, Vectors.dense(<span class="number">3.5</span>, <span class="number">40.0</span>)),</span><br><span class="line">        (<span class="number">1.0</span>, Vectors.dense(<span class="number">3.5</span>, <span class="number">40.0</span>))]</span><br><span class="line">df = spark.createDataFrame(data, [<span class="string">"label"</span>, <span class="string">"features"</span>])</span><br><span class="line"></span><br><span class="line">r = ChiSquareTest.test(df, <span class="string">"features"</span>, <span class="string">"label"</span>).head()</span><br><span class="line">print(<span class="string">"pValues: "</span> + str(r.pValues))</span><br><span class="line">print(<span class="string">"degreesOfFreedom: "</span> + str(r.degreesOfFreedom))</span><br><span class="line">print(<span class="string">"statistics: "</span> + str(r.statistics))</span><br><span class="line">spark.stop()</span><br></pre></td></tr></table></figure><p><em>Find full example code at “examples/src/main/python/ml/chi_square_test_example.py” in the Spark repo.</em></p><h2 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h2><p>接着往下阅读<a href="sparkmllib-pipeline">Pipeline</a></p><h2 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h2>]]></content>
    
    <summary type="html">
    
      &lt;p class=&quot;description&quot;&gt;机器学习裤(MLlib)指南&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;&quot; alt=&quot;&quot; style=&quot;width:100%&quot;&gt;&lt;/p&gt;
&lt;p&gt;MLlib是Spark的机器学习库，可让实际的机器学习容易和可扩展，它提供了如下工具：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;ML算法&lt;/strong&gt;：通用学习算法，如分类，回归，聚类和协同过滤&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;特征提取&lt;/strong&gt;，特征提取，转换，降维和选择&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;管道&lt;/strong&gt;：用于构建，评估和调整ML管道的工具&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;持久性&lt;/strong&gt;：保存和加载算法，模型和管道&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;实用程序&lt;/strong&gt;：线性代数，统计，数据处理等&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Spark" scheme="https://blog.writeathink.cn/categories/Spark/"/>
    
      <category term="MLlib" scheme="https://blog.writeathink.cn/categories/Spark/MLlib/"/>
    
    
      <category term="DataFrame" scheme="https://blog.writeathink.cn/tags/DataFrame/"/>
    
      <category term="RDD" scheme="https://blog.writeathink.cn/tags/RDD/"/>
    
  </entry>
  
  <entry>
    <title>hexo-music</title>
    <link href="https://blog.writeathink.cn/2018/01/19/hexo-music/"/>
    <id>https://blog.writeathink.cn/2018/01/19/hexo-music/</id>
    <published>2018-01-19T03:01:58.000Z</published>
    <updated>2018-03-01T09:35:36.316Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><p><code>hexo</code> 添加音乐，<code>iframe</code> 、 <code>hexo-tag-aplayer</code></p><p><img src="/images/lucid-dream.jpg" alt="fun"> </p><a id="more"></a><h1 id="iframe方式"><a href="#iframe方式" class="headerlink" title="iframe方式"></a>iframe方式</h1><h2 id="生成音乐外链"><a href="#生成音乐外链" class="headerlink" title="生成音乐外链"></a>生成音乐外链</h2><p>找到网易云的生成外链页面后(注找有版权保护的音乐不行，请更换没有版权保护的)</p><p>点击iframe插件，根据自己的喜好设置后复制iframe代码</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"music163player"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">iframe</span> <span class="attr">frameborder</span>=<span class="string">"no"</span> <span class="attr">border</span>=<span class="string">"0"</span> <span class="attr">marginwidth</span>=<span class="string">"0"</span> <span class="attr">marginheight</span>=<span class="string">"0"</span> <span class="attr">width</span>=<span class="string">280</span> <span class="attr">height</span>=<span class="string">86</span> <span class="attr">src</span>=<span class="string">"//music.163.com/outchain/player?type=2&amp;id=38358214&amp;auto=0&amp;height=66"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">iframe</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="添加到sidebar-swig"><a href="#添加到sidebar-swig" class="headerlink" title="添加到sidebar.swig"></a>添加到sidebar.swig</h2><p>放置到hexo-theme/next/layout/_macro/sidebar.swig文件下</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">    ...</span><br><span class="line">    <span class="tag">&lt;<span class="name">pre</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--insert here--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"music163player"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">iframe</span> <span class="attr">frameborder</span>=<span class="string">"no"</span> <span class="attr">border</span>=<span class="string">"0"</span> <span class="attr">marginwidth</span>=<span class="string">"0"</span> <span class="attr">marginheight</span>=<span class="string">"0"</span> <span class="attr">width</span>=<span class="string">280</span> <span class="attr">height</span>=<span class="string">86</span> <span class="attr">src</span>=<span class="string">"//music.163.com/outchain/player?type=2&amp;id=38358214&amp;auto=0&amp;height=66"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">iframe</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">aside</span>&gt;</span></span><br><span class="line">&#123;% endmacro %&#125;</span><br></pre></td></tr></table></figure><h2 id="效果展示"><a href="#效果展示" class="headerlink" title="效果展示"></a>效果展示</h2><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="280" height="86" src="//music.163.com/outchain/player?type=2&id=38358214&auto=0&height=66"><br></iframe><h1 id="hexo-tag-aplayer"><a href="#hexo-tag-aplayer" class="headerlink" title="hexo-tag-aplayer"></a>hexo-tag-aplayer</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-tag-aplayer@2.0.1</span><br></pre></td></tr></table></figure><h2 id="添加到文章中"><a href="#添加到文章中" class="headerlink" title="添加到文章中"></a>添加到文章中</h2><p>在media目录和images目录放置相应音频和图片文件，当然你也可以填写网络上的相关地址</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;% aplayer "Lucid dream" "Owl City" "/media/Lucid-Dream.mp3" "/images/lucid-dream.jpg" %&#125;</span><br></pre></td></tr></table></figure><p>运行<code>hexo g</code>,<code>hexo s -p 3000</code>可在本地查看效果<br>或运行<code>hexo g -d</code>部署，进入自己的网站查看</p><h2 id="效果展示-1"><a href="#效果展示-1" class="headerlink" title="效果展示"></a>效果展示</h2><div id="aplayer0" class="aplayer" style="margin-bottom: 20px;"></div><script>new APlayer({element: document.getElementById("aplayer0"),narrow: false,autoplay: false,showlrc: 0,music: {title: "Lucid dream",author: "Owl City",url: "/media/Lucid-Dream.mp3",pic: "/images/lucid-dream.jpg",}});</script><p><img src="/images/lucid-dream.jpg" alt="fun"> </p><h2 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;hexo&lt;/code&gt; 添加音乐，&lt;code&gt;iframe&lt;/code&gt; 、 &lt;code&gt;hexo-tag-aplayer&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/lucid-dream.jpg&quot; alt=&quot;fun&quot;&gt; &lt;/p&gt;
    
    </summary>
    
      <category term="hexo" scheme="https://blog.writeathink.cn/categories/hexo/"/>
    
    
      <category term="music" scheme="https://blog.writeathink.cn/tags/music/"/>
    
      <category term="hexo-tag-aplayer" scheme="https://blog.writeathink.cn/tags/hexo-tag-aplayer/"/>
    
  </entry>
  
</feed>
